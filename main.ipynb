{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "253770a5",
   "metadata": {},
   "source": [
    "# Word Embedding Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e015f1b",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7230eb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, manhattan_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36ae151",
   "metadata": {},
   "source": [
    "## 1 - Loading data\n",
    "Loading the models and sentences used.\n",
    "- Models: https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "- Sentences: https://github.com/alexa/massive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ab38a6d",
   "metadata": {},
   "source": [
    "Defining global data paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "FASTTEXT_PATH = 'Datasets/FastText/'\n",
    "MASSIVE_PATH = 'Datasets/Amazon_Massive/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "906dd80c",
   "metadata": {},
   "source": [
    "In case this your first time running this notebook, the cell below is going to create a FastText folder inside the Datasets one to store the FastText models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eb8257",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(FASTTEXT_PATH):\n",
    "    print('Creating FastText folder inside Datasets...')\n",
    "    os.mkdir(FASTTEXT_PATH)\n",
    "else:\n",
    "    print('FastText folder already exists.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8490122",
   "metadata": {},
   "source": [
    "Defining FastText models urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04495b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_MODELS = [\n",
    "    'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.da.300.vec.gz',\n",
    "    'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.nl.300.vec.gz',\n",
    "    'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz',\n",
    "    'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.vec.gz',\n",
    "    'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.de.300.vec.gz',\n",
    "    'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.it.300.vec.gz',\n",
    "    'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.pt.300.vec.gz',\n",
    "    'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ro.300.vec.gz',\n",
    "    'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz',\n",
    "    'https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.sv.300.vec.gz'\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1544a9f7",
   "metadata": {},
   "source": [
    "The cell below automatically creates a list with the FastText file names in the following format: cc.LANGUAGE.300.vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3416dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_MODELS = []\n",
    "\n",
    "for index in range(len(URL_MODELS)):\n",
    "    FILE_MODELS.append(\n",
    "        URL_MODELS[index][URL_MODELS[index].index('cc') : URL_MODELS[index].index('.gz')]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73bc41f5",
   "metadata": {},
   "source": [
    "In case you do not have the necessary models already downloaded and placed on the folder FastText, the cell below does it for you. Takes approximately 2min per .vec file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0337ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url_model, file_model in zip(URL_MODELS, FILE_MODELS):\n",
    "    if not os.path.isfile(FASTTEXT_PATH + file_model):\n",
    "\n",
    "        print(f'\\nDownloading {file_model}...')\n",
    "\n",
    "        urllib.request.urlretrieve(\n",
    "            url_model, \n",
    "            FASTTEXT_PATH + file_model\n",
    "        )\n",
    "\n",
    "        print(f'Finished downloading {file_model}.')\n",
    "\n",
    "    else:\n",
    "        print(f'File {file_model} already exists.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f860272",
   "metadata": {},
   "source": [
    "Unfortunatelly, the cell below must be hard-coded because the Amazon Massive file names do not follow a simple pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553117db",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = {\n",
    "    'da': [ FASTTEXT_PATH + 'cc.da.300.vec', MASSIVE_PATH + 'da-DK.jsonl' ],\n",
    "    'nl': [ FASTTEXT_PATH + 'cc.nl.300.vec', MASSIVE_PATH + 'nl-NL.jsonl' ],\n",
    "    'en': [ FASTTEXT_PATH + 'cc.en.300.vec', MASSIVE_PATH + 'en-US.jsonl' ],\n",
    "    'fr': [ FASTTEXT_PATH + 'cc.fr.300.vec', MASSIVE_PATH + 'fr-FR.jsonl' ],\n",
    "    'de': [ FASTTEXT_PATH + 'cc.de.300.vec', MASSIVE_PATH + 'de-DE.jsonl' ],\n",
    "    'it': [ FASTTEXT_PATH + 'cc.it.300.vec', MASSIVE_PATH + 'it-IT.jsonl' ],\n",
    "    'pt': [ FASTTEXT_PATH + 'cc.pt.300.vec', MASSIVE_PATH + 'pt-PT.jsonl' ],\n",
    "    'ro': [ FASTTEXT_PATH + 'cc.ro.300.vec', MASSIVE_PATH + 'ro-RO.jsonl' ],\n",
    "    'es': [ FASTTEXT_PATH + 'cc.es.300.vec', MASSIVE_PATH + 'es-ES.jsonl' ],\n",
    "    'sv': [ FASTTEXT_PATH + 'cc.sv.300.vec', MASSIVE_PATH + 'sv-SE.jsonl' ],\n",
    "}\n",
    "\n",
    "LANGUAGES = PATHS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f117e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(model_path, sentences_path, limit = None):\n",
    "    '''\n",
    "    Load models from FastText folder and sentences from Amazon_Massive folder.\n",
    "    \n",
    "    Params:\n",
    "    - model_path: path to the folder containing all models used, i.e., FastText\n",
    "    - sentences_path: path to the folder containing all sentences used, i.e., Amazon_Massive\n",
    "    - limit: define a limit in case your have low computer power, e.g., 5000\n",
    "    \n",
    "    Return:\n",
    "    Tuple containing the language model and its corresponding sentences\n",
    "    '''\n",
    "\n",
    "    model = KeyedVectors.load_word2vec_format(model_path, unicode_errors = 'replace', limit = limit)\n",
    "    sentences = pd.read_json(sentences_path, lines = True)['utt']\n",
    "    \n",
    "    return model, sentences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c564e517",
   "metadata": {},
   "source": [
    "We are now ready to load ours models and sentences into the code.\n",
    "\n",
    "**Note**: the cell below takes approximately 5 to 6 minutes per model. Given than we are working with 10 models, it should take approximately 1 hour. This is by far the most time-consuming cell of our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf0f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS, SENTENCES = {}, {}\n",
    "\n",
    "for language, value in PATHS.items():\n",
    "    model = value[0]\n",
    "    sentences = value[1]\n",
    "\n",
    "    print(f'Loading {model}...')\n",
    "\n",
    "    MODELS[language], SENTENCES[language] = load_files(model, sentences)\n",
    "\n",
    "    print(f'Finished loading {model}.\\n')\n",
    "\n",
    "print('\\nAll models and sentences are now loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e14fb99",
   "metadata": {},
   "source": [
    "## 2 - Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bceeb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = { key: [] for key in LANGUAGES }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67d11b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since all sentence files have the same length, we chose one at random for the range function.\n",
    "# We prove this in the cell below\n",
    "for index in range(len(SENTENCES['en'])):\n",
    "    \n",
    "    actual_sentence = { key: [] for key in LANGUAGES }\n",
    "    \n",
    "    try:\n",
    "        for lang, sent in SENTENCES.items():\n",
    "            for word in sent[index].split(' '):\n",
    "                actual_sentence[lang].append(MODELS[lang][word])\n",
    "\n",
    "    except KeyError:\n",
    "        continue\n",
    "    \n",
    "    for key, value in actual_sentence.items():\n",
    "        SAMPLES[key].append([SENTENCES[key][index], sum(value)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d43f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in SENTENCES:\n",
    "    SIZE_SAMPLES = len(SAMPLES[key])\n",
    "    print(\n",
    "        f'Total sentences in { key } file: { len(SENTENCES[key]) } \\\n",
    "        -> Model { key } samples: { len(SAMPLES[key]) } \\\n",
    "        ({ len(SAMPLES[key]) / len(SENTENCES[key]) * 100:.2f}%)'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aefab70",
   "metadata": {},
   "source": [
    "Splitting into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8198e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERCENTAGE = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fac669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_RATE = int(SIZE_SAMPLES * TRAIN_PERCENTAGE)\n",
    "\n",
    "TRAIN_SET = { key: SAMPLES[key][:SPLIT_RATE] for key in LANGUAGES }\n",
    "TEST_SET = { key: SAMPLES[key][SPLIT_RATE:] for key in LANGUAGES }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cf7d5e4",
   "metadata": {},
   "source": [
    "## 3 - Translating words using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711e3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSLATIONS = { key: { lang: None for lang in LANGUAGES if lang != key } for key in LANGUAGES }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1aadf6f9",
   "metadata": {},
   "source": [
    "Calculating SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5bc3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for origin, target in it.permutations(LANGUAGES, 2): \n",
    "\n",
    "    samples_origin = [sample[1] for sample in TRAIN_SET[origin]]\n",
    "    samples_target = [sample[1] for sample in TRAIN_SET[target]]\n",
    "\n",
    "    U, Sig, Vt = np.linalg.svd(np.transpose(samples_origin) @ samples_target)\n",
    "    \n",
    "    TRANSLATOR = np.transpose(Vt) @ np.transpose(U)\n",
    "    TRANSLATIONS[origin][target] = TRANSLATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4325e13",
   "metadata": {},
   "source": [
    "### List of examples words\n",
    "**Note**: only single words can be written, i.e., compound words like \"washing machine\" will result in Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed3f9c",
   "metadata": {},
   "source": [
    "- English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b75aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_WORD_LIST = [\n",
    "    'specification',\n",
    "    'book',\n",
    "    'duckling',\n",
    "    'machine',\n",
    "    'headphones'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04930bcf",
   "metadata": {},
   "source": [
    "- Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f14161",
   "metadata": {},
   "outputs": [],
   "source": [
    "ES_WORD_LIST = [\n",
    "    'hola',\n",
    "    'sí',\n",
    "    'computadora',\n",
    "    'país',\n",
    "    'nuevo',\n",
    "    'amor'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9107823",
   "metadata": {},
   "source": [
    "- Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed70d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_WORD_LIST = [\n",
    "    'sapato',\n",
    "    'flor',\n",
    "    'aniversário',\n",
    "    'saudades',\n",
    "    'amigo',\n",
    "    'faculdade'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad3f141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(word_list, origin_lang, target_lang):\n",
    "    '''\n",
    "    Function to translate one word from one language to another.\n",
    "\n",
    "    Params:\n",
    "    - word_list: list of example words.\n",
    "    - origin_lang: language in which the words in word_list are written\n",
    "    - target_lang: language you wish to know the translation\n",
    "\n",
    "    Example of usage:\n",
    "    translate(PT_WORD_LIST, 'es', 'pt')\n",
    "    '''\n",
    "    \n",
    "    for word in word_list:\n",
    "        print(\n",
    "            f'Original word: {word}'\n",
    "            f'Top 10 most similar words in {target_lang}'\n",
    "            f'{MODELS[target_lang].most_similar(TRANSLATIONS[origin_lang][target_lang] @ MODELS[origin_lang][word])}\\n'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18fa53d",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91ff3272",
   "metadata": {},
   "source": [
    "- Portuguese $\\rightarrow$ Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c2d369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "translate(PT_WORD_LIST, 'pt', 'es')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f29a05a8",
   "metadata": {},
   "source": [
    "- Portuguese $\\rightarrow$ English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0777db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(PT_WORD_LIST, 'pt', 'en')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42f82e71",
   "metadata": {},
   "source": [
    "- Spanish $\\rightarrow$ English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c980d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(ES_WORD_LIST, 'es', 'en')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f6b2270",
   "metadata": {},
   "source": [
    "- English $\\rightarrow$ Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3dc7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(EN_WORD_LIST, 'en', 'pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e534a",
   "metadata": {},
   "source": [
    "## 4 - Translating words using intermediate languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba21e7c",
   "metadata": {},
   "source": [
    "### Getting the most similar word in each language it pass.\n",
    "Most expensive (uses most_similar multiple times) and try to aproximate a word each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0596b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate_most_similar_word(word_list, origin_lang, intermediate_lang, target_lang):\n",
    "    '''\n",
    "    Translate one word from one language to another passing by an intermediate language.\n",
    "    In this function, we use the result of the most similar word of the intermediate language to make the next translation.\n",
    "\n",
    "    Params:\n",
    "    - word_list: list of example words.\n",
    "    - origin_lang: language in which the words in word_list are written\n",
    "    - intermediate_lang: intermediate language which translation between origin_lang and target_lang passes by\n",
    "    - target_lang: language you wish to know the translation\n",
    "\n",
    "    Example of usage:\n",
    "    intermediate_most_similar_word(PT_WORD_LIST, 'es', 'pt', 'en')\n",
    "    '''\n",
    "    \n",
    "    for word in word_list:\n",
    "        print(f'Original word: {word}')\n",
    "        \n",
    "        intermediate_word = MODELS[intermediate_lang].most_similar(\n",
    "            TRANSLATIONS[origin_lang][intermediate_lang] @ MODELS[origin_lang][word]\n",
    "        )[0][0]\n",
    "        print(f'Most similar word according to intermediate language: {intermediate_word}')\n",
    "\n",
    "        translated_language = MODELS[target_lang].most_similar(\n",
    "            TRANSLATIONS[intermediate_lang][target_lang] @ MODELS[intermediate_lang][intermediate_word]\n",
    "        )\n",
    "        print(f'Top 10 most similar words in target language passing by the intermediate language: {translated_language}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e5f3c6e",
   "metadata": {},
   "source": [
    "- Portuguese $\\rightarrow$ English $\\rightarrow$ Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c8b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_most_similar_word(PT_WORD_LIST, 'pt', 'en', 'es')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74244ca1",
   "metadata": {},
   "source": [
    "- Spanish $\\rightarrow$ Portuguese $\\rightarrow$ English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0073786",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_most_similar_word(ES_WORD_LIST, 'es', 'pt', 'en')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9842db97",
   "metadata": {},
   "source": [
    "- English $\\rightarrow$ Spanish $\\rightarrow$ Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc536b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_most_similar_word(EN_WORD_LIST, 'en', 'es', 'pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340e25f7",
   "metadata": {},
   "source": [
    "### Using the vector transformed to each subspace.\n",
    "Uses most_similar and try to approximate the word just one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd051d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate_most_similar_vector(word_list, origin_lang, intermediate_lang, target_lang):\n",
    "    '''\n",
    "    Translate one word from one language to another passing by an intermediate language.\n",
    "    In this function, we use the result of the vector of the translation passing by the intermediate language to make the next translation.\n",
    "\n",
    "    Params:\n",
    "    - word_list: list of example words.\n",
    "    - origin_lang: language in which the words in word_list are written\n",
    "    - intermediate_lang: intermediate language which translation between origin_lang and target_lang passes by\n",
    "    - target_lang: language you wish to know the translation\n",
    "\n",
    "    Example of usage:\n",
    "    intermediate_most_similar_vector(PT_WORD_LIST, 'es', 'pt', 'en')\n",
    "    '''\n",
    "    \n",
    "    for word in word_list:\n",
    "        print(f'Original word: {word}')\n",
    "\n",
    "        intermediate_vector = TRANSLATIONS[origin_lang][intermediate_lang] @ MODELS[origin_lang][word]\n",
    "        translated_vector = MODELS[target_lang].most_similar(TRANSLATIONS[intermediate_lang][target_lang] @ intermediate_vector)\n",
    "        \n",
    "        print(f'Top 10 most similar words in target language passing by the intermediate language: {translated_vector}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a173201",
   "metadata": {},
   "source": [
    "- Portuguese $\\rightarrow$ English $\\rightarrow$ Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a58ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_most_similar_vector(PT_WORD_LIST, 'pt', 'en', 'es')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbc0af35",
   "metadata": {},
   "source": [
    "- Spanish $\\rightarrow$ Portuguese $\\rightarrow$ English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2788b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_most_similar_vector(ES_WORD_LIST, 'es', 'pt', 'en')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3e0fd3f",
   "metadata": {},
   "source": [
    "- English $\\rightarrow$ Spanish $\\rightarrow$ Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9859e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_most_similar_vector(EN_WORD_LIST, 'en', 'es', 'pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f3cca3",
   "metadata": {},
   "source": [
    "## 5 - Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9a681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RIGHT_ARROW = '\\u2192'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460e30dd",
   "metadata": {},
   "source": [
    "Theorically speaking, translating the vector that one sentence represents to another should result in a similar sentence. For that purpose, we evaluate our results using the cosine similarity, which range is from -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78446c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_single_cosine_similarity(origin_lang, target_lang):\n",
    "    '''\n",
    "    Evaluate cosine similarity between single sentences.\n",
    "    Cosine similarity has an interval from -1 to 1, and the closer to 1 the value is, more similar the params are.\n",
    "\n",
    "    Params:\n",
    "    - origin_lang: language in which the words in word_list are written\n",
    "    - target_lang: language you wish to know the translation\n",
    "\n",
    "    Example of usage:\n",
    "    evaluate_single_cosine_similarity('pt', 'en')\n",
    "    '''\n",
    "    \n",
    "    for index in range(5):\n",
    "        print(f'{TEST_SET[origin_lang][index][0]} {RIGHT_ARROW} {TEST_SET[target_lang][index][0]}')\n",
    "\n",
    "        vector_translated = TRANSLATIONS[origin_lang][target_lang] @ TEST_SET[origin_lang][index][1]\n",
    "        vector_target = TEST_SET[target_lang][index][1]\n",
    "\n",
    "        print(f'Cossine similarity:  {cosine_similarity([vector_translated], [vector_target])[0][0]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb53fcd",
   "metadata": {},
   "source": [
    "- Portuguese -> English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7457740",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_single_cosine_similarity('pt', 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac78c26e",
   "metadata": {},
   "source": [
    "- Portuguese -> Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e394f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_single_cosine_similarity('pt', 'es')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a56e65",
   "metadata": {},
   "source": [
    "- English -> Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf664a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_single_cosine_similarity('en', 'es')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ad78e8",
   "metadata": {},
   "source": [
    "### Avaliating path\n",
    "We use the following metrics for that purpose:\n",
    "- Cosine similarity\n",
    "- Euclidean distance\n",
    "- Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc908230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    '''\n",
    "    Return successive overlapping pairs taken from the input iterable.\n",
    "    The number of 2-tuples in the output iterator will be one fewer than the number of inputs. \n",
    "    It will be empty if the input iterable has fewer than two values.\n",
    "    pairwise('ABCDEFG') --> AB BC CD DE EF FG\n",
    "\n",
    "    Source: https://docs.python.org/3/library/itertools.html#itertools.pairwise\n",
    "    '''\n",
    "    a, b = it.tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426214bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliate_path(path):\n",
    "    '''\n",
    "    Avaliate the translation path using cosine similarity, euclidean distance and manhattan distance.\n",
    "\n",
    "    Params:\n",
    "    - path: path of desired translation\n",
    "    \n",
    "    Return:\n",
    "    - Score of each avaliation method\n",
    "    \n",
    "    Example of usage:\n",
    "    avaliate_path(['pt', 'en', 'es'])\n",
    "    '''\n",
    "    \n",
    "    translation_matrix = np.identity(300)\n",
    "\n",
    "    for (origin, target) in pairwise(path):\n",
    "        translation_matrix = TRANSLATIONS[origin][target] @ translation_matrix\n",
    "    \n",
    "    vectors = [translation_matrix @ v for _, v in TEST_SET[path[0]] ]\n",
    "    vectors_target = [v for _, v in TEST_SET[path[-1]]]\n",
    "    \n",
    "    mean_cos_sim = sum([cosine_similarity([v1], [v2]) for v1, v2 in zip(vectors, vectors_target)])/ len(vectors)\n",
    "    mean_euc_dist = sum([euclidean_distances([v1], [v2]) for v1, v2 in zip(vectors, vectors_target)])/ len(vectors)\n",
    "    mean_man_dist = sum([manhattan_distances([v1], [v2]) for v1, v2 in zip(vectors, vectors_target)])/ len(vectors)\n",
    "    \n",
    "    return mean_cos_sim[0][0], mean_euc_dist[0][0], mean_man_dist[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4005bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliate_possible_paths(languages):\n",
    "    '''\n",
    "    Avaliate possible paths from first to last language on the list, changing the languages in the middle\n",
    "    \n",
    "    Params:\n",
    "    - languages: list of languages\n",
    "    \n",
    "    Return:\n",
    "    - Dataframe with the score of each path on cossine similarity, euclidean distance and manhattan distance\n",
    "    \n",
    "    Example of usage:\n",
    "    avaliate_paths(['pt', 'en', 'es'])\n",
    "    '''\n",
    "    \n",
    "    start = languages[0]\n",
    "    end = languages[-1]\n",
    "    paths = [[start, end]]\n",
    "    \n",
    "    for i in range(len(languages) - 2):\n",
    "        for comb in it.combinations(languages[1 : -1], i + 1):\n",
    "            paths.append([start] + list(comb) + [end])\n",
    "    \n",
    "    scores = [avaliate_path(p) for p in paths]\n",
    "    index = [RIGHT_ARROW.join(p) for p in paths]\n",
    "    \n",
    "    return pd.DataFrame(\n",
    "        data = scores, \n",
    "        columns = ['Cosine Similarity', 'Euclidean Distance', 'Manhattan Distance'], \n",
    "        index = index\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866007a0",
   "metadata": {},
   "source": [
    "## 6 - Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c8082",
   "metadata": {},
   "source": [
    "### Experiment #1: Portuguese - English - Spanish\n",
    "In this experiment, we intend to evaluate how good is a translation between two languages from the Latin group, such as Portuguese and Spanish, and if adding a language from an outer group, such as English from the West Germanic, affects the quality of the translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b908b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = avaliate_possible_paths(['pt', 'en', 'es'])\n",
    "EXPERIMENTS.append(exp1)\n",
    "exp1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf2bb3d",
   "metadata": {},
   "source": [
    "### Experiment #2: Portuguese - Spanish - French - Italian - Romanian\n",
    "In this experiment, we intend to evaluate translations between multiple languages from the same Latin group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa460b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp2 = avaliate_possible_paths(['pt', 'fr', 'it', 'ro', 'es'])\n",
    "EXPERIMENTS.append(exp2)\n",
    "exp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169d14de",
   "metadata": {},
   "source": [
    "> Adding a test with English in the middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b4164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ['pt', 'fr', 'it', 'en', 'ro', 'es']\n",
    "exp_df = pd.DataFrame(\n",
    "    data = [avaliate_path(path)], \n",
    "    index = [RIGHT_ARROW.join(path)], \n",
    "    columns = exp2.columns\n",
    ")\n",
    "\n",
    "exp21 = pd.concat([exp2, exp_df])\n",
    "EXPERIMENTS.append(exp21)\n",
    "exp21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e11951d",
   "metadata": {},
   "source": [
    "### Experiment #3: English - German - Swedish - Dutch - Danish\n",
    "In this experiment, we intend to evaluate translations between multiple languages from the same Germanic group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77458df",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp3 = avaliate_possible_paths(['en', 'sv', 'nl', 'da', 'de'])\n",
    "EXPERIMENTS.append(exp3)\n",
    "exp3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011f0d13",
   "metadata": {},
   "source": [
    "> Adding a test with Italian in the middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e4220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ['en', 'sv', 'it', 'nl', 'da', 'de']\n",
    "exp_df2 = pd.DataFrame(\n",
    "    data = [avaliate_path(path)], \n",
    "    index = [RIGHT_ARROW.join(path)], \n",
    "    columns = exp3.columns\n",
    ")\n",
    "\n",
    "exp31 = pd.concat([exp3, exp_df2])\n",
    "EXPERIMENTS.append(exp31)\n",
    "exp31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4304f41",
   "metadata": {},
   "source": [
    "### Experiment #4: Portuguese - German - French - English - Spanish\n",
    "In this experiment, we intend to evaluate translations using languages from different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddc0304",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp4 = avaliate_possible_paths(['pt', 'de', 'fr', 'en', 'es'])\n",
    "EXPERIMENTS.append(exp4)\n",
    "exp4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47926541",
   "metadata": {},
   "source": [
    "### Experiment #5: English - Spanish - Swedish - Italian - German\n",
    "In this experiment, we intend to evaluate translations using languages from different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d72124",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp5 = avaliate_possible_paths(['en', 'es', 'sv', 'it', 'de'])\n",
    "EXPERIMENTS.append(exp5)\n",
    "exp5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35631075",
   "metadata": {},
   "source": [
    "### Experiment #6: Ingles to Spanish through multiple languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a7d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp6 = avaliate_possible_paths(['en', 'pt', 'es'])\n",
    "EXPERIMENTS.append(exp6)\n",
    "exp6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832cff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp61 = avaliate_possible_paths(['en', 'de', 'es'])\n",
    "EXPERIMENTS.append(exp61)\n",
    "exp61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade77c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp62 = avaliate_possible_paths(['en', 'it', 'es'])\n",
    "EXPERIMENTS.append(exp62)\n",
    "exp62"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09768a36",
   "metadata": {},
   "source": [
    "### Saving results to spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149a99ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in EXPERIMENTS:\n",
    "    experiment.to_excel(f'Experiment results/Experiment {EXPERIMENTS.index(experiment) + 1}.xlsx')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
