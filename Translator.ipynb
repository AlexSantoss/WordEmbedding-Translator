{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "253770a5",
   "metadata": {},
   "source": [
    "# Word Embedding Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e015f1b",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7230eb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36ae151",
   "metadata": {},
   "source": [
    "## 1 - Loading data\n",
    "Loading the models and sentences used.\n",
    "- Models: https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "- Sentences: https://github.com/alexa/massive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f117e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(model_path, sentences_path, limit = None):\n",
    "    '''\n",
    "    Load models from FastText folder and sentences from Amazon Massive folder.\n",
    "    \n",
    "    Params:\n",
    "    - model_path: path to the folder containing all models used, i.e., FastText\n",
    "    - sentences_path: path to the folder containing all sentences used, i.e., Amazon_Massive\n",
    "    - limit: define a limit in case your have low computer power, e.g., 5000\n",
    "    \n",
    "    Return:\n",
    "    Tuple containing the language model and its corresponding sentences\n",
    "    '''\n",
    "\n",
    "    model = KeyedVectors.load_word2vec_format(model_path, unicode_errors = 'replace', limit = limit)\n",
    "    sentences = pd.read_json(sentences_path, lines = True)['utt']\n",
    "    \n",
    "    return model, sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab38a6d",
   "metadata": {},
   "source": [
    "Defining data path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "FASTTEXT_PATH = 'Datasets/FastText/'\n",
    "MASSIVE_PATH = 'Datasets/Amazon_Massive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553117db",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = {\n",
    "    'da': [ FASTTEXT_PATH + 'cc.da.300.vec', MASSIVE_PATH + 'da-DK.jsonl' ],\n",
    "    'de': [ FASTTEXT_PATH + 'cc.de.300.vec', MASSIVE_PATH + 'de-DE.jsonl' ],\n",
    "    'en': [ FASTTEXT_PATH + 'cc.en.300.vec', MASSIVE_PATH + 'en-US.jsonl' ],\n",
    "    'es': [ FASTTEXT_PATH + 'cc.es.300.vec', MASSIVE_PATH + 'es-ES.jsonl' ],\n",
    "    'fr': [ FASTTEXT_PATH + 'cc.fr.300.vec', MASSIVE_PATH + 'fr-FR.jsonl' ],\n",
    "    'it': [ FASTTEXT_PATH + 'cc.it.300.vec', MASSIVE_PATH + 'it-IT.jsonl' ],\n",
    "    'nl': [ FASTTEXT_PATH + 'cc.nl.300.vec', MASSIVE_PATH + 'nl-NL.jsonl' ],\n",
    "    'pt': [ FASTTEXT_PATH + 'cc.pt.300.vec', MASSIVE_PATH + 'pt-PT.jsonl' ],\n",
    "    'ro': [ FASTTEXT_PATH + 'cc.ro.300.vec', MASSIVE_PATH + 'ro-RO.jsonl' ],\n",
    "    'sv': [ FASTTEXT_PATH + 'cc.sv.300.vec', MASSIVE_PATH + 'sv-SE.jsonl' ],\n",
    "}\n",
    "\n",
    "LANGUAGES = PATHS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c564e517",
   "metadata": {},
   "source": [
    "**Note**: the cell below takes approximately 5 to 6 minutes per model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf0f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS, SENTENCES = {}, {}\n",
    "\n",
    "for language, value in PATHS.items():\n",
    "    model = value[0]\n",
    "    sentences = value[1]\n",
    "\n",
    "    print(\"Loading\", model)\n",
    "    MODELS[language], SENTENCES[language] = load_files(model, sentences)\n",
    "    print(\"Finished loading\", model)\n",
    "\n",
    "print(\"\\nAll models and sentences are now loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e14fb99",
   "metadata": {},
   "source": [
    "## 2 - Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bceeb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = { key: [] for key in LANGUAGES }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67d11b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since all sentence files have the same length, we chose one at random for the range function.\n",
    "# We prove this in the cell below\n",
    "for idx in range(len(SENTENCES['pt'])):\n",
    "    \n",
    "    actual_sentence = { key: [] for key in LANGUAGES}\n",
    "    \n",
    "    try:\n",
    "        for lang, sent in SENTENCES.items():\n",
    "            for word in sent[idx].split(' '):\n",
    "                actual_sentence[lang].append(MODELS[lang][word])\n",
    "\n",
    "    except KeyError:\n",
    "        continue\n",
    "    \n",
    "    for key, value in actual_sentence.items():\n",
    "        SAMPLES[key].append([SENTENCES[key][idx], sum(value)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d43f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in SENTENCES:\n",
    "    SIZE_SAMPLES = len(SAMPLES[key])\n",
    "    print(f'Total sentences in { key } file: { len(SENTENCES[key]) } -> Model { key } samples: { len(SAMPLES[key]) } ({ len(SAMPLES[key]) / len(SENTENCES[key]) * 100:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aefab70",
   "metadata": {},
   "source": [
    "Splitting into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fac669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_RATE = int(SIZE_SAMPLES * 0.7)\n",
    "\n",
    "TRAIN_SET = { key: SAMPLES[key][:SPLIT_RATE] for key in LANGUAGES }\n",
    "TEST_SET = { key: SAMPLES[key][SPLIT_RATE:] for key in LANGUAGES }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf7d5e4",
   "metadata": {},
   "source": [
    "## 3 - Translating words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711e3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSLATIONS = { key: { lang: None for lang in LANGUAGES if lang != key } for key in LANGUAGES }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5bc3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for origin, target in it.permutations(LANGUAGES, 2): \n",
    "\n",
    "    samples_origin = [sample[1] for sample in TRAIN_SET[origin]]\n",
    "    samples_target = [sample[1] for sample in TRAIN_SET[target]]\n",
    "\n",
    "    U, Sig, Vt = np.linalg.svd(np.transpose(samples_origin) @ samples_target)\n",
    "    \n",
    "    TRANSLATOR = np.transpose(Vt) @ np.transpose(U)\n",
    "    TRANSLATIONS[origin][target] = TRANSLATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4325e13",
   "metadata": {},
   "source": [
    "### List of examples words\n",
    "**Note**: only single words can be written, i.e., compound words like \"washing machine\" will result in Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed3f9c",
   "metadata": {},
   "source": [
    "- English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b75aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_WORD_LIST = [\n",
    "    'specification',\n",
    "    'book',\n",
    "    'duckling',\n",
    "    'machine',\n",
    "    'headphones'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04930bcf",
   "metadata": {},
   "source": [
    "- Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f14161",
   "metadata": {},
   "outputs": [],
   "source": [
    "ES_WORD_LIST = [\n",
    "    'hola',\n",
    "    'sí',\n",
    "    'computadora',\n",
    "    'país'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9107823",
   "metadata": {},
   "source": [
    "- Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed70d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_WORD_LIST = [\n",
    "    'sapato',\n",
    "    'flor',\n",
    "    'aniversário',\n",
    "    'saudades',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad3f141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(word_list, origin_lang, target_lang):\n",
    "    '''\n",
    "    Function to translate one word from one language to another.\n",
    "\n",
    "    Params:\n",
    "    - word_list: list of example words.\n",
    "    - origin_lang: language in which the words in word_list are written\n",
    "    - target_lang: language you wish to know the translation\n",
    "\n",
    "    Example of usage:\n",
    "    translate(PT_WORD_LIST, 'es', 'pt')\n",
    "    '''\n",
    "    \n",
    "    for word in word_list:\n",
    "        print(\"Original word:\", word)\n",
    "        print(\"Top 10 most similar words in\", target_lang)\n",
    "        print(MODELS[target_lang].most_similar(TRANSLATIONS[origin_lang][target_lang] @ MODELS[origin_lang][word]))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18fa53d",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ff3272",
   "metadata": {},
   "source": [
    "- Portuguese -> Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c2d369",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(PT_WORD_LIST, 'pt', 'es')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a05a8",
   "metadata": {},
   "source": [
    "- Portuguese -> English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0777db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(PT_WORD_LIST, 'pt', 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f82e71",
   "metadata": {},
   "source": [
    "- Spanish -> English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c980d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(ES_WORD_LIST, 'es', 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6b2270",
   "metadata": {},
   "source": [
    "- English -> Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3dc7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(EN_WORD_LIST, 'en', 'pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e534a",
   "metadata": {},
   "source": [
    "## 4 - Translating words using intermediate languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba21e7c",
   "metadata": {},
   "source": [
    "### Getting the most similar word in each language it pass.\n",
    "Most expensive (uses most_similar multiple times) and try to aproximate a word each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0596b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate_most_similar_word(word_list, origin_lang, intermediate_lang, target_lang):\n",
    "    '''\n",
    "    Translate one word from one language to another passing by an intermediate language.\n",
    "    In this function, we use the result of the most similar word of the intermediate language to make the next translation.\n",
    "\n",
    "    Params:\n",
    "    - word_list: list of example words.\n",
    "    - origin_lang: language in which the words in word_list are written\n",
    "    - intermediate_lang: intermediate language which translation between origin_lang and target_lang passes by\n",
    "    - target_lang: language you wish to know the translation\n",
    "\n",
    "    Example of usage:\n",
    "    intermediate_most_similar_word(PT_WORD_LIST, 'es', 'pt', 'en')\n",
    "    '''\n",
    "    \n",
    "    for word in word_list:\n",
    "        print(\"Original word:\", word)\n",
    "        \n",
    "        intermediate_word = MODELS[intermediate_lang].most_similar(TRANSLATIONS[origin_lang][intermediate_lang] @ MODELS[origin_lang][word])[0][0]\n",
    "        print(\"Most similar word according to intermediate language:\", intermediate_word)\n",
    "\n",
    "        translated_language = MODELS[target_lang].most_similar(TRANSLATIONS[intermediate_lang][target_lang] @ MODELS[intermediate_lang][intermediate_word])\n",
    "        print(\"Top 10 most similar words in target language passing by the intermediate language:\")\n",
    "        print(translated_language)\n",
    "        \n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f3c6e",
   "metadata": {},
   "source": [
    "- Portuguese -> English -> Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c8b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_most_similar_word(PT_WORD_LIST, 'pt', 'en', 'es')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74244ca1",
   "metadata": {},
   "source": [
    "- Spanish -> Portuguese -> English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0073786",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_most_similar_word(ES_WORD_LIST, 'es', 'pt', 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9842db97",
   "metadata": {},
   "source": [
    "- English -> Spanish -> Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc536b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_most_similar_word(EN_WORD_LIST, 'en', 'es', 'pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340e25f7",
   "metadata": {},
   "source": [
    "### Using the vector transformed to each subspace.\n",
    "Uses most_similar and try to approximate the word just one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd051d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate_most_similar_vector(word_list, origin_lang, intermediate_lang, target_lang):\n",
    "    '''\n",
    "    Translate one word from one language to another passing by an intermediate language.\n",
    "    In this function, we use the result of the vector of the translation passing by the intermediate language to make the next translation.\n",
    "\n",
    "    Params:\n",
    "    - word_list: list of example words.\n",
    "    - origin_lang: language in which the words in word_list are written\n",
    "    - intermediate_lang: intermediate language which translation between origin_lang and target_lang passes by\n",
    "    - target_lang: language you wish to know the translation\n",
    "\n",
    "    Example of usage:\n",
    "    intermediate_most_similar_vector(PT_WORD_LIST, 'es', 'pt', 'en')\n",
    "    '''\n",
    "    \n",
    "    for word in word_list:\n",
    "        print(\"Original word:\", word)\n",
    "\n",
    "        intermediate_vector = TRANSLATIONS[origin_lang][intermediate_lang] @ MODELS[origin_lang][word]\n",
    "        translated_vector = MODELS[target_lang].most_similar(TRANSLATIONS[intermediate_lang][target_lang] @ intermediate_vector)\n",
    "        \n",
    "        print(\"Top 10 most similar words in target language passing by the intermediate language:\")\n",
    "        print(translated_vector)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a173201",
   "metadata": {},
   "source": [
    "- Portuguese -> English -> Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a58ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_most_similar_vector(PT_WORD_LIST, 'pt', 'en', 'es')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc0af35",
   "metadata": {},
   "source": [
    "- Spanish -> Portuguese -> English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2788b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_most_similar_vector(ES_WORD_LIST, 'es', 'pt', 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e0fd3f",
   "metadata": {},
   "source": [
    "- English -> Spanish -> Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9859e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_most_similar_vector(EN_WORD_LIST, 'en', 'es', 'pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f3cca3",
   "metadata": {},
   "source": [
    "## 5 - Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460e30dd",
   "metadata": {},
   "source": [
    "Theorically speaking, translating the vector that one sentence represents to another should result in a similar sentence. For that purpose, we evaluate our results using the cosine similarity, which range is from -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78446c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_single_cosine_similarity(origin_lang, target_lang):\n",
    "    '''\n",
    "    Evaluate cosine similarity between single sentences.\n",
    "    Cosine similarity has an interval from -1 to 1, and the closer to 1 the value is, more similar the params are.\n",
    "\n",
    "    Params:\n",
    "    - origin_lang: language in which the words in word_list are written\n",
    "    - target_lang: language you wish to know the translation\n",
    "\n",
    "    Example of usage:\n",
    "    evaluate_single_cosine_similarity('pt', 'en')\n",
    "    '''\n",
    "    \n",
    "    for index in range(5):\n",
    "        print(TEST_SET[origin_lang][index][0], '->', TEST_SET[target_lang][index][0])\n",
    "\n",
    "        vector_translated = TRANSLATIONS[origin_lang][target_lang] @ TEST_SET[origin_lang][index][1]\n",
    "        vector_target = TEST_SET[target_lang][index][1]\n",
    "\n",
    "        print(\"Cossine similarity:\", cosine_similarity([vector_translated], [vector_target])[0][0], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb53fcd",
   "metadata": {},
   "source": [
    "- Portuguese -> English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7457740",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_single_cosine_similarity('pt', 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac78c26e",
   "metadata": {},
   "source": [
    "- Portuguese -> Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e394f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_single_cosine_similarity('pt', 'es')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a56e65",
   "metadata": {},
   "source": [
    "- English -> Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf664a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_single_cosine_similarity('en', 'es')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ad78e8",
   "metadata": {},
   "source": [
    "### Avaliating path\n",
    "We use the following metrics for that purpose:\n",
    "- Cosine similarity\n",
    "- Euclidean distance\n",
    "- Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc908230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    '''\n",
    "    Return successive overlapping pairs taken from the input iterable.\n",
    "    The number of 2-tuples in the output iterator will be one fewer than the number of inputs. \n",
    "    It will be empty if the input iterable has fewer than two values.\n",
    "    pairwise('ABCDEFG') --> AB BC CD DE EF FG\n",
    "\n",
    "    Source: https://docs.python.org/3/library/itertools.html#itertools.pairwise\n",
    "    '''\n",
    "    a, b = it.tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426214bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliate_path(path):\n",
    "    '''\n",
    "    Avaliate cosine similarity of translation path.\n",
    "\n",
    "    Params:\n",
    "    - path: path of desired translation\n",
    "\n",
    "    Example of usage:\n",
    "    avaliate_path(['pt', 'en', 'es'])\n",
    "    '''\n",
    "\n",
    "    translation_matrix = np.identity(300)\n",
    "\n",
    "    for (origin, target) in pairwise(path):\n",
    "        translation_matrix = TRANSLATIONS[origin][target] @ translation_matrix\n",
    "    \n",
    "    vectors = [translation_matrix @ v for _, v in TEST_SET[path[0]] ]\n",
    "    vectors_target = [v for _, v in TEST_SET[path[-1]]]\n",
    "    \n",
    "    mean_cos_sim = sum([cosine_similarity([v1], [v2]) for v1, v2 in zip(vectors, vectors_target)])/ len(vectors)\n",
    "    print(\"Average cosine similarity of path\", path, \"=\", round(mean_cos_sim[0][0], 5))\n",
    "\n",
    "    mean_euc_dist = sum([euclidean_distances([v1], [v2]) for v1, v2 in zip(vectors, vectors_target)])/ len(vectors)\n",
    "    print(\"Average Euclidean distance of path\", path, \"=\", round(mean_euc_dist[0][0], 5))\n",
    "\n",
    "    mean_man_dist = sum([manhattan_distances([v1], [v2]) for v1, v2 in zip(vectors, vectors_target)])/ len(vectors)\n",
    "    print(\"Average Manhattan distance of path\", path, \"=\", round(mean_man_dist[0][0], 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866007a0",
   "metadata": {},
   "source": [
    "## 6 - Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c8082",
   "metadata": {},
   "source": [
    "### Experiment #1: English - Portuguese - Spanish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4bdfd6",
   "metadata": {},
   "source": [
    "- Portuguese -> Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9893a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliate_path(['pt', 'es'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c2eb10",
   "metadata": {},
   "source": [
    "- Portuguese -> English -> Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliate_path(['pt', 'en', 'es'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ce2876",
   "metadata": {},
   "source": [
    "- Spanish -> English -> Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2801c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliate_path(['es', 'en', 'pt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8d91ea",
   "metadata": {},
   "source": [
    "- Portuguese -> English -> Portuguese -> English -> Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4920a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliate_path(['pt', 'en', 'pt', 'en', 'es'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf2bb3d",
   "metadata": {},
   "source": [
    "### Experiment #2: Portuguese - Spanish - French - Italian - Romanian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b61238a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e11951d",
   "metadata": {},
   "source": [
    "### Experiment #3: English - German - Swedish - Dutch - Danish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef84a2eb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
