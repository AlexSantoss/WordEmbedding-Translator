{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7230eb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36ae151",
   "metadata": {},
   "source": [
    "# 1-Loading Things\n",
    "Loading the models, sentences and analogies used.\n",
    "Models: https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "Sentences: https://github.com/alexa/massive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "553117db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to models\n",
    "model_path_pt = 'datasets/cc.pt.300.vec'\n",
    "model_path_en = 'datasets/cc.en.300.vec'\n",
    "\n",
    "#Loading models\n",
    "model_pt = KeyedVectors.load_word2vec_format(model_path_pt, unicode_errors='replace')\n",
    "model_en = KeyedVectors.load_word2vec_format(model_path_en, unicode_errors='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f165bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to sentences\n",
    "sentences_path_pt = 'datasets/1.0/data/pt-PT.jsonl'\n",
    "sentences_path_en = 'datasets/1.0/data/en-US.jsonl'\n",
    "\n",
    "#Loading sentences\n",
    "sentences_pt = pd.read_json(sentences_path_pt, lines = True)['utt']\n",
    "sentences_en = pd.read_json(sentences_path_en, lines = True)['utt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e14fb99",
   "metadata": {},
   "source": [
    "# 2-Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab0dd1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'16521 -> 15378 (93.08%)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_pt = []\n",
    "matrix_en = [] \n",
    "for (s_pt, s_en) in zip(sentences_pt, sentences_en):\n",
    "    tot_pt = []\n",
    "    tot_en = []\n",
    "    try:\n",
    "        for w in s_pt.split(' '):\n",
    "            tot_pt.append(model_pt[w])\n",
    "        for w in s_en.split(' '):\n",
    "            tot_en.append(model_en[w])\n",
    "    except KeyError:\n",
    "        continue\n",
    "    matrix_pt.append(sum(tot_pt))\n",
    "    matrix_en.append(sum(tot_en))\n",
    "    \n",
    "f'{len(sentences_pt)} -> {len(matrix_pt)} ({len(matrix_pt)/len(sentences_pt)*100:.2f}%)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf7d5e4",
   "metadata": {},
   "source": [
    "# 3-Making the translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df5bc3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the translator matrix\n",
    "A = matrix_pt\n",
    "B = matrix_en\n",
    "\n",
    "U, Sig, Vt = np.linalg.svd(np.transpose(A)@B)\n",
    "translator = np.transpose(Vt) @ np.transpose(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df51c77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shoes', 0.5022848844528198),\n",
       " ('shoe', 0.4925771951675415),\n",
       " ('shoes.', 0.469224750995636),\n",
       " ('handbag', 0.4686202108860016),\n",
       " ('high-heels', 0.42868536710739136),\n",
       " ('shoes.It', 0.4274202585220337),\n",
       " ('shoes.I', 0.42516860365867615),\n",
       " ('wear', 0.4195747971534729),\n",
       " ('stilettos', 0.41740575432777405),\n",
       " ('dress', 0.41310709714889526)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en.most_similar(translator @ model_pt['sapato'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab64bff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('não', 0.4933251738548279),\n",
       " ('Não', 0.4648018181324005),\n",
       " ('nem', 0.4586043357849121),\n",
       " ('.Não', 0.42639946937561035),\n",
       " ('consigo.Não', 0.4222370386123657),\n",
       " ('ainda.Não', 0.42222297191619873),\n",
       " ('queria.Não', 0.42034509778022766),\n",
       " ('5.Não', 0.4118790626525879),\n",
       " ('9.Não', 0.4051348865032196),\n",
       " ('aí.Não', 0.4007856249809265)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pt.most_similar(translator.T @ model_en[\"can't\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e534a",
   "metadata": {},
   "source": [
    "# 4-Evaluate *future work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c08d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69d7b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avalia(modelo, analogias, tradutor = None, modelo_o = None):\n",
    "    tradutor = np.identity(len(modelo[0])) if tradutor is None else tradutor\n",
    "    modelo_o = modelo if modelo_o is None else modelo_o\n",
    "    results = {}\n",
    "    \n",
    "    for k in analogias:\n",
    "        hits, error = 0, 0\n",
    "        for an in analogias[k]:\n",
    "            try:\n",
    "                a = modelo_o.get_vector(an[0], norm = True)\n",
    "                b = modelo_o.get_vector(an[1], norm = True)\n",
    "                c = modelo_o.get_vector(an[2], norm = True)\n",
    "            except KeyError:\n",
    "                error += 1\n",
    "            else:\n",
    "                    for r in modelo.most_similar([tradutor @ (b - a + c)], topn = 4):\n",
    "                        if r[0] in an[:3]: continue\n",
    "                        if r[0] == an[3]: hits += 1\n",
    "                        break\n",
    "        results[k] = hits/(len(analogias_en[k]) - error)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77632729",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict([br1, br2, br1_br2, br2_br1], orient='index', columns=['Glove', 'W2V', 'Glove->W2V', 'W2V->Glove'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
