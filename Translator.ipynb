{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "253770a5",
   "metadata": {},
   "source": [
    "# Translation of short phrases using an intermediate language:\n",
    "## A thesis on leveraging interlingual approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e015f1b",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7230eb8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from nltk.translate.bleu_score import SmoothingFunction, corpus_bleu, sentence_bleu #pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a7864a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7165313105737893"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = [\"estou fazendo um teste\".split()]\n",
    "frase = \"fazendo um teste\".split()\n",
    "cc = SmoothingFunction() #https://github.com/alvations/nltk/blob/develop/nltk/translate/bleu_score.py#L425\n",
    "sentence_bleu(ref, frase, weights = (0, 1, 0), smoothing_function = cc.method4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36ae151",
   "metadata": {},
   "source": [
    "## 1 - Loading data\n",
    "Loading the models and sentences used.\n",
    "- Models: https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "- Sentences: https://github.com/alexa/massive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f117e715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_files(model_path, sentences_path, limit = None):\n",
    "    '''\n",
    "    Load models from FastText folder and sentences from Amazon Massive folder.\n",
    "    \n",
    "    Params:\n",
    "    - model_path: path to the folder containing all models used, i.e., FastText\n",
    "    - sentences_path: path to the folder containing all sentences used, i.e., Amazon_Massive\n",
    "    - limit: define a limit in case your have low computer power, e.g., 5000\n",
    "    \n",
    "    Return:\n",
    "    Tuple containing the language model and its corresponding sentences\n",
    "    '''\n",
    "\n",
    "    model = KeyedVectors.load_word2vec_format(model_path, unicode_errors = 'replace', limit = limit)\n",
    "    sentences = pd.read_json(sentences_path, lines = True)['utt']\n",
    "    \n",
    "    return model, sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab38a6d",
   "metadata": {},
   "source": [
    "Defining data path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4f7b818",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FASTTEXT_PATH = 'Datasets/FastText/'\n",
    "MASSIVE_PATH = 'Datasets/Amazon_Massive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "553117db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATHS = {\n",
    "    'de': [ FASTTEXT_PATH + 'cc.de.300.vec', MASSIVE_PATH + 'de-DE.jsonl' ],\n",
    "    'en': [ FASTTEXT_PATH + 'cc.en.300.vec', MASSIVE_PATH + 'en-US.jsonl' ],\n",
    "    'es': [ FASTTEXT_PATH + 'cc.es.300.vec', MASSIVE_PATH + 'es-ES.jsonl' ],\n",
    "    'it': [ FASTTEXT_PATH + 'cc.it.300.vec', MASSIVE_PATH + 'it-IT.jsonl' ],\n",
    "    'pt': [ FASTTEXT_PATH + 'cc.pt.300.vec', MASSIVE_PATH + 'pt-PT.jsonl' ],\n",
    "    'sv': [ FASTTEXT_PATH + 'cc.sv.300.vec', MASSIVE_PATH + 'sv-SE.jsonl' ],\n",
    "}\n",
    "\n",
    "LANGUAGES = PATHS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c564e517",
   "metadata": {},
   "source": [
    "**Note**: the cell below takes approximately 5 to 7 minutes per model, if no limit is set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08bf0f8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Datasets/FastText/cc.de.300.vec...\n",
      "Finished loading Datasets/FastText/cc.de.300.vec\n",
      "\n",
      "Loading Datasets/FastText/cc.en.300.vec...\n",
      "Finished loading Datasets/FastText/cc.en.300.vec\n",
      "\n",
      "Loading Datasets/FastText/cc.es.300.vec...\n",
      "Finished loading Datasets/FastText/cc.es.300.vec\n",
      "\n",
      "Loading Datasets/FastText/cc.it.300.vec...\n",
      "Finished loading Datasets/FastText/cc.it.300.vec\n",
      "\n",
      "Loading Datasets/FastText/cc.pt.300.vec...\n",
      "Finished loading Datasets/FastText/cc.pt.300.vec\n",
      "\n",
      "Loading Datasets/FastText/cc.sv.300.vec...\n",
      "Finished loading Datasets/FastText/cc.sv.300.vec\n",
      "\n",
      "\n",
      "All models and sentences are now loaded!\n"
     ]
    }
   ],
   "source": [
    "MODELS, SENTENCES = {}, {}\n",
    "\n",
    "for language, value in PATHS.items():\n",
    "    model = value[0]\n",
    "    sentences = value[1]\n",
    "\n",
    "    print(f'Loading {model}...')\n",
    "    MODELS[language], SENTENCES[language] = load_files(model, sentences)\n",
    "    print(f'Finished loading {model}\\n')\n",
    "\n",
    "print('\\nAll models and sentences are now loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e14fb99",
   "metadata": {},
   "source": [
    "## 2 - Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bceeb1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAMPLES = { key: [] for key in LANGUAGES }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e67d11b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Since all sentence files have the same length, we chose one at random for the range function.\n",
    "# We prove this in the cell below\n",
    "for idx in range(len(SENTENCES['pt'])):\n",
    "    \n",
    "    actual_sentence = { key: [] for key in LANGUAGES }\n",
    "    \n",
    "    try:\n",
    "        for lang, sent in SENTENCES.items():\n",
    "            for word in sent[idx].split(' '):\n",
    "                actual_sentence[lang].append(MODELS[lang][word])\n",
    "\n",
    "    except KeyError:\n",
    "        continue\n",
    "    \n",
    "    for key, value in actual_sentence.items():\n",
    "        SAMPLES[key].append([SENTENCES[key][idx], sum(value)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5d43f97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in de file: 16521 -> Model de samples: 10941 (66.22%)\n",
      "Total sentences in en file: 16521 -> Model en samples: 10941 (66.22%)\n",
      "Total sentences in es file: 16521 -> Model es samples: 10941 (66.22%)\n",
      "Total sentences in it file: 16521 -> Model it samples: 10941 (66.22%)\n",
      "Total sentences in pt file: 16521 -> Model pt samples: 10941 (66.22%)\n",
      "Total sentences in sv file: 16521 -> Model sv samples: 10941 (66.22%)\n"
     ]
    }
   ],
   "source": [
    "for key in SENTENCES:\n",
    "    SIZE_SAMPLES = len(SAMPLES[key])\n",
    "    SIZE_SENTENCES = len(SENTENCES[key])\n",
    "    print(\n",
    "        f'Total sentences in { key } file: { SIZE_SENTENCES }'\n",
    "        f' -> Model { key } samples: { SIZE_SAMPLES } ({ SIZE_SAMPLES / SIZE_SENTENCES * 100:.2f}%)'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aefab70",
   "metadata": {},
   "source": [
    "Splitting into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fac669b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPLIT_RATE = int(SIZE_SAMPLES * 0.7)\n",
    "\n",
    "TRAIN_SET = { key: SAMPLES[key][:SPLIT_RATE] for key in LANGUAGES }\n",
    "TEST_SET = { key: SAMPLES[key][SPLIT_RATE:] for key in LANGUAGES }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f3cca3",
   "metadata": {},
   "source": [
    "## 3 - Evaluating Control Group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460e30dd",
   "metadata": {},
   "source": [
    "Theorically speaking, translating the vector that one sentence represents to another should result in a similar sentence. For that purpose, we evaluate our results using the cosine similarity, which range is from -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d475860e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRANSLATIONS = { key: { lang: None for lang in LANGUAGES if lang != key } for key in LANGUAGES }\n",
    "\n",
    "for origin, target in it.permutations(LANGUAGES, 2): \n",
    "\n",
    "    samples_origin = [sample[1] for sample in TRAIN_SET[origin]]\n",
    "    samples_target = [sample[1] for sample in TRAIN_SET[target]]\n",
    "\n",
    "    U, Sig, Vt = np.linalg.svd(np.transpose(samples_origin) @ samples_target)\n",
    "    \n",
    "    TRANSLATOR = np.transpose(Vt) @ np.transpose(U)\n",
    "    TRANSLATIONS[origin][target] = TRANSLATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78446c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_single_cosine_similarity(origin_lang, target_lang):\n",
    "    '''\n",
    "    Evaluate cosine similarity between single sentences.\n",
    "    Cosine similarity has an interval from -1 to 1, and the closer to 1 the value is, more similar the params are.\n",
    "\n",
    "    Params:\n",
    "    - origin_lang: language in which the words in word_list are written\n",
    "    - target_lang: language you wish to know the translation\n",
    "\n",
    "    Example of usage:\n",
    "    evaluate_single_cosine_similarity('pt', 'en')\n",
    "    '''\n",
    "    cc = SmoothingFunction()\n",
    "    for index in range(10):\n",
    "        print('Original sentence:', TEST_SET[origin_lang][index][0])\n",
    "        print('Target sentence:', TEST_SET[target_lang][index][0])\n",
    "\n",
    "        vector_translated = TRANSLATIONS[origin_lang][target_lang] @ TEST_SET[origin_lang][index][1]\n",
    "        vector_target = TEST_SET[target_lang][index][1]\n",
    "        \n",
    "        vectors = [v for s, v in SAMPLES[target_lang]]\n",
    "        strings = [s for s, v in SAMPLES[target_lang]]\n",
    "        most_similar = max(zip(cosine_similarity([vector_translated], vectors)[0], strings))\n",
    "        print('Generated sentence:', most_similar[1])\n",
    "        \n",
    "        BLEU_score = sentence_bleu([TEST_SET[target_lang][index][0].split()], most_similar[1].split(), weights=(1, 0, 0, 0), smoothing_function=cc.method4)\n",
    "        print('BLEU score:', BLEU_score)\n",
    "        \n",
    "        print('Cossine similarity to generated:', most_similar[0])\n",
    "        print(\"Cossine similarity to target:\", cosine_similarity([vector_translated], [vector_target])[0][0], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb53fcd",
   "metadata": {},
   "source": [
    "### Portuguese -> Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2bef2f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.       , 0.931034 , 0.6409205], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = [v for s, v in SAMPLES['pt']][:3]\n",
    "padrao = teste[0]\n",
    "cosine_similarity([padrao], teste)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7457740",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: continua para o próximo podcast\n",
      "Target sentence: continuar con el siguiente podcast\n",
      "Generated sentence: iniciar el próximo podcast\n",
      "BLEU score: 0.38940039153570244\n",
      "Cossine similarity to generated: 0.88823247\n",
      "Cossine similarity to target: 0.8825095 \n",
      "\n",
      "Original sentence: começa o próximo episódio do podcast\n",
      "Target sentence: empieza el siguiente episodio del podcast\n",
      "Generated sentence: comienza el siguiente episodio del podcast\n",
      "BLEU score: 0.8333333333333334\n",
      "Cossine similarity to generated: 0.9409791\n",
      "Cossine similarity to target: 0.9405708 \n",
      "\n",
      "Original sentence: reproduz o meu podcast favorito por favor\n",
      "Target sentence: pon mi podcast favorito por favor\n",
      "Generated sentence: por favor modifique mi calendario con este evento\n",
      "BLEU score: 0.375\n",
      "Cossine similarity to generated: 0.88078916\n",
      "Cossine similarity to target: 0.8463628 \n",
      "\n",
      "Original sentence: inicia o podcast esta semana para o jantar\n",
      "Target sentence: comienza esta semana para cenar el podcast\n",
      "Generated sentence: comienza esta semana para cenar el podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.9048376\n",
      "Cossine similarity to target: 0.90483767 \n",
      "\n",
      "Original sentence: reproduz o podcast de hoje\n",
      "Target sentence: pon el podcast de hoy del\n",
      "Generated sentence: obtener el tiempo de hoy\n",
      "BLEU score: 0.49123845184678916\n",
      "Cossine similarity to generated: 0.9192024\n",
      "Cossine similarity to target: 0.88036007 \n",
      "\n",
      "Original sentence: põe o próximo podcast\n",
      "Target sentence: reproducir el próximo podcast\n",
      "Generated sentence: pon el siguiente podcast\n",
      "BLEU score: 0.5\n",
      "Cossine similarity to generated: 0.9058681\n",
      "Cossine similarity to target: 0.8047818 \n",
      "\n",
      "Original sentence: reproduz o podcast anterior\n",
      "Target sentence: pon el podcast anterior\n",
      "Generated sentence: reproducir el siguiente podcast\n",
      "BLEU score: 0.5\n",
      "Cossine similarity to generated: 0.90049094\n",
      "Cossine similarity to target: 0.8072641 \n",
      "\n",
      "Original sentence: toque episódio de lista de coisas que você devia saber\n",
      "Target sentence: pon el episodio de ted en español en cola\n",
      "Generated sentence: que notificaciones de correo tengo\n",
      "BLEU score: 0.08986579282344431\n",
      "Cossine similarity to generated: 0.84167963\n",
      "Cossine similarity to target: 0.5980269 \n",
      "\n",
      "Original sentence: põe um podcast\n",
      "Target sentence: pon un podcast\n",
      "Generated sentence: pon un podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.9336146\n",
      "Cossine similarity to target: 0.9336146 \n",
      "\n",
      "Original sentence: salta para o próximo episódio deste podcast\n",
      "Target sentence: salta hacia el siguiente episodio de este podcast\n",
      "Generated sentence: empieza el siguiente episodio del podcast\n",
      "BLEU score: 0.47768754038252614\n",
      "Cossine similarity to generated: 0.8756571\n",
      "Cossine similarity to target: 0.8660348 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_single_cosine_similarity('pt', 'es')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac78c26e",
   "metadata": {},
   "source": [
    "### English -> German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7e394f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: continue to next podcast\n",
      "Target sentence: fahre mit dem nächsten podcast fort\n",
      "Generated sentence: beginn die nächste episode zu spielen\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.851653\n",
      "Cossine similarity to target: 0.6785552 \n",
      "\n",
      "Original sentence: start next podcast episode\n",
      "Target sentence: starte die nächste folge des podcasts\n",
      "Generated sentence: folgende podcast episode starten\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.715421\n",
      "Cossine similarity to target: 0.6182311 \n",
      "\n",
      "Original sentence: play my favorite podcast please\n",
      "Target sentence: spiel bitte meinen lieblings podcast\n",
      "Generated sentence: spiel bitte meinen lieblings podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.8784077\n",
      "Cossine similarity to target: 0.8784077 \n",
      "\n",
      "Original sentence: start this week for dinner podcast\n",
      "Target sentence: starte den this week for dinner podcast\n",
      "Generated sentence: zeitplan für diese woche\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.805292\n",
      "Cossine similarity to target: 0.53795874 \n",
      "\n",
      "Original sentence: play today's podcast from the mi\n",
      "Target sentence: spielen die heutige podcast von die mi\n",
      "Generated sentence: spielen die heutige podcast von die mi\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.6144086\n",
      "Cossine similarity to target: 0.6144086 \n",
      "\n",
      "Original sentence: play the next podcast\n",
      "Target sentence: spiel den nächsten podcast\n",
      "Generated sentence: spiel die nächste episode vom podcast\n",
      "BLEU score: 0.3333333333333333\n",
      "Cossine similarity to generated: 0.83820575\n",
      "Cossine similarity to target: 0.7682682 \n",
      "\n",
      "Original sentence: play the previous podcast\n",
      "Target sentence: spiel den letzten podcast\n",
      "Generated sentence: spiel die nächste episode vom podcast\n",
      "BLEU score: 0.3333333333333333\n",
      "Cossine similarity to generated: 0.83465517\n",
      "Cossine similarity to target: 0.7833324 \n",
      "\n",
      "Original sentence: play episode of stuff you should know in queue\n",
      "Target sentence: spielen folge auf sachen die sie in der warteschlange kennen sollten\n",
      "Generated sentence: wie sind die titel der listen in kontakten\n",
      "BLEU score: 0.2577334795466146\n",
      "Cossine similarity to generated: 0.8705561\n",
      "Cossine similarity to target: 0.8626804 \n",
      "\n",
      "Original sentence: play a podcast\n",
      "Target sentence: spiel einen podcast\n",
      "Generated sentence: stell eine playlist mit dänischer musik ein\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.8286656\n",
      "Cossine similarity to target: 0.7288231 \n",
      "\n",
      "Original sentence: skip forward to the next episode of this podcast\n",
      "Target sentence: springe zur nächsten folge vom podcast\n",
      "Generated sentence: starte bitte die nächste episode des podcasts\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.869973\n",
      "Cossine similarity to target: 0.784319 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_single_cosine_similarity('en', 'de')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ad78e8",
   "metadata": {},
   "source": [
    "### Avaliating path\n",
    "We use the following metrics for that purpose:\n",
    "- Cosine similarity\n",
    "- Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc908230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    '''\n",
    "    Return successive overlapping pairs taken from the input iterable.\n",
    "    The number of 2-tuples in the output iterator will be one fewer than the number of inputs. \n",
    "    It will be empty if the input iterable has fewer than two values.\n",
    "    pairwise('ABCDEFG') --> AB BC CD DE EF FG\n",
    "\n",
    "    Source: https://docs.python.org/3/library/itertools.html#itertools.pairwise\n",
    "    '''\n",
    "    a, b = it.tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "426214bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def avaliate_path(path, debug = True):\n",
    "    '''\n",
    "    Avaliate the translation path using cosine similarity, euclidean distance.\n",
    "\n",
    "    Params:\n",
    "    - path: path of desired translation\n",
    "    \n",
    "    Return:\n",
    "    - Score of each avaliation method\n",
    "    \n",
    "    Example of usage:\n",
    "    avaliate_path(['pt', 'en', 'es'])\n",
    "    '''\n",
    "    \n",
    "    translation_matrix = np.identity(300)\n",
    "\n",
    "    for (origin, target) in pairwise(path):\n",
    "        translation_matrix = TRANSLATIONS[origin][target] @ translation_matrix\n",
    "        if debug:\n",
    "            evaluate_single_cosine_similarity(origin, target)\n",
    "    \n",
    "    vectors = [translation_matrix @ v for _, v in TEST_SET[path[0]] ]\n",
    "    vectors_target = [v for _, v in TEST_SET[path[-1]]]\n",
    "    \n",
    "    mean_cos_sim = sum([cosine_similarity([v1], [v2]) for v1, v2 in zip(vectors, vectors_target)])/ len(vectors)\n",
    "    mean_euc_dist = sum([euclidean_distances([v1], [v2]) for v1, v2 in zip(vectors, vectors_target)])/ len(vectors)\n",
    "    \n",
    "    mean_bleu_score = 0\n",
    "    for i, (vo, vt) in enumerate( zip(vectors, vectors_target) ):\n",
    "        target_lang = path[-1]\n",
    "        \n",
    "        all_vectors = [v for s, v in SAMPLES[target_lang]]\n",
    "        all_strings = [s for s, v in SAMPLES[target_lang]]\n",
    "        generated_sentence = max(zip(cosine_similarity([vo], all_vectors)[0], all_strings))[1]\n",
    "        \n",
    "        original_sentence = TEST_SET[path[0]][i][0]\n",
    "        target_sentence = TEST_SET[path[-1]][i][0]\n",
    "        mean_bleu_score += sentence_bleu([target_sentence.split()], generated_sentence.split(), weights=(1, 0, 0, 0), smoothing_function=cc.method4)\n",
    "        \n",
    "        # print(original_sentence, [target_sentence.split()], generated_sentence, bleu_score, sep='|')\n",
    "    \n",
    "    return mean_cos_sim[0][0], mean_euc_dist[0][0], mean_bleu_score/len(vectors)\n",
    "    # return mean_cos_sim[0][0], mean_euc_dist[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4005bbfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def avaliate_possible_paths(languages):\n",
    "    '''\n",
    "    Avaliate possible paths from first to last language on the list, changing the languages in the middle\n",
    "    \n",
    "    Params:\n",
    "    - languages: list of languages\n",
    "    \n",
    "    Return:\n",
    "    - Dataframe with the score of each path on cossine similarity, euclidean distance and manhattan distance\n",
    "    \n",
    "    Example of usage:\n",
    "    avaliate_paths(['pt', 'en', 'es'])\n",
    "    '''\n",
    "    \n",
    "    start = languages[0]\n",
    "    end = languages[-1]\n",
    "    \n",
    "    paths = [[start, end]]\n",
    "    for i in range(len(languages) - 2):\n",
    "        for comb in it.combinations(languages[1: -1], i + 1):\n",
    "            paths.append([start] + list(comb) + [end])\n",
    "    \n",
    "    scores = [avaliate_path(p) for p in paths]\n",
    "    index = [ ' -> '.join(p) for p in paths]\n",
    "\n",
    "    return pd.DataFrame(data = scores, columns = ['Cosine Similarity', 'Euclidean Distance', 'Bleu Score'], index = index)\n",
    "    # return pd.DataFrame(data = scores, columns = ['Cosine Similarity', 'Euclidean Distance'], index = index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866007a0",
   "metadata": {},
   "source": [
    "## 4 - Study Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c8082",
   "metadata": {},
   "source": [
    "### Study Case #1: Portuguese - Italian - Spanish\n",
    "In this case, we intend to evaluate how good is a translation between two languages from the Romance language family, such as Portuguese and Spanish, and if adding a language from the same family, such as Italian, affects the quality of the translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b908b884",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: continua para o próximo podcast\n",
      "Target sentence: continuar con el siguiente podcast\n",
      "Generated sentence: iniciar el próximo podcast\n",
      "BLEU score: 0.38940039153570244\n",
      "Cossine similarity to generated: 0.88823247\n",
      "Cossine similarity to target: 0.8825095 \n",
      "\n",
      "Original sentence: começa o próximo episódio do podcast\n",
      "Target sentence: empieza el siguiente episodio del podcast\n",
      "Generated sentence: comienza el siguiente episodio del podcast\n",
      "BLEU score: 0.8333333333333334\n",
      "Cossine similarity to generated: 0.9409791\n",
      "Cossine similarity to target: 0.9405708 \n",
      "\n",
      "Original sentence: reproduz o meu podcast favorito por favor\n",
      "Target sentence: pon mi podcast favorito por favor\n",
      "Generated sentence: por favor modifique mi calendario con este evento\n",
      "BLEU score: 0.375\n",
      "Cossine similarity to generated: 0.88078916\n",
      "Cossine similarity to target: 0.8463628 \n",
      "\n",
      "Original sentence: inicia o podcast esta semana para o jantar\n",
      "Target sentence: comienza esta semana para cenar el podcast\n",
      "Generated sentence: comienza esta semana para cenar el podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.9048376\n",
      "Cossine similarity to target: 0.90483767 \n",
      "\n",
      "Original sentence: reproduz o podcast de hoje\n",
      "Target sentence: pon el podcast de hoy del\n",
      "Generated sentence: obtener el tiempo de hoy\n",
      "BLEU score: 0.49123845184678916\n",
      "Cossine similarity to generated: 0.9192024\n",
      "Cossine similarity to target: 0.88036007 \n",
      "\n",
      "Original sentence: põe o próximo podcast\n",
      "Target sentence: reproducir el próximo podcast\n",
      "Generated sentence: pon el siguiente podcast\n",
      "BLEU score: 0.5\n",
      "Cossine similarity to generated: 0.9058681\n",
      "Cossine similarity to target: 0.8047818 \n",
      "\n",
      "Original sentence: reproduz o podcast anterior\n",
      "Target sentence: pon el podcast anterior\n",
      "Generated sentence: reproducir el siguiente podcast\n",
      "BLEU score: 0.5\n",
      "Cossine similarity to generated: 0.90049094\n",
      "Cossine similarity to target: 0.8072641 \n",
      "\n",
      "Original sentence: toque episódio de lista de coisas que você devia saber\n",
      "Target sentence: pon el episodio de ted en español en cola\n",
      "Generated sentence: que notificaciones de correo tengo\n",
      "BLEU score: 0.08986579282344431\n",
      "Cossine similarity to generated: 0.84167963\n",
      "Cossine similarity to target: 0.5980269 \n",
      "\n",
      "Original sentence: põe um podcast\n",
      "Target sentence: pon un podcast\n",
      "Generated sentence: pon un podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.9336146\n",
      "Cossine similarity to target: 0.9336146 \n",
      "\n",
      "Original sentence: salta para o próximo episódio deste podcast\n",
      "Target sentence: salta hacia el siguiente episodio de este podcast\n",
      "Generated sentence: empieza el siguiente episodio del podcast\n",
      "BLEU score: 0.47768754038252614\n",
      "Cossine similarity to generated: 0.8756571\n",
      "Cossine similarity to target: 0.8660348 \n",
      "\n",
      "Original sentence: continua para o próximo podcast\n",
      "Target sentence: continua col prossimo podcast\n",
      "Generated sentence: voglio vedere il prossimo podcast disponibile\n",
      "BLEU score: 0.3333333333333333\n",
      "Cossine similarity to generated: 0.90575886\n",
      "Cossine similarity to target: 0.6593134 \n",
      "\n",
      "Original sentence: começa o próximo episódio do podcast\n",
      "Target sentence: avvia il prossimo episodio del podcast\n",
      "Generated sentence: seleziona il prossimo episodio del podcast\n",
      "BLEU score: 0.8333333333333334\n",
      "Cossine similarity to generated: 0.93609333\n",
      "Cossine similarity to target: 0.926149 \n",
      "\n",
      "Original sentence: reproduz o meu podcast favorito por favor\n",
      "Target sentence: riproduci il mio podcast preferito per favore\n",
      "Generated sentence: riproduci il mio podcast preferito per favore\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.93047535\n",
      "Cossine similarity to target: 0.93047535 \n",
      "\n",
      "Original sentence: inicia o podcast esta semana para o jantar\n",
      "Target sentence: avvia il podcast this week for dinner\n",
      "Generated sentence: come sarà il tempo questa settimana\n",
      "BLEU score: 0.141080287481769\n",
      "Cossine similarity to generated: 0.8978056\n",
      "Cossine similarity to target: 0.65234625 \n",
      "\n",
      "Original sentence: reproduz o podcast de hoje\n",
      "Target sentence: riproduci il podcast di oggi\n",
      "Generated sentence: riproduci il podcast di oggi\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.94641066\n",
      "Cossine similarity to target: 0.9464108 \n",
      "\n",
      "Original sentence: põe o próximo podcast\n",
      "Target sentence: riproduci il prossimo podcast\n",
      "Generated sentence: metti il podcast precedente\n",
      "BLEU score: 0.5\n",
      "Cossine similarity to generated: 0.87645566\n",
      "Cossine similarity to target: 0.84795064 \n",
      "\n",
      "Original sentence: reproduz o podcast anterior\n",
      "Target sentence: metti il podcast precedente\n",
      "Generated sentence: riproduci il prossimo podcast\n",
      "BLEU score: 0.5\n",
      "Cossine similarity to generated: 0.88497114\n",
      "Cossine similarity to target: 0.878651 \n",
      "\n",
      "Original sentence: toque episódio de lista de coisas que você devia saber\n",
      "Target sentence: riproduci l' episodio di demoni urbani in coda\n",
      "Generated sentence: devo creare una nuova lista di cose da fare\n",
      "BLEU score: 0.11111111111111109\n",
      "Cossine similarity to generated: 0.8563386\n",
      "Cossine similarity to target: 0.6151462 \n",
      "\n",
      "Original sentence: põe um podcast\n",
      "Target sentence: riproduci un podcast\n",
      "Generated sentence: riproduci un podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.8768748\n",
      "Cossine similarity to target: 0.8768748 \n",
      "\n",
      "Original sentence: salta para o próximo episódio deste podcast\n",
      "Target sentence: salta e vai al prossimo episodio di questo podcast\n",
      "Generated sentence: salta il prossimo episodio del podcast\n",
      "BLEU score: 0.4043537731417556\n",
      "Cossine similarity to generated: 0.87631047\n",
      "Cossine similarity to target: 0.75582856 \n",
      "\n",
      "Original sentence: continua col prossimo podcast\n",
      "Target sentence: continuar con el siguiente podcast\n",
      "Generated sentence: por favor continúa con el siguiente episodio del podcast\n",
      "BLEU score: 0.4444444444444444\n",
      "Cossine similarity to generated: 0.73501205\n",
      "Cossine similarity to target: 0.73056835 \n",
      "\n",
      "Original sentence: avvia il prossimo episodio del podcast\n",
      "Target sentence: empieza el siguiente episodio del podcast\n",
      "Generated sentence: empieza el siguiente episodio del podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.9203149\n",
      "Cossine similarity to target: 0.9203149 \n",
      "\n",
      "Original sentence: riproduci il mio podcast preferito per favore\n",
      "Target sentence: pon mi podcast favorito por favor\n",
      "Generated sentence: limpiar mi calendario por el resto del día\n",
      "BLEU score: 0.25\n",
      "Cossine similarity to generated: 0.9128259\n",
      "Cossine similarity to target: 0.8459638 \n",
      "\n",
      "Original sentence: avvia il podcast this week for dinner\n",
      "Target sentence: comienza esta semana para cenar el podcast\n",
      "Generated sentence: por favor añada el almuerzo con erin a mi calendario en el restaurante\n",
      "BLEU score: 0.07692307692307693\n",
      "Cossine similarity to generated: 0.6623843\n",
      "Cossine similarity to target: 0.64657503 \n",
      "\n",
      "Original sentence: riproduci il podcast di oggi\n",
      "Target sentence: pon el podcast de hoy del\n",
      "Generated sentence: el tiempo de hoy\n",
      "BLEU score: 0.45489799478447507\n",
      "Cossine similarity to generated: 0.93347144\n",
      "Cossine similarity to target: 0.88164854 \n",
      "\n",
      "Original sentence: riproduci il prossimo podcast\n",
      "Target sentence: reproducir el próximo podcast\n",
      "Generated sentence: reproducir el próximo podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.926731\n",
      "Cossine similarity to target: 0.92673093 \n",
      "\n",
      "Original sentence: metti il podcast precedente\n",
      "Target sentence: pon el podcast anterior\n",
      "Generated sentence: reproducir el siguiente podcast\n",
      "BLEU score: 0.5\n",
      "Cossine similarity to generated: 0.9053299\n",
      "Cossine similarity to target: 0.86170566 \n",
      "\n",
      "Original sentence: riproduci l' episodio di demoni urbani in coda\n",
      "Target sentence: pon el episodio de ted en español en cola\n",
      "Generated sentence: hay un nuevo correo de javier en la bandeja de entrada\n",
      "BLEU score: 0.18181818181818182\n",
      "Cossine similarity to generated: 0.8437947\n",
      "Cossine similarity to target: 0.74053127 \n",
      "\n",
      "Original sentence: riproduci un podcast\n",
      "Target sentence: pon un podcast\n",
      "Generated sentence: establecer un recordatorio\n",
      "BLEU score: 0.3333333333333333\n",
      "Cossine similarity to generated: 0.9166459\n",
      "Cossine similarity to target: 0.885275 \n",
      "\n",
      "Original sentence: salta e vai al prossimo episodio di questo podcast\n",
      "Target sentence: salta hacia el siguiente episodio de este podcast\n",
      "Generated sentence: ir al próximo episodio de este podcast\n",
      "BLEU score: 0.4953587998572467\n",
      "Cossine similarity to generated: 0.9186435\n",
      "Cossine similarity to target: 0.81966096 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <th>Bleu Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pt -&gt; es</th>\n",
       "      <td>0.761036</td>\n",
       "      <td>4.187897</td>\n",
       "      <td>0.412073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; it -&gt; es</th>\n",
       "      <td>0.748819</td>\n",
       "      <td>4.274804</td>\n",
       "      <td>0.392679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Cosine Similarity  Euclidean Distance  Bleu Score\n",
       "pt -> es                 0.761036            4.187897    0.412073\n",
       "pt -> it -> es           0.748819            4.274804    0.392679"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp1 = avaliate_possible_paths(['pt', 'it', 'es'])\n",
    "exp1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf2bb3d",
   "metadata": {},
   "source": [
    "### Study Case #2: English - Swedish - German\n",
    "In this case, we intend to evaluate how good is a translation between two languages from the Anglo-Saxon language family, such as English and German, and if adding a language from the same family, such as Swedish, affects the quality of the translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dfa460b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: continue to next podcast\n",
      "Target sentence: fahre mit dem nächsten podcast fort\n",
      "Generated sentence: beginn die nächste episode zu spielen\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.851653\n",
      "Cossine similarity to target: 0.6785552 \n",
      "\n",
      "Original sentence: start next podcast episode\n",
      "Target sentence: starte die nächste folge des podcasts\n",
      "Generated sentence: folgende podcast episode starten\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.715421\n",
      "Cossine similarity to target: 0.6182311 \n",
      "\n",
      "Original sentence: play my favorite podcast please\n",
      "Target sentence: spiel bitte meinen lieblings podcast\n",
      "Generated sentence: spiel bitte meinen lieblings podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.8784077\n",
      "Cossine similarity to target: 0.8784077 \n",
      "\n",
      "Original sentence: start this week for dinner podcast\n",
      "Target sentence: starte den this week for dinner podcast\n",
      "Generated sentence: zeitplan für diese woche\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.805292\n",
      "Cossine similarity to target: 0.53795874 \n",
      "\n",
      "Original sentence: play today's podcast from the mi\n",
      "Target sentence: spielen die heutige podcast von die mi\n",
      "Generated sentence: spielen die heutige podcast von die mi\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.6144086\n",
      "Cossine similarity to target: 0.6144086 \n",
      "\n",
      "Original sentence: play the next podcast\n",
      "Target sentence: spiel den nächsten podcast\n",
      "Generated sentence: spiel die nächste episode vom podcast\n",
      "BLEU score: 0.3333333333333333\n",
      "Cossine similarity to generated: 0.83820575\n",
      "Cossine similarity to target: 0.7682682 \n",
      "\n",
      "Original sentence: play the previous podcast\n",
      "Target sentence: spiel den letzten podcast\n",
      "Generated sentence: spiel die nächste episode vom podcast\n",
      "BLEU score: 0.3333333333333333\n",
      "Cossine similarity to generated: 0.83465517\n",
      "Cossine similarity to target: 0.7833324 \n",
      "\n",
      "Original sentence: play episode of stuff you should know in queue\n",
      "Target sentence: spielen folge auf sachen die sie in der warteschlange kennen sollten\n",
      "Generated sentence: wie sind die titel der listen in kontakten\n",
      "BLEU score: 0.2577334795466146\n",
      "Cossine similarity to generated: 0.8705561\n",
      "Cossine similarity to target: 0.8626804 \n",
      "\n",
      "Original sentence: play a podcast\n",
      "Target sentence: spiel einen podcast\n",
      "Generated sentence: stell eine playlist mit dänischer musik ein\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.8286656\n",
      "Cossine similarity to target: 0.7288231 \n",
      "\n",
      "Original sentence: skip forward to the next episode of this podcast\n",
      "Target sentence: springe zur nächsten folge vom podcast\n",
      "Generated sentence: starte bitte die nächste episode des podcasts\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.869973\n",
      "Cossine similarity to target: 0.784319 \n",
      "\n",
      "Original sentence: continue to next podcast\n",
      "Target sentence: fortsätt till nästa podcast\n",
      "Generated sentence: lägg till påminnelse den fjärde april att gå till tandläkaren\n",
      "BLEU score: 0.10000000000000002\n",
      "Cossine similarity to generated: 0.8260703\n",
      "Cossine similarity to target: 0.8100806 \n",
      "\n",
      "Original sentence: start next podcast episode\n",
      "Target sentence: starta nästa podcast avsnitt\n",
      "Generated sentence: starta nästa podcast avsnitt\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.8320949\n",
      "Cossine similarity to target: 0.8320949 \n",
      "\n",
      "Original sentence: play my favorite podcast please\n",
      "Target sentence: spela min favorit podcast tack\n",
      "Generated sentence: spela min favorit podcast\n",
      "BLEU score: 0.7788007830714049\n",
      "Cossine similarity to generated: 0.929883\n",
      "Cossine similarity to target: 0.91526335 \n",
      "\n",
      "Original sentence: start this week for dinner podcast\n",
      "Target sentence: starta podcasten mitt i maten\n",
      "Generated sentence: radera kalender händelser för den här veckan\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.7882852\n",
      "Cossine similarity to target: 0.5829184 \n",
      "\n",
      "Original sentence: play today's podcast from the mi\n",
      "Target sentence: spela dagens podcast från mi\n",
      "Generated sentence: spela dagens podcast från mi\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.65915656\n",
      "Cossine similarity to target: 0.6591566 \n",
      "\n",
      "Original sentence: play the next podcast\n",
      "Target sentence: spela nästa podcast\n",
      "Generated sentence: spela nästa podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.8110575\n",
      "Cossine similarity to target: 0.8110575 \n",
      "\n",
      "Original sentence: play the previous podcast\n",
      "Target sentence: spela föregående podd\n",
      "Generated sentence: spela den nyaste podcasten\n",
      "BLEU score: 0.25\n",
      "Cossine similarity to generated: 0.79540294\n",
      "Cossine similarity to target: 0.7231896 \n",
      "\n",
      "Original sentence: play episode of stuff you should know in queue\n",
      "Target sentence: spela avsnitt av saker du borde veta i kön\n",
      "Generated sentence: spela avsnitt av saker du borde veta i kön\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.89087546\n",
      "Cossine similarity to target: 0.8908755 \n",
      "\n",
      "Original sentence: play a podcast\n",
      "Target sentence: spela en podcast\n",
      "Generated sentence: spela en podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.9163576\n",
      "Cossine similarity to target: 0.9163574 \n",
      "\n",
      "Original sentence: skip forward to the next episode of this podcast\n",
      "Target sentence: hoppa över till nästa avsnitt av denna podcast\n",
      "Generated sentence: hoppa till nästa avsnitt av den här podden\n",
      "BLEU score: 0.625\n",
      "Cossine similarity to generated: 0.90552044\n",
      "Cossine similarity to target: 0.8747552 \n",
      "\n",
      "Original sentence: fortsätt till nästa podcast\n",
      "Target sentence: fahre mit dem nächsten podcast fort\n",
      "Generated sentence: springe zum nächsten podcast\n",
      "BLEU score: 0.3032653298563167\n",
      "Cossine similarity to generated: 0.8060154\n",
      "Cossine similarity to target: 0.7346695 \n",
      "\n",
      "Original sentence: starta nästa podcast avsnitt\n",
      "Target sentence: starte die nächste folge des podcasts\n",
      "Generated sentence: folgende podcast episode starten\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.76952803\n",
      "Cossine similarity to target: 0.6018109 \n",
      "\n",
      "Original sentence: spela min favorit podcast tack\n",
      "Target sentence: spiel bitte meinen lieblings podcast\n",
      "Generated sentence: spiel bitte meinen lieblings podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.8941219\n",
      "Cossine similarity to target: 0.89412194 \n",
      "\n",
      "Original sentence: starta podcasten mitt i maten\n",
      "Target sentence: starte den this week for dinner podcast\n",
      "Generated sentence: starte die nächste episode in einem podcast\n",
      "BLEU score: 0.2857142857142857\n",
      "Cossine similarity to generated: 0.86905044\n",
      "Cossine similarity to target: 0.5557016 \n",
      "\n",
      "Original sentence: spela dagens podcast från mi\n",
      "Target sentence: spielen die heutige podcast von die mi\n",
      "Generated sentence: spielen die heutige podcast von die mi\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.64131504\n",
      "Cossine similarity to target: 0.64131504 \n",
      "\n",
      "Original sentence: spela nästa podcast\n",
      "Target sentence: spiel den nächsten podcast\n",
      "Generated sentence: spiel nächsten podcast\n",
      "BLEU score: 0.7165313105737893\n",
      "Cossine similarity to generated: 0.8838748\n",
      "Cossine similarity to target: 0.7521727 \n",
      "\n",
      "Original sentence: spela föregående podd\n",
      "Target sentence: spiel den letzten podcast\n",
      "Generated sentence: spiel nächsten podcast\n",
      "BLEU score: 0.47768754038252614\n",
      "Cossine similarity to generated: 0.78641504\n",
      "Cossine similarity to target: 0.638703 \n",
      "\n",
      "Original sentence: spela avsnitt av saker du borde veta i kön\n",
      "Target sentence: spielen folge auf sachen die sie in der warteschlange kennen sollten\n",
      "Generated sentence: kannst du sicherstellen dass das licht in der küche aus ist\n",
      "BLEU score: 0.18181818181818182\n",
      "Cossine similarity to generated: 0.8791102\n",
      "Cossine similarity to target: 0.8323574 \n",
      "\n",
      "Original sentence: spela en podcast\n",
      "Target sentence: spiel einen podcast\n",
      "Generated sentence: erstelle eine liste aller halloween veranstaltungen in hamburg\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.720078\n",
      "Cossine similarity to target: 0.6051782 \n",
      "\n",
      "Original sentence: hoppa över till nästa avsnitt av denna podcast\n",
      "Target sentence: springe zur nächsten folge vom podcast\n",
      "Generated sentence: spiel bitte die nächste episode von dem podcast\n",
      "BLEU score: 0.12500000000000003\n",
      "Cossine similarity to generated: 0.8861712\n",
      "Cossine similarity to target: 0.7956789 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <th>Bleu Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en -&gt; de</th>\n",
       "      <td>0.751231</td>\n",
       "      <td>4.850476</td>\n",
       "      <td>0.320940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; sv -&gt; de</th>\n",
       "      <td>0.737642</td>\n",
       "      <td>4.951251</td>\n",
       "      <td>0.288412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Cosine Similarity  Euclidean Distance  Bleu Score\n",
       "en -> de                 0.751231            4.850476    0.320940\n",
       "en -> sv -> de           0.737642            4.951251    0.288412"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp2 = avaliate_possible_paths(['en', 'sv', 'de'])\n",
    "exp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e11951d",
   "metadata": {},
   "source": [
    "### Study Case #3: Portuguese - English - Spanish\n",
    "In this case, we intend to evaluate how good is a translation between two languages from the Romance language family, such as Portuguese and Spanish, and if adding a language from an outer group, such as English from the Anglo-Saxon, affects the quality of the translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d77458df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: continua para o próximo podcast\n",
      "Target sentence: continuar con el siguiente podcast\n",
      "Generated sentence: iniciar el próximo podcast\n",
      "BLEU score: 0.38940039153570244\n",
      "Cossine similarity to generated: 0.88823247\n",
      "Cossine similarity to target: 0.8825095 \n",
      "\n",
      "Original sentence: começa o próximo episódio do podcast\n",
      "Target sentence: empieza el siguiente episodio del podcast\n",
      "Generated sentence: comienza el siguiente episodio del podcast\n",
      "BLEU score: 0.8333333333333334\n",
      "Cossine similarity to generated: 0.9409791\n",
      "Cossine similarity to target: 0.9405708 \n",
      "\n",
      "Original sentence: reproduz o meu podcast favorito por favor\n",
      "Target sentence: pon mi podcast favorito por favor\n",
      "Generated sentence: por favor modifique mi calendario con este evento\n",
      "BLEU score: 0.375\n",
      "Cossine similarity to generated: 0.88078916\n",
      "Cossine similarity to target: 0.8463628 \n",
      "\n",
      "Original sentence: inicia o podcast esta semana para o jantar\n",
      "Target sentence: comienza esta semana para cenar el podcast\n",
      "Generated sentence: comienza esta semana para cenar el podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.9048376\n",
      "Cossine similarity to target: 0.90483767 \n",
      "\n",
      "Original sentence: reproduz o podcast de hoje\n",
      "Target sentence: pon el podcast de hoy del\n",
      "Generated sentence: obtener el tiempo de hoy\n",
      "BLEU score: 0.49123845184678916\n",
      "Cossine similarity to generated: 0.9192024\n",
      "Cossine similarity to target: 0.88036007 \n",
      "\n",
      "Original sentence: põe o próximo podcast\n",
      "Target sentence: reproducir el próximo podcast\n",
      "Generated sentence: pon el siguiente podcast\n",
      "BLEU score: 0.5\n",
      "Cossine similarity to generated: 0.9058681\n",
      "Cossine similarity to target: 0.8047818 \n",
      "\n",
      "Original sentence: reproduz o podcast anterior\n",
      "Target sentence: pon el podcast anterior\n",
      "Generated sentence: reproducir el siguiente podcast\n",
      "BLEU score: 0.5\n",
      "Cossine similarity to generated: 0.90049094\n",
      "Cossine similarity to target: 0.8072641 \n",
      "\n",
      "Original sentence: toque episódio de lista de coisas que você devia saber\n",
      "Target sentence: pon el episodio de ted en español en cola\n",
      "Generated sentence: que notificaciones de correo tengo\n",
      "BLEU score: 0.08986579282344431\n",
      "Cossine similarity to generated: 0.84167963\n",
      "Cossine similarity to target: 0.5980269 \n",
      "\n",
      "Original sentence: põe um podcast\n",
      "Target sentence: pon un podcast\n",
      "Generated sentence: pon un podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.9336146\n",
      "Cossine similarity to target: 0.9336146 \n",
      "\n",
      "Original sentence: salta para o próximo episódio deste podcast\n",
      "Target sentence: salta hacia el siguiente episodio de este podcast\n",
      "Generated sentence: empieza el siguiente episodio del podcast\n",
      "BLEU score: 0.47768754038252614\n",
      "Cossine similarity to generated: 0.8756571\n",
      "Cossine similarity to target: 0.8660348 \n",
      "\n",
      "Original sentence: continua para o próximo podcast\n",
      "Target sentence: continue to next podcast\n",
      "Generated sentence: can the latest news be pulled up on the latest weather forecast for the week\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.7999855\n",
      "Cossine similarity to target: 0.70551485 \n",
      "\n",
      "Original sentence: começa o próximo episódio do podcast\n",
      "Target sentence: start next podcast episode\n",
      "Generated sentence: get rid of the events on the nineteenth from my calendar\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.76590204\n",
      "Cossine similarity to target: 0.5610544 \n",
      "\n",
      "Original sentence: reproduz o meu podcast favorito por favor\n",
      "Target sentence: play my favorite podcast please\n",
      "Generated sentence: please modify my calendar with this event\n",
      "BLEU score: 0.2857142857142857\n",
      "Cossine similarity to generated: 0.81576085\n",
      "Cossine similarity to target: 0.7785077 \n",
      "\n",
      "Original sentence: inicia o podcast esta semana para o jantar\n",
      "Target sentence: start this week for dinner podcast\n",
      "Generated sentence: what is my schedule for the day\n",
      "BLEU score: 0.14285714285714285\n",
      "Cossine similarity to generated: 0.8296408\n",
      "Cossine similarity to target: 0.7789551 \n",
      "\n",
      "Original sentence: reproduz o podcast de hoje\n",
      "Target sentence: play today's podcast from the mi\n",
      "Generated sentence: what is the time of the morning train headed to chicago\n",
      "BLEU score: 0.0909090909090909\n",
      "Cossine similarity to generated: 0.8306085\n",
      "Cossine similarity to target: 0.47525728 \n",
      "\n",
      "Original sentence: põe o próximo podcast\n",
      "Target sentence: play the next podcast\n",
      "Generated sentence: play the podcast\n",
      "BLEU score: 0.7165313105737893\n",
      "Cossine similarity to generated: 0.7781627\n",
      "Cossine similarity to target: 0.77001894 \n",
      "\n",
      "Original sentence: reproduz o podcast anterior\n",
      "Target sentence: play the previous podcast\n",
      "Generated sentence: start the podcast\n",
      "BLEU score: 0.47768754038252614\n",
      "Cossine similarity to generated: 0.7875767\n",
      "Cossine similarity to target: 0.73894763 \n",
      "\n",
      "Original sentence: toque episódio de lista de coisas que você devia saber\n",
      "Target sentence: play episode of stuff you should know in queue\n",
      "Generated sentence: please make a list of thing i have to shop tomorrow\n",
      "BLEU score: 0.0909090909090909\n",
      "Cossine similarity to generated: 0.8562044\n",
      "Cossine similarity to target: 0.7354614 \n",
      "\n",
      "Original sentence: põe um podcast\n",
      "Target sentence: play a podcast\n",
      "Generated sentence: play a podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.8046698\n",
      "Cossine similarity to target: 0.8046698 \n",
      "\n",
      "Original sentence: salta para o próximo episódio deste podcast\n",
      "Target sentence: skip forward to the next episode of this podcast\n",
      "Generated sentence: can you add to my calendar an event for next friday\n",
      "BLEU score: 0.18181818181818182\n",
      "Cossine similarity to generated: 0.7788306\n",
      "Cossine similarity to target: 0.77606124 \n",
      "\n",
      "Original sentence: continue to next podcast\n",
      "Target sentence: continuar con el siguiente podcast\n",
      "Generated sentence: el camino mas cercano para volver a casa\n",
      "BLEU score: 0.12500000000000003\n",
      "Cossine similarity to generated: 0.8241549\n",
      "Cossine similarity to target: 0.6452859 \n",
      "\n",
      "Original sentence: start next podcast episode\n",
      "Target sentence: empieza el siguiente episodio del podcast\n",
      "Generated sentence: podcast siguiente episodio\n",
      "BLEU score: 0.36787944117144233\n",
      "Cossine similarity to generated: 0.7605107\n",
      "Cossine similarity to target: 0.6733025 \n",
      "\n",
      "Original sentence: play my favorite podcast please\n",
      "Target sentence: pon mi podcast favorito por favor\n",
      "Generated sentence: pon de nuevo mi último podcast\n",
      "BLEU score: 0.5\n",
      "Cossine similarity to generated: 0.9123432\n",
      "Cossine similarity to target: 0.90411335 \n",
      "\n",
      "Original sentence: start this week for dinner podcast\n",
      "Target sentence: comienza esta semana para cenar el podcast\n",
      "Generated sentence: comienza esta semana para cenar el podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.85432696\n",
      "Cossine similarity to target: 0.85432696 \n",
      "\n",
      "Original sentence: play today's podcast from the mi\n",
      "Target sentence: pon el podcast de hoy del\n",
      "Generated sentence: pon mi canción de rap y rock uno tras otro\n",
      "BLEU score: 0.2\n",
      "Cossine similarity to generated: 0.58046746\n",
      "Cossine similarity to target: 0.5232377 \n",
      "\n",
      "Original sentence: play the next podcast\n",
      "Target sentence: reproducir el próximo podcast\n",
      "Generated sentence: pon el siguiente episodio de este podcast\n",
      "BLEU score: 0.2857142857142857\n",
      "Cossine similarity to generated: 0.7880002\n",
      "Cossine similarity to target: 0.6992792 \n",
      "\n",
      "Original sentence: play the previous podcast\n",
      "Target sentence: pon el podcast anterior\n",
      "Generated sentence: pon el siguiente episodio de este podcast\n",
      "BLEU score: 0.42857142857142855\n",
      "Cossine similarity to generated: 0.80019975\n",
      "Cossine similarity to target: 0.77351195 \n",
      "\n",
      "Original sentence: play episode of stuff you should know in queue\n",
      "Target sentence: pon el episodio de ted en español en cola\n",
      "Generated sentence: qué hay de nuevo en el mercado de valores\n",
      "BLEU score: 0.3333333333333333\n",
      "Cossine similarity to generated: 0.8636221\n",
      "Cossine similarity to target: 0.80281806 \n",
      "\n",
      "Original sentence: play a podcast\n",
      "Target sentence: pon un podcast\n",
      "Generated sentence: pon un algo de radio\n",
      "BLEU score: 0.4\n",
      "Cossine similarity to generated: 0.8634953\n",
      "Cossine similarity to target: 0.8601861 \n",
      "\n",
      "Original sentence: skip forward to the next episode of this podcast\n",
      "Target sentence: salta hacia el siguiente episodio de este podcast\n",
      "Generated sentence: salta al siguiente episodio de este podcast\n",
      "BLEU score: 0.7430381997858699\n",
      "Cossine similarity to generated: 0.87560165\n",
      "Cossine similarity to target: 0.86805564 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <th>Bleu Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pt -&gt; es</th>\n",
       "      <td>0.761036</td>\n",
       "      <td>4.187897</td>\n",
       "      <td>0.412073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; en -&gt; es</th>\n",
       "      <td>0.735565</td>\n",
       "      <td>4.411218</td>\n",
       "      <td>0.394879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Cosine Similarity  Euclidean Distance  Bleu Score\n",
       "pt -> es                 0.761036            4.187897    0.412073\n",
       "pt -> en -> es           0.735565            4.411218    0.394879"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp3 = avaliate_possible_paths(['pt', 'en', 'es'])\n",
    "exp3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4304f41",
   "metadata": {},
   "source": [
    "### Study Case #4: English - Portuguese - German\n",
    "In this case, we intend to evaluate how good is a translation between two languages from the Anglo-Saxon language family, such as English and German, and if adding a language from an outer group, such as Portuguese from the Romance, affects the quality of the translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ddc0304",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: continua para o próximo podcast\n",
      "Target sentence: continuar con el siguiente podcast\n",
      "Generated sentence: iniciar el próximo podcast\n",
      "BLEU score: 0.38940039153570244\n",
      "Cossine similarity to generated: 0.88823247\n",
      "Cossine similarity to target: 0.8825095 \n",
      "\n",
      "Original sentence: começa o próximo episódio do podcast\n",
      "Target sentence: empieza el siguiente episodio del podcast\n",
      "Generated sentence: comienza el siguiente episodio del podcast\n",
      "BLEU score: 0.8333333333333334\n",
      "Cossine similarity to generated: 0.9409791\n",
      "Cossine similarity to target: 0.9405708 \n",
      "\n",
      "Original sentence: reproduz o meu podcast favorito por favor\n",
      "Target sentence: pon mi podcast favorito por favor\n",
      "Generated sentence: por favor modifique mi calendario con este evento\n",
      "BLEU score: 0.375\n",
      "Cossine similarity to generated: 0.88078916\n",
      "Cossine similarity to target: 0.8463628 \n",
      "\n",
      "Original sentence: inicia o podcast esta semana para o jantar\n",
      "Target sentence: comienza esta semana para cenar el podcast\n",
      "Generated sentence: comienza esta semana para cenar el podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.9048376\n",
      "Cossine similarity to target: 0.90483767 \n",
      "\n",
      "Original sentence: reproduz o podcast de hoje\n",
      "Target sentence: pon el podcast de hoy del\n",
      "Generated sentence: obtener el tiempo de hoy\n",
      "BLEU score: 0.49123845184678916\n",
      "Cossine similarity to generated: 0.9192024\n",
      "Cossine similarity to target: 0.88036007 \n",
      "\n",
      "Original sentence: põe o próximo podcast\n",
      "Target sentence: reproducir el próximo podcast\n",
      "Generated sentence: pon el siguiente podcast\n",
      "BLEU score: 0.5\n",
      "Cossine similarity to generated: 0.9058681\n",
      "Cossine similarity to target: 0.8047818 \n",
      "\n",
      "Original sentence: reproduz o podcast anterior\n",
      "Target sentence: pon el podcast anterior\n",
      "Generated sentence: reproducir el siguiente podcast\n",
      "BLEU score: 0.5\n",
      "Cossine similarity to generated: 0.90049094\n",
      "Cossine similarity to target: 0.8072641 \n",
      "\n",
      "Original sentence: toque episódio de lista de coisas que você devia saber\n",
      "Target sentence: pon el episodio de ted en español en cola\n",
      "Generated sentence: que notificaciones de correo tengo\n",
      "BLEU score: 0.08986579282344431\n",
      "Cossine similarity to generated: 0.84167963\n",
      "Cossine similarity to target: 0.5980269 \n",
      "\n",
      "Original sentence: põe um podcast\n",
      "Target sentence: pon un podcast\n",
      "Generated sentence: pon un podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.9336146\n",
      "Cossine similarity to target: 0.9336146 \n",
      "\n",
      "Original sentence: salta para o próximo episódio deste podcast\n",
      "Target sentence: salta hacia el siguiente episodio de este podcast\n",
      "Generated sentence: empieza el siguiente episodio del podcast\n",
      "BLEU score: 0.47768754038252614\n",
      "Cossine similarity to generated: 0.8756571\n",
      "Cossine similarity to target: 0.8660348 \n",
      "\n",
      "Original sentence: continua para o próximo podcast\n",
      "Target sentence: continue to next podcast\n",
      "Generated sentence: can the latest news be pulled up on the latest weather forecast for the week\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.7999855\n",
      "Cossine similarity to target: 0.70551485 \n",
      "\n",
      "Original sentence: começa o próximo episódio do podcast\n",
      "Target sentence: start next podcast episode\n",
      "Generated sentence: get rid of the events on the nineteenth from my calendar\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.76590204\n",
      "Cossine similarity to target: 0.5610544 \n",
      "\n",
      "Original sentence: reproduz o meu podcast favorito por favor\n",
      "Target sentence: play my favorite podcast please\n",
      "Generated sentence: please modify my calendar with this event\n",
      "BLEU score: 0.2857142857142857\n",
      "Cossine similarity to generated: 0.81576085\n",
      "Cossine similarity to target: 0.7785077 \n",
      "\n",
      "Original sentence: inicia o podcast esta semana para o jantar\n",
      "Target sentence: start this week for dinner podcast\n",
      "Generated sentence: what is my schedule for the day\n",
      "BLEU score: 0.14285714285714285\n",
      "Cossine similarity to generated: 0.8296408\n",
      "Cossine similarity to target: 0.7789551 \n",
      "\n",
      "Original sentence: reproduz o podcast de hoje\n",
      "Target sentence: play today's podcast from the mi\n",
      "Generated sentence: what is the time of the morning train headed to chicago\n",
      "BLEU score: 0.0909090909090909\n",
      "Cossine similarity to generated: 0.8306085\n",
      "Cossine similarity to target: 0.47525728 \n",
      "\n",
      "Original sentence: põe o próximo podcast\n",
      "Target sentence: play the next podcast\n",
      "Generated sentence: play the podcast\n",
      "BLEU score: 0.7165313105737893\n",
      "Cossine similarity to generated: 0.7781627\n",
      "Cossine similarity to target: 0.77001894 \n",
      "\n",
      "Original sentence: reproduz o podcast anterior\n",
      "Target sentence: play the previous podcast\n",
      "Generated sentence: start the podcast\n",
      "BLEU score: 0.47768754038252614\n",
      "Cossine similarity to generated: 0.7875767\n",
      "Cossine similarity to target: 0.73894763 \n",
      "\n",
      "Original sentence: toque episódio de lista de coisas que você devia saber\n",
      "Target sentence: play episode of stuff you should know in queue\n",
      "Generated sentence: please make a list of thing i have to shop tomorrow\n",
      "BLEU score: 0.0909090909090909\n",
      "Cossine similarity to generated: 0.8562044\n",
      "Cossine similarity to target: 0.7354614 \n",
      "\n",
      "Original sentence: põe um podcast\n",
      "Target sentence: play a podcast\n",
      "Generated sentence: play a podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.8046698\n",
      "Cossine similarity to target: 0.8046698 \n",
      "\n",
      "Original sentence: salta para o próximo episódio deste podcast\n",
      "Target sentence: skip forward to the next episode of this podcast\n",
      "Generated sentence: can you add to my calendar an event for next friday\n",
      "BLEU score: 0.18181818181818182\n",
      "Cossine similarity to generated: 0.7788306\n",
      "Cossine similarity to target: 0.77606124 \n",
      "\n",
      "Original sentence: continue to next podcast\n",
      "Target sentence: continuar con el siguiente podcast\n",
      "Generated sentence: el camino mas cercano para volver a casa\n",
      "BLEU score: 0.12500000000000003\n",
      "Cossine similarity to generated: 0.8241549\n",
      "Cossine similarity to target: 0.6452859 \n",
      "\n",
      "Original sentence: start next podcast episode\n",
      "Target sentence: empieza el siguiente episodio del podcast\n",
      "Generated sentence: podcast siguiente episodio\n",
      "BLEU score: 0.36787944117144233\n",
      "Cossine similarity to generated: 0.7605107\n",
      "Cossine similarity to target: 0.6733025 \n",
      "\n",
      "Original sentence: play my favorite podcast please\n",
      "Target sentence: pon mi podcast favorito por favor\n",
      "Generated sentence: pon de nuevo mi último podcast\n",
      "BLEU score: 0.5\n",
      "Cossine similarity to generated: 0.9123432\n",
      "Cossine similarity to target: 0.90411335 \n",
      "\n",
      "Original sentence: start this week for dinner podcast\n",
      "Target sentence: comienza esta semana para cenar el podcast\n",
      "Generated sentence: comienza esta semana para cenar el podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.85432696\n",
      "Cossine similarity to target: 0.85432696 \n",
      "\n",
      "Original sentence: play today's podcast from the mi\n",
      "Target sentence: pon el podcast de hoy del\n",
      "Generated sentence: pon mi canción de rap y rock uno tras otro\n",
      "BLEU score: 0.2\n",
      "Cossine similarity to generated: 0.58046746\n",
      "Cossine similarity to target: 0.5232377 \n",
      "\n",
      "Original sentence: play the next podcast\n",
      "Target sentence: reproducir el próximo podcast\n",
      "Generated sentence: pon el siguiente episodio de este podcast\n",
      "BLEU score: 0.2857142857142857\n",
      "Cossine similarity to generated: 0.7880002\n",
      "Cossine similarity to target: 0.6992792 \n",
      "\n",
      "Original sentence: play the previous podcast\n",
      "Target sentence: pon el podcast anterior\n",
      "Generated sentence: pon el siguiente episodio de este podcast\n",
      "BLEU score: 0.42857142857142855\n",
      "Cossine similarity to generated: 0.80019975\n",
      "Cossine similarity to target: 0.77351195 \n",
      "\n",
      "Original sentence: play episode of stuff you should know in queue\n",
      "Target sentence: pon el episodio de ted en español en cola\n",
      "Generated sentence: qué hay de nuevo en el mercado de valores\n",
      "BLEU score: 0.3333333333333333\n",
      "Cossine similarity to generated: 0.8636221\n",
      "Cossine similarity to target: 0.80281806 \n",
      "\n",
      "Original sentence: play a podcast\n",
      "Target sentence: pon un podcast\n",
      "Generated sentence: pon un algo de radio\n",
      "BLEU score: 0.4\n",
      "Cossine similarity to generated: 0.8634953\n",
      "Cossine similarity to target: 0.8601861 \n",
      "\n",
      "Original sentence: skip forward to the next episode of this podcast\n",
      "Target sentence: salta hacia el siguiente episodio de este podcast\n",
      "Generated sentence: salta al siguiente episodio de este podcast\n",
      "BLEU score: 0.7430381997858699\n",
      "Cossine similarity to generated: 0.87560165\n",
      "Cossine similarity to target: 0.86805564 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <th>Bleu Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pt -&gt; es</th>\n",
       "      <td>0.761036</td>\n",
       "      <td>4.187897</td>\n",
       "      <td>0.412073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; en -&gt; es</th>\n",
       "      <td>0.735565</td>\n",
       "      <td>4.411218</td>\n",
       "      <td>0.394879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Cosine Similarity  Euclidean Distance  Bleu Score\n",
       "pt -> es                 0.761036            4.187897    0.412073\n",
       "pt -> en -> es           0.735565            4.411218    0.394879"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp4 = avaliate_possible_paths(['pt', 'en', 'es'])\n",
    "exp4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc69518",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47926541",
   "metadata": {},
   "source": [
    "### Experiment #1: Portuguese - Spanish - German\n",
    "In this experiment, we intend to evaluate translations using languages from different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73d72124",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: continua para o próximo podcast\n",
      "Target sentence: fahre mit dem nächsten podcast fort\n",
      "Generated sentence: stell die nächste podcast episode zum abspielen ein\n",
      "BLEU score: 0.12500000000000003\n",
      "Cossine similarity to generated: 0.8257882\n",
      "Cossine similarity to target: 0.7637129 \n",
      "\n",
      "Original sentence: começa o próximo episódio do podcast\n",
      "Target sentence: starte die nächste folge des podcasts\n",
      "Generated sentence: wie ist der status vom derzeitigem wetter\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.809924\n",
      "Cossine similarity to target: 0.6960387 \n",
      "\n",
      "Original sentence: reproduz o meu podcast favorito por favor\n",
      "Target sentence: spiel bitte meinen lieblings podcast\n",
      "Generated sentence: schalte bitte meinen lieblings radiosender ein\n",
      "BLEU score: 0.5\n",
      "Cossine similarity to generated: 0.80715036\n",
      "Cossine similarity to target: 0.77412176 \n",
      "\n",
      "Original sentence: inicia o podcast esta semana para o jantar\n",
      "Target sentence: starte den this week for dinner podcast\n",
      "Generated sentence: was steht heute auf dem programm\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.8598444\n",
      "Cossine similarity to target: 0.5818287 \n",
      "\n",
      "Original sentence: reproduz o podcast de hoje\n",
      "Target sentence: spielen die heutige podcast von die mi\n",
      "Generated sentence: spiele den podcast von barack obama der auf dem gerät gespeichert ist\n",
      "BLEU score: 0.16666666666666669\n",
      "Cossine similarity to generated: 0.82526743\n",
      "Cossine similarity to target: 0.71466076 \n",
      "\n",
      "Original sentence: põe o próximo podcast\n",
      "Target sentence: spiel den nächsten podcast\n",
      "Generated sentence: spiel das programm deutschland sucht den superstar\n",
      "BLEU score: 0.2857142857142857\n",
      "Cossine similarity to generated: 0.77109426\n",
      "Cossine similarity to target: 0.76481634 \n",
      "\n",
      "Original sentence: reproduz o podcast anterior\n",
      "Target sentence: spiel den letzten podcast\n",
      "Generated sentence: was passiert heute mit dem brexit\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.77642393\n",
      "Cossine similarity to target: 0.72922355 \n",
      "\n",
      "Original sentence: toque episódio de lista de coisas que você devia saber\n",
      "Target sentence: spielen folge auf sachen die sie in der warteschlange kennen sollten\n",
      "Generated sentence: erstelle eine liste von monatlichen lebensmitteln die ich kaufen muss\n",
      "BLEU score: 0.09048374180359597\n",
      "Cossine similarity to generated: 0.7957753\n",
      "Cossine similarity to target: 0.6793706 \n",
      "\n",
      "Original sentence: põe um podcast\n",
      "Target sentence: spiel einen podcast\n",
      "Generated sentence: spiel einen podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.77328455\n",
      "Cossine similarity to target: 0.77328455 \n",
      "\n",
      "Original sentence: salta para o próximo episódio deste podcast\n",
      "Target sentence: springe zur nächsten folge vom podcast\n",
      "Generated sentence: stell die nächste podcast episode zum abspielen ein\n",
      "BLEU score: 0.12500000000000003\n",
      "Cossine similarity to generated: 0.83542514\n",
      "Cossine similarity to target: 0.74495995 \n",
      "\n",
      "Original sentence: continua para o próximo podcast\n",
      "Target sentence: continuar con el siguiente podcast\n",
      "Generated sentence: iniciar el próximo podcast\n",
      "BLEU score: 0.38940039153570244\n",
      "Cossine similarity to generated: 0.88823247\n",
      "Cossine similarity to target: 0.8825095 \n",
      "\n",
      "Original sentence: começa o próximo episódio do podcast\n",
      "Target sentence: empieza el siguiente episodio del podcast\n",
      "Generated sentence: comienza el siguiente episodio del podcast\n",
      "BLEU score: 0.8333333333333334\n",
      "Cossine similarity to generated: 0.9409791\n",
      "Cossine similarity to target: 0.9405708 \n",
      "\n",
      "Original sentence: reproduz o meu podcast favorito por favor\n",
      "Target sentence: pon mi podcast favorito por favor\n",
      "Generated sentence: por favor modifique mi calendario con este evento\n",
      "BLEU score: 0.375\n",
      "Cossine similarity to generated: 0.88078916\n",
      "Cossine similarity to target: 0.8463628 \n",
      "\n",
      "Original sentence: inicia o podcast esta semana para o jantar\n",
      "Target sentence: comienza esta semana para cenar el podcast\n",
      "Generated sentence: comienza esta semana para cenar el podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.9048376\n",
      "Cossine similarity to target: 0.90483767 \n",
      "\n",
      "Original sentence: reproduz o podcast de hoje\n",
      "Target sentence: pon el podcast de hoy del\n",
      "Generated sentence: obtener el tiempo de hoy\n",
      "BLEU score: 0.49123845184678916\n",
      "Cossine similarity to generated: 0.9192024\n",
      "Cossine similarity to target: 0.88036007 \n",
      "\n",
      "Original sentence: põe o próximo podcast\n",
      "Target sentence: reproducir el próximo podcast\n",
      "Generated sentence: pon el siguiente podcast\n",
      "BLEU score: 0.5\n",
      "Cossine similarity to generated: 0.9058681\n",
      "Cossine similarity to target: 0.8047818 \n",
      "\n",
      "Original sentence: reproduz o podcast anterior\n",
      "Target sentence: pon el podcast anterior\n",
      "Generated sentence: reproducir el siguiente podcast\n",
      "BLEU score: 0.5\n",
      "Cossine similarity to generated: 0.90049094\n",
      "Cossine similarity to target: 0.8072641 \n",
      "\n",
      "Original sentence: toque episódio de lista de coisas que você devia saber\n",
      "Target sentence: pon el episodio de ted en español en cola\n",
      "Generated sentence: que notificaciones de correo tengo\n",
      "BLEU score: 0.08986579282344431\n",
      "Cossine similarity to generated: 0.84167963\n",
      "Cossine similarity to target: 0.5980269 \n",
      "\n",
      "Original sentence: põe um podcast\n",
      "Target sentence: pon un podcast\n",
      "Generated sentence: pon un podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.9336146\n",
      "Cossine similarity to target: 0.9336146 \n",
      "\n",
      "Original sentence: salta para o próximo episódio deste podcast\n",
      "Target sentence: salta hacia el siguiente episodio de este podcast\n",
      "Generated sentence: empieza el siguiente episodio del podcast\n",
      "BLEU score: 0.47768754038252614\n",
      "Cossine similarity to generated: 0.8756571\n",
      "Cossine similarity to target: 0.8660348 \n",
      "\n",
      "Original sentence: continuar con el siguiente podcast\n",
      "Target sentence: fahre mit dem nächsten podcast fort\n",
      "Generated sentence: entferne mittagessen mit den kollegen am donnerstag\n",
      "BLEU score: 0.14285714285714285\n",
      "Cossine similarity to generated: 0.82414234\n",
      "Cossine similarity to target: 0.80108976 \n",
      "\n",
      "Original sentence: empieza el siguiente episodio del podcast\n",
      "Target sentence: starte die nächste folge des podcasts\n",
      "Generated sentence: wie wird das wetter am siebten\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.79512143\n",
      "Cossine similarity to target: 0.7084804 \n",
      "\n",
      "Original sentence: pon mi podcast favorito por favor\n",
      "Target sentence: spiel bitte meinen lieblings podcast\n",
      "Generated sentence: spiel bitte meinen lieblings podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.8863301\n",
      "Cossine similarity to target: 0.88633007 \n",
      "\n",
      "Original sentence: comienza esta semana para cenar el podcast\n",
      "Target sentence: starte den this week for dinner podcast\n",
      "Generated sentence: wie wird das wetter am montag diese woche\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.8169869\n",
      "Cossine similarity to target: 0.53563935 \n",
      "\n",
      "Original sentence: pon el podcast de hoy del\n",
      "Target sentence: spielen die heutige podcast von die mi\n",
      "Generated sentence: spiel die nächste episode von dem podcast\n",
      "BLEU score: 0.42857142857142855\n",
      "Cossine similarity to generated: 0.8508003\n",
      "Cossine similarity to target: 0.71367353 \n",
      "\n",
      "Original sentence: reproducir el próximo podcast\n",
      "Target sentence: spiel den nächsten podcast\n",
      "Generated sentence: wie wird das wetter am siebten\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.8412261\n",
      "Cossine similarity to target: 0.64283514 \n",
      "\n",
      "Original sentence: pon el podcast anterior\n",
      "Target sentence: spiel den letzten podcast\n",
      "Generated sentence: spiel den podcast\n",
      "BLEU score: 0.7165313105737893\n",
      "Cossine similarity to generated: 0.73205537\n",
      "Cossine similarity to target: 0.71430653 \n",
      "\n",
      "Original sentence: pon el episodio de ted en español en cola\n",
      "Target sentence: spielen folge auf sachen die sie in der warteschlange kennen sollten\n",
      "Generated sentence: bitte trag ferien in kuba am zweiten april in meinen kalender ein\n",
      "BLEU score: 0.08333333333333333\n",
      "Cossine similarity to generated: 0.8582515\n",
      "Cossine similarity to target: 0.7961863 \n",
      "\n",
      "Original sentence: pon un podcast\n",
      "Target sentence: spiel einen podcast\n",
      "Generated sentence: spiel ein spiel\n",
      "BLEU score: 0.3333333333333333\n",
      "Cossine similarity to generated: 0.7667891\n",
      "Cossine similarity to target: 0.7616186 \n",
      "\n",
      "Original sentence: salta hacia el siguiente episodio de este podcast\n",
      "Target sentence: springe zur nächsten folge vom podcast\n",
      "Generated sentence: spiel bitte die nächste episode von dem podcast\n",
      "BLEU score: 0.12500000000000003\n",
      "Cossine similarity to generated: 0.8518937\n",
      "Cossine similarity to target: 0.77906394 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <th>Bleu Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pt -&gt; de</th>\n",
       "      <td>0.672054</td>\n",
       "      <td>4.727530</td>\n",
       "      <td>0.217575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; es -&gt; de</th>\n",
       "      <td>0.665095</td>\n",
       "      <td>4.762326</td>\n",
       "      <td>0.204248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Cosine Similarity  Euclidean Distance  Bleu Score\n",
       "pt -> de                 0.672054            4.727530    0.217575\n",
       "pt -> es -> de           0.665095            4.762326    0.204248"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp5 = avaliate_possible_paths(['pt', 'es', 'de'])\n",
    "exp5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35631075",
   "metadata": {},
   "source": [
    "### Experiment #2: Portuguese - Swedish - German "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41a7d5fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: continua para o próximo podcast\n",
      "Target sentence: fahre mit dem nächsten podcast fort\n",
      "Generated sentence: stell die nächste podcast episode zum abspielen ein\n",
      "BLEU score: 0.12500000000000003\n",
      "Cossine similarity to generated: 0.8257882\n",
      "Cossine similarity to target: 0.7637129 \n",
      "\n",
      "Original sentence: começa o próximo episódio do podcast\n",
      "Target sentence: starte die nächste folge des podcasts\n",
      "Generated sentence: wie ist der status vom derzeitigem wetter\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.809924\n",
      "Cossine similarity to target: 0.6960387 \n",
      "\n",
      "Original sentence: reproduz o meu podcast favorito por favor\n",
      "Target sentence: spiel bitte meinen lieblings podcast\n",
      "Generated sentence: schalte bitte meinen lieblings radiosender ein\n",
      "BLEU score: 0.5\n",
      "Cossine similarity to generated: 0.80715036\n",
      "Cossine similarity to target: 0.77412176 \n",
      "\n",
      "Original sentence: inicia o podcast esta semana para o jantar\n",
      "Target sentence: starte den this week for dinner podcast\n",
      "Generated sentence: was steht heute auf dem programm\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.8598444\n",
      "Cossine similarity to target: 0.5818287 \n",
      "\n",
      "Original sentence: reproduz o podcast de hoje\n",
      "Target sentence: spielen die heutige podcast von die mi\n",
      "Generated sentence: spiele den podcast von barack obama der auf dem gerät gespeichert ist\n",
      "BLEU score: 0.16666666666666669\n",
      "Cossine similarity to generated: 0.82526743\n",
      "Cossine similarity to target: 0.71466076 \n",
      "\n",
      "Original sentence: põe o próximo podcast\n",
      "Target sentence: spiel den nächsten podcast\n",
      "Generated sentence: spiel das programm deutschland sucht den superstar\n",
      "BLEU score: 0.2857142857142857\n",
      "Cossine similarity to generated: 0.77109426\n",
      "Cossine similarity to target: 0.76481634 \n",
      "\n",
      "Original sentence: reproduz o podcast anterior\n",
      "Target sentence: spiel den letzten podcast\n",
      "Generated sentence: was passiert heute mit dem brexit\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.77642393\n",
      "Cossine similarity to target: 0.72922355 \n",
      "\n",
      "Original sentence: toque episódio de lista de coisas que você devia saber\n",
      "Target sentence: spielen folge auf sachen die sie in der warteschlange kennen sollten\n",
      "Generated sentence: erstelle eine liste von monatlichen lebensmitteln die ich kaufen muss\n",
      "BLEU score: 0.09048374180359597\n",
      "Cossine similarity to generated: 0.7957753\n",
      "Cossine similarity to target: 0.6793706 \n",
      "\n",
      "Original sentence: põe um podcast\n",
      "Target sentence: spiel einen podcast\n",
      "Generated sentence: spiel einen podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.77328455\n",
      "Cossine similarity to target: 0.77328455 \n",
      "\n",
      "Original sentence: salta para o próximo episódio deste podcast\n",
      "Target sentence: springe zur nächsten folge vom podcast\n",
      "Generated sentence: stell die nächste podcast episode zum abspielen ein\n",
      "BLEU score: 0.12500000000000003\n",
      "Cossine similarity to generated: 0.83542514\n",
      "Cossine similarity to target: 0.74495995 \n",
      "\n",
      "Original sentence: continua para o próximo podcast\n",
      "Target sentence: fortsätt till nästa podcast\n",
      "Generated sentence: hur kommer vädret att vara i stockholm nästa vecka\n",
      "BLEU score: 0.11111111111111109\n",
      "Cossine similarity to generated: 0.77471703\n",
      "Cossine similarity to target: 0.7451748 \n",
      "\n",
      "Original sentence: começa o próximo episódio do podcast\n",
      "Target sentence: starta nästa podcast avsnitt\n",
      "Generated sentence: vad är nästa händelse i min kalender\n",
      "BLEU score: 0.14285714285714285\n",
      "Cossine similarity to generated: 0.7211047\n",
      "Cossine similarity to target: 0.54476255 \n",
      "\n",
      "Original sentence: reproduz o meu podcast favorito por favor\n",
      "Target sentence: spela min favorit podcast tack\n",
      "Generated sentence: har jag meddelanden i min inkorg tack\n",
      "BLEU score: 0.2857142857142857\n",
      "Cossine similarity to generated: 0.81425965\n",
      "Cossine similarity to target: 0.8136345 \n",
      "\n",
      "Original sentence: inicia o podcast esta semana para o jantar\n",
      "Target sentence: starta podcasten mitt i maten\n",
      "Generated sentence: vad är prognosen för den här veckan\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.8014248\n",
      "Cossine similarity to target: 0.68630594 \n",
      "\n",
      "Original sentence: reproduz o podcast de hoje\n",
      "Target sentence: spela dagens podcast från mi\n",
      "Generated sentence: berätta för mig vad den formella definitionen av en banan\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.79651576\n",
      "Cossine similarity to target: 0.52300775 \n",
      "\n",
      "Original sentence: põe o próximo podcast\n",
      "Target sentence: spela nästa podcast\n",
      "Generated sentence: vad är nästa avsnitt spela det\n",
      "BLEU score: 0.3333333333333333\n",
      "Cossine similarity to generated: 0.7259397\n",
      "Cossine similarity to target: 0.6886194 \n",
      "\n",
      "Original sentence: reproduz o podcast anterior\n",
      "Target sentence: spela föregående podd\n",
      "Generated sentence: vad är den bästa podcasten\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.6975852\n",
      "Cossine similarity to target: 0.534956 \n",
      "\n",
      "Original sentence: toque episódio de lista de coisas que você devia saber\n",
      "Target sentence: spela avsnitt av saker du borde veta i kön\n",
      "Generated sentence: jag behöver att en händelse skapas med bara dessa människor\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.82697415\n",
      "Cossine similarity to target: 0.6862141 \n",
      "\n",
      "Original sentence: põe um podcast\n",
      "Target sentence: spela en podcast\n",
      "Generated sentence: spela en podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.762463\n",
      "Cossine similarity to target: 0.76246303 \n",
      "\n",
      "Original sentence: salta para o próximo episódio deste podcast\n",
      "Target sentence: hoppa över till nästa avsnitt av denna podcast\n",
      "Generated sentence: hoppa till nästa avsnitt av den här podden\n",
      "BLEU score: 0.625\n",
      "Cossine similarity to generated: 0.7868629\n",
      "Cossine similarity to target: 0.73952067 \n",
      "\n",
      "Original sentence: fortsätt till nästa podcast\n",
      "Target sentence: fahre mit dem nächsten podcast fort\n",
      "Generated sentence: springe zum nächsten podcast\n",
      "BLEU score: 0.3032653298563167\n",
      "Cossine similarity to generated: 0.8060154\n",
      "Cossine similarity to target: 0.7346695 \n",
      "\n",
      "Original sentence: starta nästa podcast avsnitt\n",
      "Target sentence: starte die nächste folge des podcasts\n",
      "Generated sentence: folgende podcast episode starten\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.76952803\n",
      "Cossine similarity to target: 0.6018109 \n",
      "\n",
      "Original sentence: spela min favorit podcast tack\n",
      "Target sentence: spiel bitte meinen lieblings podcast\n",
      "Generated sentence: spiel bitte meinen lieblings podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.8941219\n",
      "Cossine similarity to target: 0.89412194 \n",
      "\n",
      "Original sentence: starta podcasten mitt i maten\n",
      "Target sentence: starte den this week for dinner podcast\n",
      "Generated sentence: starte die nächste episode in einem podcast\n",
      "BLEU score: 0.2857142857142857\n",
      "Cossine similarity to generated: 0.86905044\n",
      "Cossine similarity to target: 0.5557016 \n",
      "\n",
      "Original sentence: spela dagens podcast från mi\n",
      "Target sentence: spielen die heutige podcast von die mi\n",
      "Generated sentence: spielen die heutige podcast von die mi\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.64131504\n",
      "Cossine similarity to target: 0.64131504 \n",
      "\n",
      "Original sentence: spela nästa podcast\n",
      "Target sentence: spiel den nächsten podcast\n",
      "Generated sentence: spiel nächsten podcast\n",
      "BLEU score: 0.7165313105737893\n",
      "Cossine similarity to generated: 0.8838748\n",
      "Cossine similarity to target: 0.7521727 \n",
      "\n",
      "Original sentence: spela föregående podd\n",
      "Target sentence: spiel den letzten podcast\n",
      "Generated sentence: spiel nächsten podcast\n",
      "BLEU score: 0.47768754038252614\n",
      "Cossine similarity to generated: 0.78641504\n",
      "Cossine similarity to target: 0.638703 \n",
      "\n",
      "Original sentence: spela avsnitt av saker du borde veta i kön\n",
      "Target sentence: spielen folge auf sachen die sie in der warteschlange kennen sollten\n",
      "Generated sentence: kannst du sicherstellen dass das licht in der küche aus ist\n",
      "BLEU score: 0.18181818181818182\n",
      "Cossine similarity to generated: 0.8791102\n",
      "Cossine similarity to target: 0.8323574 \n",
      "\n",
      "Original sentence: spela en podcast\n",
      "Target sentence: spiel einen podcast\n",
      "Generated sentence: erstelle eine liste aller halloween veranstaltungen in hamburg\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.720078\n",
      "Cossine similarity to target: 0.6051782 \n",
      "\n",
      "Original sentence: hoppa över till nästa avsnitt av denna podcast\n",
      "Target sentence: springe zur nächsten folge vom podcast\n",
      "Generated sentence: spiel bitte die nächste episode von dem podcast\n",
      "BLEU score: 0.12500000000000003\n",
      "Cossine similarity to generated: 0.8861712\n",
      "Cossine similarity to target: 0.7956789 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <th>Bleu Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pt -&gt; de</th>\n",
       "      <td>0.672054</td>\n",
       "      <td>4.727530</td>\n",
       "      <td>0.217575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; sv -&gt; de</th>\n",
       "      <td>0.657271</td>\n",
       "      <td>4.815911</td>\n",
       "      <td>0.197072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Cosine Similarity  Euclidean Distance  Bleu Score\n",
       "pt -> de                 0.672054            4.727530    0.217575\n",
       "pt -> sv -> de           0.657271            4.815911    0.197072"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp6 = avaliate_possible_paths(['pt', 'sv', 'de'])\n",
    "exp6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb19ed3b",
   "metadata": {},
   "source": [
    "### Experiment #3: English - Swedish - Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f723a889",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: continue to next podcast\n",
      "Target sentence: continua col prossimo podcast\n",
      "Generated sentence: passa al prossimo episodio del podcast per favore\n",
      "BLEU score: 0.25\n",
      "Cossine similarity to generated: 0.8070029\n",
      "Cossine similarity to target: 0.63051754 \n",
      "\n",
      "Original sentence: start next podcast episode\n",
      "Target sentence: avvia il prossimo episodio del podcast\n",
      "Generated sentence: podcast prossimo episodio\n",
      "BLEU score: 0.36787944117144233\n",
      "Cossine similarity to generated: 0.71518207\n",
      "Cossine similarity to target: 0.6761684 \n",
      "\n",
      "Original sentence: play my favorite podcast please\n",
      "Target sentence: riproduci il mio podcast preferito per favore\n",
      "Generated sentence: vorrei ascoltare la playlist del mio matrimonio\n",
      "BLEU score: 0.14285714285714285\n",
      "Cossine similarity to generated: 0.86869645\n",
      "Cossine similarity to target: 0.81960255 \n",
      "\n",
      "Original sentence: start this week for dinner podcast\n",
      "Target sentence: avvia il podcast this week for dinner\n",
      "Generated sentence: per favore avvia musica classica per la cena adesso\n",
      "BLEU score: 0.11111111111111109\n",
      "Cossine similarity to generated: 0.7717012\n",
      "Cossine similarity to target: 0.5460218 \n",
      "\n",
      "Original sentence: play today's podcast from the mi\n",
      "Target sentence: riproduci il podcast di oggi\n",
      "Generated sentence: dai cinque stelle a questa canzone e salva il giudizio\n",
      "BLEU score: 0.10000000000000002\n",
      "Cossine similarity to generated: 0.58515394\n",
      "Cossine similarity to target: 0.49325496 \n",
      "\n",
      "Original sentence: play the next podcast\n",
      "Target sentence: riproduci il prossimo podcast\n",
      "Generated sentence: per favore riproduci il podcast\n",
      "BLEU score: 0.6\n",
      "Cossine similarity to generated: 0.7611816\n",
      "Cossine similarity to target: 0.7580359 \n",
      "\n",
      "Original sentence: play the previous podcast\n",
      "Target sentence: metti il podcast precedente\n",
      "Generated sentence: riproduci la playlist del musicista\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.7509137\n",
      "Cossine similarity to target: 0.7162944 \n",
      "\n",
      "Original sentence: play episode of stuff you should know in queue\n",
      "Target sentence: riproduci l' episodio di demoni urbani in coda\n",
      "Generated sentence: fammi sapere cosa si è accumulato nella mia casella di posta in arrivo dalle tre del pomeriggio\n",
      "BLEU score: 0.11764705882352941\n",
      "Cossine similarity to generated: 0.84652877\n",
      "Cossine similarity to target: 0.7846671 \n",
      "\n",
      "Original sentence: play a podcast\n",
      "Target sentence: riproduci un podcast\n",
      "Generated sentence: metti una stazione radio con un documentario\n",
      "BLEU score: 0.14285714285714285\n",
      "Cossine similarity to generated: 0.88698316\n",
      "Cossine similarity to target: 0.84001935 \n",
      "\n",
      "Original sentence: skip forward to the next episode of this podcast\n",
      "Target sentence: salta e vai al prossimo episodio di questo podcast\n",
      "Generated sentence: ricordami di comprare del prosciutto la prossima volta che sono al supermercato\n",
      "BLEU score: 0.16666666666666669\n",
      "Cossine similarity to generated: 0.8704387\n",
      "Cossine similarity to target: 0.84412205 \n",
      "\n",
      "Original sentence: continue to next podcast\n",
      "Target sentence: fortsätt till nästa podcast\n",
      "Generated sentence: lägg till påminnelse den fjärde april att gå till tandläkaren\n",
      "BLEU score: 0.10000000000000002\n",
      "Cossine similarity to generated: 0.8260703\n",
      "Cossine similarity to target: 0.8100806 \n",
      "\n",
      "Original sentence: start next podcast episode\n",
      "Target sentence: starta nästa podcast avsnitt\n",
      "Generated sentence: starta nästa podcast avsnitt\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.8320949\n",
      "Cossine similarity to target: 0.8320949 \n",
      "\n",
      "Original sentence: play my favorite podcast please\n",
      "Target sentence: spela min favorit podcast tack\n",
      "Generated sentence: spela min favorit podcast\n",
      "BLEU score: 0.7788007830714049\n",
      "Cossine similarity to generated: 0.929883\n",
      "Cossine similarity to target: 0.91526335 \n",
      "\n",
      "Original sentence: start this week for dinner podcast\n",
      "Target sentence: starta podcasten mitt i maten\n",
      "Generated sentence: radera kalender händelser för den här veckan\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.7882852\n",
      "Cossine similarity to target: 0.5829184 \n",
      "\n",
      "Original sentence: play today's podcast from the mi\n",
      "Target sentence: spela dagens podcast från mi\n",
      "Generated sentence: spela dagens podcast från mi\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.65915656\n",
      "Cossine similarity to target: 0.6591566 \n",
      "\n",
      "Original sentence: play the next podcast\n",
      "Target sentence: spela nästa podcast\n",
      "Generated sentence: spela nästa podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.8110575\n",
      "Cossine similarity to target: 0.8110575 \n",
      "\n",
      "Original sentence: play the previous podcast\n",
      "Target sentence: spela föregående podd\n",
      "Generated sentence: spela den nyaste podcasten\n",
      "BLEU score: 0.25\n",
      "Cossine similarity to generated: 0.79540294\n",
      "Cossine similarity to target: 0.7231896 \n",
      "\n",
      "Original sentence: play episode of stuff you should know in queue\n",
      "Target sentence: spela avsnitt av saker du borde veta i kön\n",
      "Generated sentence: spela avsnitt av saker du borde veta i kön\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.89087546\n",
      "Cossine similarity to target: 0.8908755 \n",
      "\n",
      "Original sentence: play a podcast\n",
      "Target sentence: spela en podcast\n",
      "Generated sentence: spela en podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.9163576\n",
      "Cossine similarity to target: 0.9163574 \n",
      "\n",
      "Original sentence: skip forward to the next episode of this podcast\n",
      "Target sentence: hoppa över till nästa avsnitt av denna podcast\n",
      "Generated sentence: hoppa till nästa avsnitt av den här podden\n",
      "BLEU score: 0.625\n",
      "Cossine similarity to generated: 0.90552044\n",
      "Cossine similarity to target: 0.8747552 \n",
      "\n",
      "Original sentence: fortsätt till nästa podcast\n",
      "Target sentence: continua col prossimo podcast\n",
      "Generated sentence: riproduci il prossimo episodio del podcast per favore\n",
      "BLEU score: 0.25\n",
      "Cossine similarity to generated: 0.80310893\n",
      "Cossine similarity to target: 0.6756545 \n",
      "\n",
      "Original sentence: starta nästa podcast avsnitt\n",
      "Target sentence: avvia il prossimo episodio del podcast\n",
      "Generated sentence: inizia il prossimo episodio podcast\n",
      "BLEU score: 0.6549846024623855\n",
      "Cossine similarity to generated: 0.7253101\n",
      "Cossine similarity to target: 0.7093684 \n",
      "\n",
      "Original sentence: spela min favorit podcast tack\n",
      "Target sentence: riproduci il mio podcast preferito per favore\n",
      "Generated sentence: riproduci il mio podcast preferito per favore\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.84227693\n",
      "Cossine similarity to target: 0.8422769 \n",
      "\n",
      "Original sentence: starta podcasten mitt i maten\n",
      "Target sentence: avvia il podcast this week for dinner\n",
      "Generated sentence: avvertimi il giorno prima della mia gita in toscana\n",
      "BLEU score: 0.11111111111111109\n",
      "Cossine similarity to generated: 0.8224749\n",
      "Cossine similarity to target: 0.54524654 \n",
      "\n",
      "Original sentence: spela dagens podcast från mi\n",
      "Target sentence: riproduci il podcast di oggi\n",
      "Generated sentence: metti su la mia playlist di musica rap preferita\n",
      "BLEU score: 0.11111111111111109\n",
      "Cossine similarity to generated: 0.58171374\n",
      "Cossine similarity to target: 0.51381004 \n",
      "\n",
      "Original sentence: spela nästa podcast\n",
      "Target sentence: riproduci il prossimo podcast\n",
      "Generated sentence: inizia il prossimo episodio podcast\n",
      "BLEU score: 0.6\n",
      "Cossine similarity to generated: 0.7148062\n",
      "Cossine similarity to target: 0.69614536 \n",
      "\n",
      "Original sentence: spela föregående podd\n",
      "Target sentence: metti il podcast precedente\n",
      "Generated sentence: riproduci questo podcast\n",
      "BLEU score: 0.23884377019126307\n",
      "Cossine similarity to generated: 0.63986135\n",
      "Cossine similarity to target: 0.53211224 \n",
      "\n",
      "Original sentence: spela avsnitt av saker du borde veta i kön\n",
      "Target sentence: riproduci l' episodio di demoni urbani in coda\n",
      "Generated sentence: se sono le otto di sera nella costa orientale che ore sono a sacramento in california\n",
      "BLEU score: 0.12500000000000003\n",
      "Cossine similarity to generated: 0.826002\n",
      "Cossine similarity to target: 0.72674316 \n",
      "\n",
      "Original sentence: spela en podcast\n",
      "Target sentence: riproduci un podcast\n",
      "Generated sentence: metti una stazione radio con un documentario\n",
      "BLEU score: 0.14285714285714285\n",
      "Cossine similarity to generated: 0.8107955\n",
      "Cossine similarity to target: 0.7573109 \n",
      "\n",
      "Original sentence: hoppa över till nästa avsnitt av denna podcast\n",
      "Target sentence: salta e vai al prossimo episodio di questo podcast\n",
      "Generated sentence: dammi la lista di tutti gli eventi in arrivo il prossimo mese e imposta delle notifiche per tutti\n",
      "BLEU score: 0.16666666666666669\n",
      "Cossine similarity to generated: 0.83050454\n",
      "Cossine similarity to target: 0.7907162 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <th>Bleu Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en -&gt; it</th>\n",
       "      <td>0.708238</td>\n",
       "      <td>5.442024</td>\n",
       "      <td>0.225563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; sv -&gt; it</th>\n",
       "      <td>0.692051</td>\n",
       "      <td>5.569716</td>\n",
       "      <td>0.190160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Cosine Similarity  Euclidean Distance  Bleu Score\n",
       "en -> it                 0.708238            5.442024    0.225563\n",
       "en -> sv -> it           0.692051            5.569716    0.190160"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp7 = avaliate_possible_paths(['en', 'sv', 'it'])\n",
    "exp7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fd5770",
   "metadata": {},
   "source": [
    "### Experiment #4: English - Spanish - Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d04b0f76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: continue to next podcast\n",
      "Target sentence: continua col prossimo podcast\n",
      "Generated sentence: passa al prossimo episodio del podcast per favore\n",
      "BLEU score: 0.25\n",
      "Cossine similarity to generated: 0.8070029\n",
      "Cossine similarity to target: 0.63051754 \n",
      "\n",
      "Original sentence: start next podcast episode\n",
      "Target sentence: avvia il prossimo episodio del podcast\n",
      "Generated sentence: podcast prossimo episodio\n",
      "BLEU score: 0.36787944117144233\n",
      "Cossine similarity to generated: 0.71518207\n",
      "Cossine similarity to target: 0.6761684 \n",
      "\n",
      "Original sentence: play my favorite podcast please\n",
      "Target sentence: riproduci il mio podcast preferito per favore\n",
      "Generated sentence: vorrei ascoltare la playlist del mio matrimonio\n",
      "BLEU score: 0.14285714285714285\n",
      "Cossine similarity to generated: 0.86869645\n",
      "Cossine similarity to target: 0.81960255 \n",
      "\n",
      "Original sentence: start this week for dinner podcast\n",
      "Target sentence: avvia il podcast this week for dinner\n",
      "Generated sentence: per favore avvia musica classica per la cena adesso\n",
      "BLEU score: 0.11111111111111109\n",
      "Cossine similarity to generated: 0.7717012\n",
      "Cossine similarity to target: 0.5460218 \n",
      "\n",
      "Original sentence: play today's podcast from the mi\n",
      "Target sentence: riproduci il podcast di oggi\n",
      "Generated sentence: dai cinque stelle a questa canzone e salva il giudizio\n",
      "BLEU score: 0.10000000000000002\n",
      "Cossine similarity to generated: 0.58515394\n",
      "Cossine similarity to target: 0.49325496 \n",
      "\n",
      "Original sentence: play the next podcast\n",
      "Target sentence: riproduci il prossimo podcast\n",
      "Generated sentence: per favore riproduci il podcast\n",
      "BLEU score: 0.6\n",
      "Cossine similarity to generated: 0.7611816\n",
      "Cossine similarity to target: 0.7580359 \n",
      "\n",
      "Original sentence: play the previous podcast\n",
      "Target sentence: metti il podcast precedente\n",
      "Generated sentence: riproduci la playlist del musicista\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.7509137\n",
      "Cossine similarity to target: 0.7162944 \n",
      "\n",
      "Original sentence: play episode of stuff you should know in queue\n",
      "Target sentence: riproduci l' episodio di demoni urbani in coda\n",
      "Generated sentence: fammi sapere cosa si è accumulato nella mia casella di posta in arrivo dalle tre del pomeriggio\n",
      "BLEU score: 0.11764705882352941\n",
      "Cossine similarity to generated: 0.84652877\n",
      "Cossine similarity to target: 0.7846671 \n",
      "\n",
      "Original sentence: play a podcast\n",
      "Target sentence: riproduci un podcast\n",
      "Generated sentence: metti una stazione radio con un documentario\n",
      "BLEU score: 0.14285714285714285\n",
      "Cossine similarity to generated: 0.88698316\n",
      "Cossine similarity to target: 0.84001935 \n",
      "\n",
      "Original sentence: skip forward to the next episode of this podcast\n",
      "Target sentence: salta e vai al prossimo episodio di questo podcast\n",
      "Generated sentence: ricordami di comprare del prosciutto la prossima volta che sono al supermercato\n",
      "BLEU score: 0.16666666666666669\n",
      "Cossine similarity to generated: 0.8704387\n",
      "Cossine similarity to target: 0.84412205 \n",
      "\n",
      "Original sentence: continue to next podcast\n",
      "Target sentence: continuar con el siguiente podcast\n",
      "Generated sentence: el camino mas cercano para volver a casa\n",
      "BLEU score: 0.12500000000000003\n",
      "Cossine similarity to generated: 0.8241549\n",
      "Cossine similarity to target: 0.6452859 \n",
      "\n",
      "Original sentence: start next podcast episode\n",
      "Target sentence: empieza el siguiente episodio del podcast\n",
      "Generated sentence: podcast siguiente episodio\n",
      "BLEU score: 0.36787944117144233\n",
      "Cossine similarity to generated: 0.7605107\n",
      "Cossine similarity to target: 0.6733025 \n",
      "\n",
      "Original sentence: play my favorite podcast please\n",
      "Target sentence: pon mi podcast favorito por favor\n",
      "Generated sentence: pon de nuevo mi último podcast\n",
      "BLEU score: 0.5\n",
      "Cossine similarity to generated: 0.9123432\n",
      "Cossine similarity to target: 0.90411335 \n",
      "\n",
      "Original sentence: start this week for dinner podcast\n",
      "Target sentence: comienza esta semana para cenar el podcast\n",
      "Generated sentence: comienza esta semana para cenar el podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.85432696\n",
      "Cossine similarity to target: 0.85432696 \n",
      "\n",
      "Original sentence: play today's podcast from the mi\n",
      "Target sentence: pon el podcast de hoy del\n",
      "Generated sentence: pon mi canción de rap y rock uno tras otro\n",
      "BLEU score: 0.2\n",
      "Cossine similarity to generated: 0.58046746\n",
      "Cossine similarity to target: 0.5232377 \n",
      "\n",
      "Original sentence: play the next podcast\n",
      "Target sentence: reproducir el próximo podcast\n",
      "Generated sentence: pon el siguiente episodio de este podcast\n",
      "BLEU score: 0.2857142857142857\n",
      "Cossine similarity to generated: 0.7880002\n",
      "Cossine similarity to target: 0.6992792 \n",
      "\n",
      "Original sentence: play the previous podcast\n",
      "Target sentence: pon el podcast anterior\n",
      "Generated sentence: pon el siguiente episodio de este podcast\n",
      "BLEU score: 0.42857142857142855\n",
      "Cossine similarity to generated: 0.80019975\n",
      "Cossine similarity to target: 0.77351195 \n",
      "\n",
      "Original sentence: play episode of stuff you should know in queue\n",
      "Target sentence: pon el episodio de ted en español en cola\n",
      "Generated sentence: qué hay de nuevo en el mercado de valores\n",
      "BLEU score: 0.3333333333333333\n",
      "Cossine similarity to generated: 0.8636221\n",
      "Cossine similarity to target: 0.80281806 \n",
      "\n",
      "Original sentence: play a podcast\n",
      "Target sentence: pon un podcast\n",
      "Generated sentence: pon un algo de radio\n",
      "BLEU score: 0.4\n",
      "Cossine similarity to generated: 0.8634953\n",
      "Cossine similarity to target: 0.8601861 \n",
      "\n",
      "Original sentence: skip forward to the next episode of this podcast\n",
      "Target sentence: salta hacia el siguiente episodio de este podcast\n",
      "Generated sentence: salta al siguiente episodio de este podcast\n",
      "BLEU score: 0.7430381997858699\n",
      "Cossine similarity to generated: 0.87560165\n",
      "Cossine similarity to target: 0.86805564 \n",
      "\n",
      "Original sentence: continuar con el siguiente podcast\n",
      "Target sentence: continua col prossimo podcast\n",
      "Generated sentence: che succede con il nuovo fornitore\n",
      "BLEU score: 0\n",
      "Cossine similarity to generated: 0.9048711\n",
      "Cossine similarity to target: 0.73056847 \n",
      "\n",
      "Original sentence: empieza el siguiente episodio del podcast\n",
      "Target sentence: avvia il prossimo episodio del podcast\n",
      "Generated sentence: avvia il prossimo episodio del podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.9203148\n",
      "Cossine similarity to target: 0.92031485 \n",
      "\n",
      "Original sentence: pon mi podcast favorito por favor\n",
      "Target sentence: riproduci il mio podcast preferito per favore\n",
      "Generated sentence: riproduci il mio podcast preferito per favore\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.8459637\n",
      "Cossine similarity to target: 0.8459638 \n",
      "\n",
      "Original sentence: comienza esta semana para cenar el podcast\n",
      "Target sentence: avvia il podcast this week for dinner\n",
      "Generated sentence: come sarà il tempo questa settimana\n",
      "BLEU score: 0.141080287481769\n",
      "Cossine similarity to generated: 0.85507226\n",
      "Cossine similarity to target: 0.6465745 \n",
      "\n",
      "Original sentence: pon el podcast de hoy del\n",
      "Target sentence: riproduci il podcast di oggi\n",
      "Generated sentence: riproduci il podcast di francesco costa salvato sul dispositivo\n",
      "BLEU score: 0.4444444444444444\n",
      "Cossine similarity to generated: 0.8831555\n",
      "Cossine similarity to target: 0.8816486 \n",
      "\n",
      "Original sentence: reproducir el próximo podcast\n",
      "Target sentence: riproduci il prossimo podcast\n",
      "Generated sentence: inizia il prossimo episodio podcast\n",
      "BLEU score: 0.6\n",
      "Cossine similarity to generated: 0.93121487\n",
      "Cossine similarity to target: 0.9267309 \n",
      "\n",
      "Original sentence: pon el podcast anterior\n",
      "Target sentence: metti il podcast precedente\n",
      "Generated sentence: metti il podcast precedente\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.86170566\n",
      "Cossine similarity to target: 0.86170554 \n",
      "\n",
      "Original sentence: pon el episodio de ted en español en cola\n",
      "Target sentence: riproduci l' episodio di demoni urbani in coda\n",
      "Generated sentence: in che giorno della settimana cade il quindici marzo\n",
      "BLEU score: 0.11111111111111109\n",
      "Cossine similarity to generated: 0.83800566\n",
      "Cossine similarity to target: 0.740531 \n",
      "\n",
      "Original sentence: pon un podcast\n",
      "Target sentence: riproduci un podcast\n",
      "Generated sentence: riproduci un podcast\n",
      "BLEU score: 1.0\n",
      "Cossine similarity to generated: 0.885275\n",
      "Cossine similarity to target: 0.885275 \n",
      "\n",
      "Original sentence: salta hacia el siguiente episodio de este podcast\n",
      "Target sentence: salta e vai al prossimo episodio di questo podcast\n",
      "Generated sentence: riproduci il prossimo episodio di questo podcast\n",
      "BLEU score: 0.5367694950537757\n",
      "Cossine similarity to generated: 0.91169524\n",
      "Cossine similarity to target: 0.81966096 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <th>Bleu Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en -&gt; it</th>\n",
       "      <td>0.708238</td>\n",
       "      <td>5.442024</td>\n",
       "      <td>0.225563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; es -&gt; it</th>\n",
       "      <td>0.701003</td>\n",
       "      <td>5.494420</td>\n",
       "      <td>0.211460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Cosine Similarity  Euclidean Distance  Bleu Score\n",
       "en -> it                 0.708238            5.442024    0.225563\n",
       "en -> es -> it           0.701003            5.494420    0.211460"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp8 = avaliate_possible_paths(['en', 'es', 'it'])\n",
    "exp8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09768a36",
   "metadata": {},
   "source": [
    "## Saving results to spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "149a99ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = 'results.xlsx'\n",
    "with pd.ExcelWriter(path) as writer:\n",
    "    exp1.to_excel(writer, sheet_name = 'Study case 1')\n",
    "    exp2.to_excel(writer, sheet_name = 'Study case 2')\n",
    "    exp3.to_excel(writer, sheet_name = 'Study case 3')\n",
    "    exp4.to_excel(writer, sheet_name = 'Study case 4')\n",
    "    exp5.to_excel(writer, sheet_name = 'Experiment 1')\n",
    "    exp6.to_excel(writer, sheet_name = 'Experiment 2')\n",
    "    exp7.to_excel(writer, sheet_name = 'Experiment 3')\n",
    "    exp8.to_excel(writer, sheet_name = 'Experiment 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a77d8",
   "metadata": {},
   "source": [
    "## New results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ff0c9a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rom = ['pt', 'it', 'es'] #romance\n",
    "ang = ['en', 'sv', 'de'] #anglo-saxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2147169b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def avaliate_multiple_paths(paths):\n",
    "    '''\n",
    "    Avaliate multiple paths\n",
    "    \n",
    "    Params:\n",
    "    - languages: list of paths\n",
    "    \n",
    "    Return:\n",
    "    - Dataframe with the score of each path on cossine similarity, euclidean distance and Bleu score\n",
    "    \n",
    "    Example of usage:\n",
    "    avaliate_paths([('pt', 'es'), ('it', 'en')])\n",
    "    '''\n",
    "    \n",
    "    scores = []\n",
    "    index = [ ' -> '.join(p) for p in paths]\n",
    "    \n",
    "    for p in paths:\n",
    "        print('->'.join(p), end='...')\n",
    "        scores.append(avaliate_path(p, debug=False))\n",
    "        print('ok')\n",
    "        \n",
    "    df = pd.DataFrame(data=scores, columns=['Cosine Similarity', 'Euclidean Distance', 'Bleu Score'], index = index)\n",
    "    # df = pd.DataFrame(data = scores, columns = ['Cosine Similarity', 'Euclidean Distance'], index = index)\n",
    "    print(f\"Cosine similarity mean = {df['Cosine Similarity'].mean()}\")\n",
    "    print(f\"Euclidean distance mean = {df['Euclidean Distance'].mean()}\")\n",
    "    print(f\"BLEU mean = {df['Bleu Score'].mean()}\")\n",
    "    print(f\"Standard deviation: \\n{df.std()}\\n\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b059cbd",
   "metadata": {},
   "source": [
    "### Direct translation, same family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be6633e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt->it...ok\n",
      "pt->es...ok\n",
      "it->pt...ok\n",
      "it->es...ok\n",
      "es->pt...ok\n",
      "es->it...ok\n",
      "en->sv...ok\n",
      "en->de...ok\n",
      "sv->en...ok\n",
      "sv->de...ok\n",
      "de->en...ok\n",
      "de->sv...ok\n",
      "Cosine similarity mean = 0.7430349514544252\n",
      "Euclidean distance mean = 4.509141633167239\n",
      "BLEU mean = 0.3379800452414116\n",
      "Standard deviation: \n",
      "Cosine Similarity     0.023056\n",
      "Euclidean Distance    0.251984\n",
      "Bleu Score            0.061631\n",
      "dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <th>Bleu Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pt -&gt; it</th>\n",
       "      <td>0.704933</td>\n",
       "      <td>4.668492</td>\n",
       "      <td>0.269054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; es</th>\n",
       "      <td>0.761036</td>\n",
       "      <td>4.187897</td>\n",
       "      <td>0.412073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; pt</th>\n",
       "      <td>0.704933</td>\n",
       "      <td>4.668492</td>\n",
       "      <td>0.265319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; es</th>\n",
       "      <td>0.735707</td>\n",
       "      <td>4.464251</td>\n",
       "      <td>0.312520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; pt</th>\n",
       "      <td>0.761036</td>\n",
       "      <td>4.187897</td>\n",
       "      <td>0.397233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; it</th>\n",
       "      <td>0.735707</td>\n",
       "      <td>4.464250</td>\n",
       "      <td>0.315689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; sv</th>\n",
       "      <td>0.773172</td>\n",
       "      <td>4.657575</td>\n",
       "      <td>0.409668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; de</th>\n",
       "      <td>0.751231</td>\n",
       "      <td>4.850476</td>\n",
       "      <td>0.320940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; en</th>\n",
       "      <td>0.773171</td>\n",
       "      <td>4.657575</td>\n",
       "      <td>0.423461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; de</th>\n",
       "      <td>0.732132</td>\n",
       "      <td>4.226160</td>\n",
       "      <td>0.252610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; en</th>\n",
       "      <td>0.751231</td>\n",
       "      <td>4.850476</td>\n",
       "      <td>0.366715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; sv</th>\n",
       "      <td>0.732132</td>\n",
       "      <td>4.226159</td>\n",
       "      <td>0.310478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Cosine Similarity  Euclidean Distance  Bleu Score\n",
       "pt -> it           0.704933            4.668492    0.269054\n",
       "pt -> es           0.761036            4.187897    0.412073\n",
       "it -> pt           0.704933            4.668492    0.265319\n",
       "it -> es           0.735707            4.464251    0.312520\n",
       "es -> pt           0.761036            4.187897    0.397233\n",
       "es -> it           0.735707            4.464250    0.315689\n",
       "en -> sv           0.773172            4.657575    0.409668\n",
       "en -> de           0.751231            4.850476    0.320940\n",
       "sv -> en           0.773171            4.657575    0.423461\n",
       "sv -> de           0.732132            4.226160    0.252610\n",
       "de -> en           0.751231            4.850476    0.366715\n",
       "de -> sv           0.732132            4.226159    0.310478"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tradução direta mesma família\n",
    "rom_rom = list(it.permutations(rom, 2))\n",
    "ang_ang = list(it.permutations(ang, 2))\n",
    "\n",
    "direct_same = avaliate_multiple_paths(rom_rom + ang_ang)\n",
    "direct_same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f957f03f",
   "metadata": {},
   "source": [
    "### Direct translation, different family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "435d7c5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt->en...ok\n",
      "pt->sv...ok\n",
      "pt->de...ok\n",
      "it->en...ok\n",
      "it->sv...ok\n",
      "it->de...ok\n",
      "es->en...ok\n",
      "es->sv...ok\n",
      "es->de...ok\n",
      "en->pt...ok\n",
      "en->it...ok\n",
      "en->es...ok\n",
      "sv->pt...ok\n",
      "sv->it...ok\n",
      "sv->es...ok\n",
      "de->pt...ok\n",
      "de->it...ok\n",
      "de->es...ok\n",
      "Cosine similarity mean = 0.6967593549816353\n",
      "Euclidean distance mean = 5.01797187808681\n",
      "BLEU mean = 0.23339732741645436\n",
      "Standard deviation: \n",
      "Cosine Similarity     0.021032\n",
      "Euclidean Distance    0.241808\n",
      "Bleu Score            0.060107\n",
      "dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <th>Bleu Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pt -&gt; en</th>\n",
       "      <td>0.710168</td>\n",
       "      <td>5.357246</td>\n",
       "      <td>0.330341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; sv</th>\n",
       "      <td>0.678615</td>\n",
       "      <td>4.972782</td>\n",
       "      <td>0.230546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; de</th>\n",
       "      <td>0.672054</td>\n",
       "      <td>4.727530</td>\n",
       "      <td>0.217575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; en</th>\n",
       "      <td>0.708238</td>\n",
       "      <td>5.442024</td>\n",
       "      <td>0.283460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; sv</th>\n",
       "      <td>0.684280</td>\n",
       "      <td>5.065522</td>\n",
       "      <td>0.214822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; de</th>\n",
       "      <td>0.683391</td>\n",
       "      <td>4.834031</td>\n",
       "      <td>0.181349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; en</th>\n",
       "      <td>0.742659</td>\n",
       "      <td>5.080621</td>\n",
       "      <td>0.375541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; sv</th>\n",
       "      <td>0.701439</td>\n",
       "      <td>4.921671</td>\n",
       "      <td>0.261141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; de</th>\n",
       "      <td>0.689991</td>\n",
       "      <td>4.760320</td>\n",
       "      <td>0.222460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; pt</th>\n",
       "      <td>0.710168</td>\n",
       "      <td>5.357246</td>\n",
       "      <td>0.251207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; it</th>\n",
       "      <td>0.708238</td>\n",
       "      <td>5.442024</td>\n",
       "      <td>0.225563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; es</th>\n",
       "      <td>0.742659</td>\n",
       "      <td>5.080620</td>\n",
       "      <td>0.317150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; pt</th>\n",
       "      <td>0.678615</td>\n",
       "      <td>4.972782</td>\n",
       "      <td>0.168319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; it</th>\n",
       "      <td>0.684280</td>\n",
       "      <td>5.065522</td>\n",
       "      <td>0.161345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; es</th>\n",
       "      <td>0.701439</td>\n",
       "      <td>4.921672</td>\n",
       "      <td>0.206272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; pt</th>\n",
       "      <td>0.672054</td>\n",
       "      <td>4.727530</td>\n",
       "      <td>0.174930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; it</th>\n",
       "      <td>0.683391</td>\n",
       "      <td>4.834032</td>\n",
       "      <td>0.177489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; es</th>\n",
       "      <td>0.689991</td>\n",
       "      <td>4.760320</td>\n",
       "      <td>0.201642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Cosine Similarity  Euclidean Distance  Bleu Score\n",
       "pt -> en           0.710168            5.357246    0.330341\n",
       "pt -> sv           0.678615            4.972782    0.230546\n",
       "pt -> de           0.672054            4.727530    0.217575\n",
       "it -> en           0.708238            5.442024    0.283460\n",
       "it -> sv           0.684280            5.065522    0.214822\n",
       "it -> de           0.683391            4.834031    0.181349\n",
       "es -> en           0.742659            5.080621    0.375541\n",
       "es -> sv           0.701439            4.921671    0.261141\n",
       "es -> de           0.689991            4.760320    0.222460\n",
       "en -> pt           0.710168            5.357246    0.251207\n",
       "en -> it           0.708238            5.442024    0.225563\n",
       "en -> es           0.742659            5.080620    0.317150\n",
       "sv -> pt           0.678615            4.972782    0.168319\n",
       "sv -> it           0.684280            5.065522    0.161345\n",
       "sv -> es           0.701439            4.921672    0.206272\n",
       "de -> pt           0.672054            4.727530    0.174930\n",
       "de -> it           0.683391            4.834032    0.177489\n",
       "de -> es           0.689991            4.760320    0.201642"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tradução direta familia diferente\n",
    "rom_ang = list(it.product(rom, ang))\n",
    "ang_rom = list(it.product(ang, rom))\n",
    "\n",
    "direct_diff = avaliate_multiple_paths(rom_ang + ang_rom)\n",
    "direct_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31104cfc",
   "metadata": {},
   "source": [
    "### Indirect translation, same family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b58fe82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt->it->es...ok\n",
      "pt->es->it...ok\n",
      "it->pt->es...ok\n",
      "it->es->pt...ok\n",
      "es->pt->it...ok\n",
      "es->it->pt...ok\n",
      "en->sv->de...ok\n",
      "en->de->sv...ok\n",
      "sv->en->de...ok\n",
      "sv->de->en...ok\n",
      "de->en->sv...ok\n",
      "de->sv->en...ok\n",
      "Cosine similarity mean = 0.731165156107012\n",
      "Euclidean distance mean = 4.598723040890902\n",
      "BLEU mean = 0.31006295799143163\n",
      "Standard deviation: \n",
      "Cosine Similarity     0.020582\n",
      "Euclidean Distance    0.262778\n",
      "Bleu Score            0.054278\n",
      "dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <th>Bleu Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pt -&gt; it -&gt; es</th>\n",
       "      <td>0.748819</td>\n",
       "      <td>4.274804</td>\n",
       "      <td>0.392679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; es -&gt; it</th>\n",
       "      <td>0.696832</td>\n",
       "      <td>4.728963</td>\n",
       "      <td>0.251871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; pt -&gt; es</th>\n",
       "      <td>0.723071</td>\n",
       "      <td>4.573865</td>\n",
       "      <td>0.293648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; es -&gt; pt</th>\n",
       "      <td>0.696831</td>\n",
       "      <td>4.728964</td>\n",
       "      <td>0.251933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; pt -&gt; it</th>\n",
       "      <td>0.723071</td>\n",
       "      <td>4.573865</td>\n",
       "      <td>0.282416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; it -&gt; pt</th>\n",
       "      <td>0.748819</td>\n",
       "      <td>4.274803</td>\n",
       "      <td>0.372951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; sv -&gt; de</th>\n",
       "      <td>0.737642</td>\n",
       "      <td>4.951251</td>\n",
       "      <td>0.288412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; de -&gt; sv</th>\n",
       "      <td>0.757116</td>\n",
       "      <td>4.780757</td>\n",
       "      <td>0.369750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; en -&gt; de</th>\n",
       "      <td>0.723510</td>\n",
       "      <td>4.282699</td>\n",
       "      <td>0.234285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; de -&gt; en</th>\n",
       "      <td>0.757116</td>\n",
       "      <td>4.780756</td>\n",
       "      <td>0.364858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; en -&gt; sv</th>\n",
       "      <td>0.723511</td>\n",
       "      <td>4.282697</td>\n",
       "      <td>0.286070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; sv -&gt; en</th>\n",
       "      <td>0.737642</td>\n",
       "      <td>4.951252</td>\n",
       "      <td>0.331883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Cosine Similarity  Euclidean Distance  Bleu Score\n",
       "pt -> it -> es           0.748819            4.274804    0.392679\n",
       "pt -> es -> it           0.696832            4.728963    0.251871\n",
       "it -> pt -> es           0.723071            4.573865    0.293648\n",
       "it -> es -> pt           0.696831            4.728964    0.251933\n",
       "es -> pt -> it           0.723071            4.573865    0.282416\n",
       "es -> it -> pt           0.748819            4.274803    0.372951\n",
       "en -> sv -> de           0.737642            4.951251    0.288412\n",
       "en -> de -> sv           0.757116            4.780757    0.369750\n",
       "sv -> en -> de           0.723510            4.282699    0.234285\n",
       "sv -> de -> en           0.757116            4.780756    0.364858\n",
       "de -> en -> sv           0.723511            4.282697    0.286070\n",
       "de -> sv -> en           0.737642            4.951252    0.331883"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tradução com idioma intermediario igual\n",
    "rom_rom_rom = list(it.permutations(rom, 3))\n",
    "ang_ang_ang = list(it.permutations(ang, 3))\n",
    "\n",
    "indirect_same = avaliate_multiple_paths(rom_rom_rom +  ang_ang_ang)\n",
    "indirect_same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f77aff4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Indirect translation, start language different family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "897c0b3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en->pt->it...ok\n",
      "sv->pt->it...ok\n",
      "de->pt->it...ok\n",
      "en->pt->es...ok\n",
      "sv->pt->es...ok\n",
      "de->pt->es...ok\n",
      "en->it->pt...ok\n",
      "sv->it->pt...ok\n",
      "de->it->pt...ok\n",
      "en->it->es...ok\n",
      "sv->it->es...ok\n",
      "de->it->es...ok\n",
      "en->es->pt...ok\n",
      "sv->es->pt...ok\n",
      "de->es->pt...ok\n",
      "en->es->it...ok\n",
      "sv->es->it...ok\n",
      "de->es->it...ok\n",
      "pt->en->sv...ok\n",
      "it->en->sv...ok\n",
      "es->en->sv...ok\n",
      "pt->en->de...ok\n",
      "it->en->de...ok\n",
      "es->en->de...ok\n",
      "pt->sv->en...ok\n",
      "it->sv->en...ok\n",
      "es->sv->en...ok\n",
      "pt->sv->de...ok\n",
      "it->sv->de...ok\n",
      "es->sv->de...ok\n",
      "pt->de->en...ok\n",
      "it->de->en...ok\n",
      "es->de->en...ok\n",
      "pt->de->sv...ok\n",
      "it->de->sv...ok\n",
      "es->de->sv...ok\n",
      "Cosine similarity mean = 0.6850931850757063\n",
      "Euclidean distance mean = 5.097010301046057\n",
      "BLEU mean = 0.21390608745277584\n",
      "Standard deviation: \n",
      "Cosine Similarity     0.018934\n",
      "Euclidean Distance    0.256419\n",
      "Bleu Score            0.052895\n",
      "dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <th>Bleu Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en -&gt; pt -&gt; it</th>\n",
       "      <td>0.695482</td>\n",
       "      <td>5.542440</td>\n",
       "      <td>0.194528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; pt -&gt; it</th>\n",
       "      <td>0.673986</td>\n",
       "      <td>5.132392</td>\n",
       "      <td>0.144900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; pt -&gt; it</th>\n",
       "      <td>0.674496</td>\n",
       "      <td>4.887265</td>\n",
       "      <td>0.164321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; pt -&gt; es</th>\n",
       "      <td>0.731230</td>\n",
       "      <td>5.173896</td>\n",
       "      <td>0.301534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; pt -&gt; es</th>\n",
       "      <td>0.691123</td>\n",
       "      <td>4.991087</td>\n",
       "      <td>0.192122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; pt -&gt; es</th>\n",
       "      <td>0.681299</td>\n",
       "      <td>4.817945</td>\n",
       "      <td>0.195222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; it -&gt; pt</th>\n",
       "      <td>0.698156</td>\n",
       "      <td>5.444389</td>\n",
       "      <td>0.227912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; it -&gt; pt</th>\n",
       "      <td>0.667184</td>\n",
       "      <td>5.040010</td>\n",
       "      <td>0.152837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; it -&gt; pt</th>\n",
       "      <td>0.658959</td>\n",
       "      <td>4.799254</td>\n",
       "      <td>0.157171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; it -&gt; es</th>\n",
       "      <td>0.726628</td>\n",
       "      <td>5.202614</td>\n",
       "      <td>0.285021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; it -&gt; es</th>\n",
       "      <td>0.687061</td>\n",
       "      <td>5.016478</td>\n",
       "      <td>0.185477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; it -&gt; es</th>\n",
       "      <td>0.677088</td>\n",
       "      <td>4.840245</td>\n",
       "      <td>0.189024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; es -&gt; pt</th>\n",
       "      <td>0.703957</td>\n",
       "      <td>5.403017</td>\n",
       "      <td>0.237620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; es -&gt; pt</th>\n",
       "      <td>0.673066</td>\n",
       "      <td>5.001632</td>\n",
       "      <td>0.158718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; es -&gt; pt</th>\n",
       "      <td>0.665095</td>\n",
       "      <td>4.762326</td>\n",
       "      <td>0.163247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; es -&gt; it</th>\n",
       "      <td>0.701003</td>\n",
       "      <td>5.494420</td>\n",
       "      <td>0.211460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; es -&gt; it</th>\n",
       "      <td>0.677265</td>\n",
       "      <td>5.103656</td>\n",
       "      <td>0.152397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; es -&gt; it</th>\n",
       "      <td>0.676984</td>\n",
       "      <td>4.869474</td>\n",
       "      <td>0.170312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; en -&gt; sv</th>\n",
       "      <td>0.672868</td>\n",
       "      <td>5.002662</td>\n",
       "      <td>0.227233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; en -&gt; sv</th>\n",
       "      <td>0.680602</td>\n",
       "      <td>5.083476</td>\n",
       "      <td>0.212040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; en -&gt; sv</th>\n",
       "      <td>0.693877</td>\n",
       "      <td>4.968661</td>\n",
       "      <td>0.238141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; en -&gt; de</th>\n",
       "      <td>0.662763</td>\n",
       "      <td>4.777122</td>\n",
       "      <td>0.196650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; en -&gt; de</th>\n",
       "      <td>0.673046</td>\n",
       "      <td>4.892868</td>\n",
       "      <td>0.173423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; en -&gt; de</th>\n",
       "      <td>0.681144</td>\n",
       "      <td>4.811578</td>\n",
       "      <td>0.206582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; sv -&gt; en</th>\n",
       "      <td>0.694102</td>\n",
       "      <td>5.482860</td>\n",
       "      <td>0.295168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; sv -&gt; en</th>\n",
       "      <td>0.692051</td>\n",
       "      <td>5.569715</td>\n",
       "      <td>0.254245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; sv -&gt; en</th>\n",
       "      <td>0.724229</td>\n",
       "      <td>5.226618</td>\n",
       "      <td>0.345239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; sv -&gt; de</th>\n",
       "      <td>0.657271</td>\n",
       "      <td>4.815911</td>\n",
       "      <td>0.197072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; sv -&gt; de</th>\n",
       "      <td>0.669590</td>\n",
       "      <td>4.921922</td>\n",
       "      <td>0.165780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; sv -&gt; de</th>\n",
       "      <td>0.676997</td>\n",
       "      <td>4.843306</td>\n",
       "      <td>0.207248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; de -&gt; en</th>\n",
       "      <td>0.691938</td>\n",
       "      <td>5.492896</td>\n",
       "      <td>0.297528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; de -&gt; en</th>\n",
       "      <td>0.689639</td>\n",
       "      <td>5.585932</td>\n",
       "      <td>0.239248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; de -&gt; en</th>\n",
       "      <td>0.722606</td>\n",
       "      <td>5.240709</td>\n",
       "      <td>0.342925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; de -&gt; sv</th>\n",
       "      <td>0.665412</td>\n",
       "      <td>5.057063</td>\n",
       "      <td>0.213003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; de -&gt; sv</th>\n",
       "      <td>0.668822</td>\n",
       "      <td>5.168057</td>\n",
       "      <td>0.181212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; de -&gt; sv</th>\n",
       "      <td>0.686334</td>\n",
       "      <td>5.028473</td>\n",
       "      <td>0.224056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Cosine Similarity  Euclidean Distance  Bleu Score\n",
       "en -> pt -> it           0.695482            5.542440    0.194528\n",
       "sv -> pt -> it           0.673986            5.132392    0.144900\n",
       "de -> pt -> it           0.674496            4.887265    0.164321\n",
       "en -> pt -> es           0.731230            5.173896    0.301534\n",
       "sv -> pt -> es           0.691123            4.991087    0.192122\n",
       "de -> pt -> es           0.681299            4.817945    0.195222\n",
       "en -> it -> pt           0.698156            5.444389    0.227912\n",
       "sv -> it -> pt           0.667184            5.040010    0.152837\n",
       "de -> it -> pt           0.658959            4.799254    0.157171\n",
       "en -> it -> es           0.726628            5.202614    0.285021\n",
       "sv -> it -> es           0.687061            5.016478    0.185477\n",
       "de -> it -> es           0.677088            4.840245    0.189024\n",
       "en -> es -> pt           0.703957            5.403017    0.237620\n",
       "sv -> es -> pt           0.673066            5.001632    0.158718\n",
       "de -> es -> pt           0.665095            4.762326    0.163247\n",
       "en -> es -> it           0.701003            5.494420    0.211460\n",
       "sv -> es -> it           0.677265            5.103656    0.152397\n",
       "de -> es -> it           0.676984            4.869474    0.170312\n",
       "pt -> en -> sv           0.672868            5.002662    0.227233\n",
       "it -> en -> sv           0.680602            5.083476    0.212040\n",
       "es -> en -> sv           0.693877            4.968661    0.238141\n",
       "pt -> en -> de           0.662763            4.777122    0.196650\n",
       "it -> en -> de           0.673046            4.892868    0.173423\n",
       "es -> en -> de           0.681144            4.811578    0.206582\n",
       "pt -> sv -> en           0.694102            5.482860    0.295168\n",
       "it -> sv -> en           0.692051            5.569715    0.254245\n",
       "es -> sv -> en           0.724229            5.226618    0.345239\n",
       "pt -> sv -> de           0.657271            4.815911    0.197072\n",
       "it -> sv -> de           0.669590            4.921922    0.165780\n",
       "es -> sv -> de           0.676997            4.843306    0.207248\n",
       "pt -> de -> en           0.691938            5.492896    0.297528\n",
       "it -> de -> en           0.689639            5.585932    0.239248\n",
       "es -> de -> en           0.722606            5.240709    0.342925\n",
       "pt -> de -> sv           0.665412            5.057063    0.213003\n",
       "it -> de -> sv           0.668822            5.168057    0.181212\n",
       "es -> de -> sv           0.686334            5.028473    0.224056"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ang_rom_rom = [(a1, r1, r2) for (r1, r2), a1 in it.product(rom_rom, ang)]\n",
    "rom_ang_ang = [(r1, a1, a2) for (a1, a2), r1 in it.product(ang_ang, rom)]\n",
    "\n",
    "indirect_start = avaliate_multiple_paths(ang_rom_rom +  rom_ang_ang)\n",
    "indirect_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aa8208",
   "metadata": {},
   "source": [
    "### Indirect translation, mid language different family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "775b8229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt->en->it...ok\n",
      "pt->sv->it...ok\n",
      "pt->de->it...ok\n",
      "pt->en->es...ok\n",
      "pt->sv->es...ok\n",
      "pt->de->es...ok\n",
      "it->en->pt...ok\n",
      "it->sv->pt...ok\n",
      "it->de->pt...ok\n",
      "it->en->es...ok\n",
      "it->sv->es...ok\n",
      "it->de->es...ok\n",
      "es->en->pt...ok\n",
      "es->sv->pt...ok\n",
      "es->de->pt...ok\n",
      "es->en->it...ok\n",
      "es->sv->it...ok\n",
      "es->de->it...ok\n",
      "en->pt->sv...ok\n",
      "en->it->sv...ok\n",
      "en->es->sv...ok\n",
      "en->pt->de...ok\n",
      "en->it->de...ok\n",
      "en->es->de...ok\n",
      "sv->pt->en...ok\n",
      "sv->it->en...ok\n",
      "sv->es->en...ok\n",
      "sv->pt->de...ok\n",
      "sv->it->de...ok\n",
      "sv->es->de...ok\n",
      "de->pt->en...ok\n",
      "de->it->en...ok\n",
      "de->es->en...ok\n",
      "de->pt->sv...ok\n",
      "de->it->sv...ok\n",
      "de->es->sv...ok\n",
      "Cosine similarity mean = 0.7218003548608741\n",
      "Euclidean distance mean = 4.686341819629901\n",
      "BLEU mean = 0.29597873164996785\n",
      "Standard deviation: \n",
      "Cosine Similarity     0.024257\n",
      "Euclidean Distance    0.234353\n",
      "Bleu Score            0.055582\n",
      "dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <th>Bleu Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pt -&gt; en -&gt; it</th>\n",
       "      <td>0.683885</td>\n",
       "      <td>4.847572</td>\n",
       "      <td>0.245341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; sv -&gt; it</th>\n",
       "      <td>0.677082</td>\n",
       "      <td>4.906317</td>\n",
       "      <td>0.226846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; de -&gt; it</th>\n",
       "      <td>0.678369</td>\n",
       "      <td>4.886759</td>\n",
       "      <td>0.235931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; en -&gt; es</th>\n",
       "      <td>0.735565</td>\n",
       "      <td>4.411218</td>\n",
       "      <td>0.394879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; sv -&gt; es</th>\n",
       "      <td>0.729514</td>\n",
       "      <td>4.463664</td>\n",
       "      <td>0.384818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; de -&gt; es</th>\n",
       "      <td>0.726058</td>\n",
       "      <td>4.489707</td>\n",
       "      <td>0.368706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; en -&gt; pt</th>\n",
       "      <td>0.683885</td>\n",
       "      <td>4.847571</td>\n",
       "      <td>0.228770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; sv -&gt; pt</th>\n",
       "      <td>0.677082</td>\n",
       "      <td>4.906317</td>\n",
       "      <td>0.215679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; de -&gt; pt</th>\n",
       "      <td>0.678369</td>\n",
       "      <td>4.886758</td>\n",
       "      <td>0.210590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; en -&gt; es</th>\n",
       "      <td>0.712411</td>\n",
       "      <td>4.667339</td>\n",
       "      <td>0.267075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; sv -&gt; es</th>\n",
       "      <td>0.706080</td>\n",
       "      <td>4.728230</td>\n",
       "      <td>0.256944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; de -&gt; es</th>\n",
       "      <td>0.706753</td>\n",
       "      <td>4.713403</td>\n",
       "      <td>0.260700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; en -&gt; pt</th>\n",
       "      <td>0.735565</td>\n",
       "      <td>4.411218</td>\n",
       "      <td>0.345403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; sv -&gt; pt</th>\n",
       "      <td>0.729514</td>\n",
       "      <td>4.463663</td>\n",
       "      <td>0.333358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; de -&gt; pt</th>\n",
       "      <td>0.726058</td>\n",
       "      <td>4.489707</td>\n",
       "      <td>0.326668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; en -&gt; it</th>\n",
       "      <td>0.712411</td>\n",
       "      <td>4.667338</td>\n",
       "      <td>0.270833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; sv -&gt; it</th>\n",
       "      <td>0.706081</td>\n",
       "      <td>4.728229</td>\n",
       "      <td>0.265295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; de -&gt; it</th>\n",
       "      <td>0.706752</td>\n",
       "      <td>4.713403</td>\n",
       "      <td>0.265286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; pt -&gt; sv</th>\n",
       "      <td>0.755973</td>\n",
       "      <td>4.801410</td>\n",
       "      <td>0.365872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; it -&gt; sv</th>\n",
       "      <td>0.753323</td>\n",
       "      <td>4.826162</td>\n",
       "      <td>0.357756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; es -&gt; sv</th>\n",
       "      <td>0.756480</td>\n",
       "      <td>4.795191</td>\n",
       "      <td>0.375386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; pt -&gt; de</th>\n",
       "      <td>0.737893</td>\n",
       "      <td>4.953251</td>\n",
       "      <td>0.290245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; it -&gt; de</th>\n",
       "      <td>0.735833</td>\n",
       "      <td>4.967798</td>\n",
       "      <td>0.290648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; es -&gt; de</th>\n",
       "      <td>0.739161</td>\n",
       "      <td>4.951684</td>\n",
       "      <td>0.290745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; pt -&gt; en</th>\n",
       "      <td>0.755973</td>\n",
       "      <td>4.801409</td>\n",
       "      <td>0.366426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; it -&gt; en</th>\n",
       "      <td>0.753323</td>\n",
       "      <td>4.826160</td>\n",
       "      <td>0.358744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; es -&gt; en</th>\n",
       "      <td>0.756480</td>\n",
       "      <td>4.795190</td>\n",
       "      <td>0.355710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; pt -&gt; de</th>\n",
       "      <td>0.719618</td>\n",
       "      <td>4.315253</td>\n",
       "      <td>0.230031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; it -&gt; de</th>\n",
       "      <td>0.717567</td>\n",
       "      <td>4.324225</td>\n",
       "      <td>0.230646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; es -&gt; de</th>\n",
       "      <td>0.720840</td>\n",
       "      <td>4.304974</td>\n",
       "      <td>0.229539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; pt -&gt; en</th>\n",
       "      <td>0.737893</td>\n",
       "      <td>4.953251</td>\n",
       "      <td>0.331443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; it -&gt; en</th>\n",
       "      <td>0.735833</td>\n",
       "      <td>4.967798</td>\n",
       "      <td>0.321169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; es -&gt; en</th>\n",
       "      <td>0.739161</td>\n",
       "      <td>4.951684</td>\n",
       "      <td>0.331077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; pt -&gt; sv</th>\n",
       "      <td>0.719618</td>\n",
       "      <td>4.315252</td>\n",
       "      <td>0.272880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; it -&gt; sv</th>\n",
       "      <td>0.717567</td>\n",
       "      <td>4.324226</td>\n",
       "      <td>0.270757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; es -&gt; sv</th>\n",
       "      <td>0.720840</td>\n",
       "      <td>4.304974</td>\n",
       "      <td>0.283035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Cosine Similarity  Euclidean Distance  Bleu Score\n",
       "pt -> en -> it           0.683885            4.847572    0.245341\n",
       "pt -> sv -> it           0.677082            4.906317    0.226846\n",
       "pt -> de -> it           0.678369            4.886759    0.235931\n",
       "pt -> en -> es           0.735565            4.411218    0.394879\n",
       "pt -> sv -> es           0.729514            4.463664    0.384818\n",
       "pt -> de -> es           0.726058            4.489707    0.368706\n",
       "it -> en -> pt           0.683885            4.847571    0.228770\n",
       "it -> sv -> pt           0.677082            4.906317    0.215679\n",
       "it -> de -> pt           0.678369            4.886758    0.210590\n",
       "it -> en -> es           0.712411            4.667339    0.267075\n",
       "it -> sv -> es           0.706080            4.728230    0.256944\n",
       "it -> de -> es           0.706753            4.713403    0.260700\n",
       "es -> en -> pt           0.735565            4.411218    0.345403\n",
       "es -> sv -> pt           0.729514            4.463663    0.333358\n",
       "es -> de -> pt           0.726058            4.489707    0.326668\n",
       "es -> en -> it           0.712411            4.667338    0.270833\n",
       "es -> sv -> it           0.706081            4.728229    0.265295\n",
       "es -> de -> it           0.706752            4.713403    0.265286\n",
       "en -> pt -> sv           0.755973            4.801410    0.365872\n",
       "en -> it -> sv           0.753323            4.826162    0.357756\n",
       "en -> es -> sv           0.756480            4.795191    0.375386\n",
       "en -> pt -> de           0.737893            4.953251    0.290245\n",
       "en -> it -> de           0.735833            4.967798    0.290648\n",
       "en -> es -> de           0.739161            4.951684    0.290745\n",
       "sv -> pt -> en           0.755973            4.801409    0.366426\n",
       "sv -> it -> en           0.753323            4.826160    0.358744\n",
       "sv -> es -> en           0.756480            4.795190    0.355710\n",
       "sv -> pt -> de           0.719618            4.315253    0.230031\n",
       "sv -> it -> de           0.717567            4.324225    0.230646\n",
       "sv -> es -> de           0.720840            4.304974    0.229539\n",
       "de -> pt -> en           0.737893            4.953251    0.331443\n",
       "de -> it -> en           0.735833            4.967798    0.321169\n",
       "de -> es -> en           0.739161            4.951684    0.331077\n",
       "de -> pt -> sv           0.719618            4.315252    0.272880\n",
       "de -> it -> sv           0.717567            4.324226    0.270757\n",
       "de -> es -> sv           0.720840            4.304974    0.283035"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tradução com idioma intermediario diferente\n",
    "rom_ang_rom = [(r1, a1, r2) for (r1, r2), a1 in it.product(rom_rom, ang)]\n",
    "ang_rom_ang = [(a1, r1, a2) for (a1, a2), r1 in it.product(ang_ang, rom)]\n",
    "\n",
    "indirect_mid = avaliate_multiple_paths(rom_ang_rom +  ang_rom_ang)\n",
    "indirect_mid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cb0a9b",
   "metadata": {},
   "source": [
    "### Indirect translation, end language different family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1239092",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt->it->en...ok\n",
      "pt->it->sv...ok\n",
      "pt->it->de...ok\n",
      "pt->es->en...ok\n",
      "pt->es->sv...ok\n",
      "pt->es->de...ok\n",
      "it->pt->en...ok\n",
      "it->pt->sv...ok\n",
      "it->pt->de...ok\n",
      "it->es->en...ok\n",
      "it->es->sv...ok\n",
      "it->es->de...ok\n",
      "es->pt->en...ok\n",
      "es->pt->sv...ok\n",
      "es->pt->de...ok\n",
      "es->it->en...ok\n",
      "es->it->sv...ok\n",
      "es->it->de...ok\n",
      "en->sv->pt...ok\n",
      "en->sv->it...ok\n",
      "en->sv->es...ok\n",
      "en->de->pt...ok\n",
      "en->de->it...ok\n",
      "en->de->es...ok\n",
      "sv->en->pt...ok\n",
      "sv->en->it...ok\n",
      "sv->en->es...ok\n",
      "sv->de->pt...ok\n",
      "sv->de->it...ok\n",
      "sv->de->es...ok\n",
      "de->en->pt...ok\n",
      "de->en->it...ok\n",
      "de->en->es...ok\n",
      "de->sv->pt...ok\n",
      "de->sv->it...ok\n",
      "de->sv->es...ok\n",
      "Cosine similarity mean = 0.6850931696817105\n",
      "Euclidean distance mean = 5.09701031445598\n",
      "BLEU mean = 0.2133887891892107\n",
      "Standard deviation: \n",
      "Cosine Similarity     0.018934\n",
      "Euclidean Distance    0.256419\n",
      "Bleu Score            0.056748\n",
      "dtype: float64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Euclidean Distance</th>\n",
       "      <th>Bleu Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pt -&gt; it -&gt; en</th>\n",
       "      <td>0.698156</td>\n",
       "      <td>5.444389</td>\n",
       "      <td>0.312143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; it -&gt; sv</th>\n",
       "      <td>0.667183</td>\n",
       "      <td>5.040010</td>\n",
       "      <td>0.212312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; it -&gt; de</th>\n",
       "      <td>0.658959</td>\n",
       "      <td>4.799254</td>\n",
       "      <td>0.199895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; es -&gt; en</th>\n",
       "      <td>0.703957</td>\n",
       "      <td>5.403017</td>\n",
       "      <td>0.317437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; es -&gt; sv</th>\n",
       "      <td>0.673067</td>\n",
       "      <td>5.001631</td>\n",
       "      <td>0.228127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt -&gt; es -&gt; de</th>\n",
       "      <td>0.665095</td>\n",
       "      <td>4.762326</td>\n",
       "      <td>0.204248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; pt -&gt; en</th>\n",
       "      <td>0.695482</td>\n",
       "      <td>5.542440</td>\n",
       "      <td>0.257280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; pt -&gt; sv</th>\n",
       "      <td>0.673986</td>\n",
       "      <td>5.132392</td>\n",
       "      <td>0.192750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; pt -&gt; de</th>\n",
       "      <td>0.674496</td>\n",
       "      <td>4.887265</td>\n",
       "      <td>0.179077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; es -&gt; en</th>\n",
       "      <td>0.701003</td>\n",
       "      <td>5.494420</td>\n",
       "      <td>0.267862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; es -&gt; sv</th>\n",
       "      <td>0.677265</td>\n",
       "      <td>5.103656</td>\n",
       "      <td>0.200830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it -&gt; es -&gt; de</th>\n",
       "      <td>0.676984</td>\n",
       "      <td>4.869474</td>\n",
       "      <td>0.180297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; pt -&gt; en</th>\n",
       "      <td>0.731230</td>\n",
       "      <td>5.173897</td>\n",
       "      <td>0.358436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; pt -&gt; sv</th>\n",
       "      <td>0.691124</td>\n",
       "      <td>4.991086</td>\n",
       "      <td>0.231569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; pt -&gt; de</th>\n",
       "      <td>0.681299</td>\n",
       "      <td>4.817945</td>\n",
       "      <td>0.214372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; it -&gt; en</th>\n",
       "      <td>0.726628</td>\n",
       "      <td>5.202613</td>\n",
       "      <td>0.359346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; it -&gt; sv</th>\n",
       "      <td>0.687061</td>\n",
       "      <td>5.016478</td>\n",
       "      <td>0.223892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es -&gt; it -&gt; de</th>\n",
       "      <td>0.677088</td>\n",
       "      <td>4.840244</td>\n",
       "      <td>0.204122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; sv -&gt; pt</th>\n",
       "      <td>0.694102</td>\n",
       "      <td>5.482861</td>\n",
       "      <td>0.220547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; sv -&gt; it</th>\n",
       "      <td>0.692051</td>\n",
       "      <td>5.569716</td>\n",
       "      <td>0.190160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; sv -&gt; es</th>\n",
       "      <td>0.724229</td>\n",
       "      <td>5.226619</td>\n",
       "      <td>0.278019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; de -&gt; pt</th>\n",
       "      <td>0.691938</td>\n",
       "      <td>5.492895</td>\n",
       "      <td>0.217060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; de -&gt; it</th>\n",
       "      <td>0.689640</td>\n",
       "      <td>5.585931</td>\n",
       "      <td>0.182985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en -&gt; de -&gt; es</th>\n",
       "      <td>0.722606</td>\n",
       "      <td>5.240709</td>\n",
       "      <td>0.274163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; en -&gt; pt</th>\n",
       "      <td>0.672867</td>\n",
       "      <td>5.002663</td>\n",
       "      <td>0.155014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; en -&gt; it</th>\n",
       "      <td>0.680602</td>\n",
       "      <td>5.083477</td>\n",
       "      <td>0.158929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; en -&gt; es</th>\n",
       "      <td>0.693877</td>\n",
       "      <td>4.968660</td>\n",
       "      <td>0.187941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; de -&gt; pt</th>\n",
       "      <td>0.665412</td>\n",
       "      <td>5.057064</td>\n",
       "      <td>0.145497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; de -&gt; it</th>\n",
       "      <td>0.668822</td>\n",
       "      <td>5.168057</td>\n",
       "      <td>0.140077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv -&gt; de -&gt; es</th>\n",
       "      <td>0.686334</td>\n",
       "      <td>5.028474</td>\n",
       "      <td>0.177590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; en -&gt; pt</th>\n",
       "      <td>0.662763</td>\n",
       "      <td>4.777122</td>\n",
       "      <td>0.162141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; en -&gt; it</th>\n",
       "      <td>0.673045</td>\n",
       "      <td>4.892868</td>\n",
       "      <td>0.164520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; en -&gt; es</th>\n",
       "      <td>0.681144</td>\n",
       "      <td>4.811577</td>\n",
       "      <td>0.187146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; sv -&gt; pt</th>\n",
       "      <td>0.657271</td>\n",
       "      <td>4.815911</td>\n",
       "      <td>0.151909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; sv -&gt; it</th>\n",
       "      <td>0.669590</td>\n",
       "      <td>4.921923</td>\n",
       "      <td>0.156971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de -&gt; sv -&gt; es</th>\n",
       "      <td>0.676997</td>\n",
       "      <td>4.843306</td>\n",
       "      <td>0.187335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Cosine Similarity  Euclidean Distance  Bleu Score\n",
       "pt -> it -> en           0.698156            5.444389    0.312143\n",
       "pt -> it -> sv           0.667183            5.040010    0.212312\n",
       "pt -> it -> de           0.658959            4.799254    0.199895\n",
       "pt -> es -> en           0.703957            5.403017    0.317437\n",
       "pt -> es -> sv           0.673067            5.001631    0.228127\n",
       "pt -> es -> de           0.665095            4.762326    0.204248\n",
       "it -> pt -> en           0.695482            5.542440    0.257280\n",
       "it -> pt -> sv           0.673986            5.132392    0.192750\n",
       "it -> pt -> de           0.674496            4.887265    0.179077\n",
       "it -> es -> en           0.701003            5.494420    0.267862\n",
       "it -> es -> sv           0.677265            5.103656    0.200830\n",
       "it -> es -> de           0.676984            4.869474    0.180297\n",
       "es -> pt -> en           0.731230            5.173897    0.358436\n",
       "es -> pt -> sv           0.691124            4.991086    0.231569\n",
       "es -> pt -> de           0.681299            4.817945    0.214372\n",
       "es -> it -> en           0.726628            5.202613    0.359346\n",
       "es -> it -> sv           0.687061            5.016478    0.223892\n",
       "es -> it -> de           0.677088            4.840244    0.204122\n",
       "en -> sv -> pt           0.694102            5.482861    0.220547\n",
       "en -> sv -> it           0.692051            5.569716    0.190160\n",
       "en -> sv -> es           0.724229            5.226619    0.278019\n",
       "en -> de -> pt           0.691938            5.492895    0.217060\n",
       "en -> de -> it           0.689640            5.585931    0.182985\n",
       "en -> de -> es           0.722606            5.240709    0.274163\n",
       "sv -> en -> pt           0.672867            5.002663    0.155014\n",
       "sv -> en -> it           0.680602            5.083477    0.158929\n",
       "sv -> en -> es           0.693877            4.968660    0.187941\n",
       "sv -> de -> pt           0.665412            5.057064    0.145497\n",
       "sv -> de -> it           0.668822            5.168057    0.140077\n",
       "sv -> de -> es           0.686334            5.028474    0.177590\n",
       "de -> en -> pt           0.662763            4.777122    0.162141\n",
       "de -> en -> it           0.673045            4.892868    0.164520\n",
       "de -> en -> es           0.681144            4.811577    0.187146\n",
       "de -> sv -> pt           0.657271            4.815911    0.151909\n",
       "de -> sv -> it           0.669590            4.921923    0.156971\n",
       "de -> sv -> es           0.676997            4.843306    0.187335"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tradução com idioma\n",
    "rom_rom_ang = [(r1, r2, a1) for (r1, r2), a1 in it.product(rom_rom, ang)]\n",
    "ang_ang_rom = [(a1, a2, r1) for (a1, a2), r1 in it.product(ang_ang, rom)]\n",
    "\n",
    "indirect_end = avaliate_multiple_paths(rom_rom_ang +  ang_ang_rom)\n",
    "indirect_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea6c1a",
   "metadata": {},
   "source": [
    "### Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b6a32e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = 'new_results.xlsx'\n",
    "with pd.ExcelWriter(path) as writer:\n",
    "    direct_same.describe().to_excel(writer, sheet_name = 'Direct same')\n",
    "    direct_diff.describe().to_excel(writer, sheet_name = 'Direct diff')\n",
    "    indirect_same.describe().to_excel(writer, sheet_name = 'Indirect same')\n",
    "    indirect_start.describe().to_excel(writer, sheet_name = 'Indirect start')\n",
    "    indirect_mid.describe().to_excel(writer, sheet_name = 'Indirect mid')\n",
    "    indirect_end.describe().to_excel(writer, sheet_name = 'Indirect end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aac534e-74f0-476a-8370-d0bae0e71b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
