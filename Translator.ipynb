{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "253770a5",
   "metadata": {},
   "source": [
    "# Word Embedding Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e015f1b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7230eb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36ae151",
   "metadata": {},
   "source": [
    "## 1 - Loading data\n",
    "Loading the models and sentences used.\n",
    "- Models: https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "- Sentences: https://github.com/alexa/massive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f117e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(model_path, sentences_path, limit = None):\n",
    "    model = KeyedVectors.load_word2vec_format(model_path, unicode_errors = 'replace', limit = limit)\n",
    "    sentences = pd.read_json(sentences_path, lines = True)['utt']\n",
    "    \n",
    "    return model, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "553117db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths order: model path, sentences path\n",
    "fasttext_path ='Datasets/FastText/'\n",
    "massive_path = 'Datasets/Amazon_Massive/'\n",
    "\n",
    "paths = {\n",
    "    'pt': [ fasttext_path + 'cc.pt.300.vec', massive_path + 'pt-PT.jsonl' ],\n",
    "    'en': [ fasttext_path + 'cc.en.300.vec', massive_path + 'en-US.jsonl' ],\n",
    "    'es': [ fasttext_path + 'cc.es.300.vec', massive_path + 'es-ES.jsonl' ]\n",
    "}\n",
    "\n",
    "languages = paths.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08bf0f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models, sentences = {}, {}\n",
    "\n",
    "for key, value in paths.items():\n",
    "    models[key], sentences[key] = load_files(value[0], value[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e14fb99",
   "metadata": {},
   "source": [
    "## 2 - Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e67d11b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = { key: [] for key in languages }\n",
    "\n",
    "for idx in range(len(sentences['pt'])):\n",
    "    actual_sentence = { key: [] for key in languages}\n",
    "    \n",
    "    try:\n",
    "        for lang, sent in sentences.items():\n",
    "            for word in sent[idx].split(' '):\n",
    "                actual_sentence[lang].append(models[lang][word])\n",
    "\n",
    "    except KeyError:\n",
    "        continue\n",
    "    \n",
    "    for key, value in actual_sentence.items():\n",
    "        samples[key].append(sum(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5d43f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 16521 -> Model pt samples: 15055 (91.13%)\n",
      "Total sentences: 16521 -> Model en samples: 15055 (91.13%)\n",
      "Total sentences: 16521 -> Model es samples: 15055 (91.13%)\n"
     ]
    }
   ],
   "source": [
    "for key in sentences:\n",
    "    print(f'Total sentences: { len(sentences[key]) } -> Model { key } samples: { len(samples[key]) } ({ len(samples[key]) / len(sentences[key]) * 100:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf7d5e4",
   "metadata": {},
   "source": [
    "## 3 - Making the translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df5bc3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = { key: { lang: None for lang in languages if lang != key } for key in languages }\n",
    "\n",
    "# It is possible to use combinations and transpose translator to speedup and similar results\n",
    "for origin, target in it.permutations(languages, 2): \n",
    "    U, Sig, Vt = np.linalg.svd(np.transpose(samples[origin]) @ samples[target])\n",
    "    translator = np.transpose(Vt) @ np.transpose(U)\n",
    "    translations[origin][target] = translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed70d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_word_list = [\n",
    "    'sapato',\n",
    "    'flor',\n",
    "    'aniversário',\n",
    "    'saudades'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04131c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('zapato', 0.662111222743988), ('zapatos', 0.5563797950744629), ('vestido', 0.5291659235954285), ('calzado', 0.5260925889015198), ('tacón', 0.5103809237480164), ('sapato', 0.5011822581291199), ('bolso', 0.5003554224967957), ('tacones', 0.4980669617652893), ('abriguito', 0.4970734119415283), ('tacon', 0.4929378926753998)]\n",
      "===\n",
      "[('flor', 0.578707754611969), ('florecilla', 0.5153224468231201), ('peonia', 0.5134485960006714), ('camelia', 0.49486222863197327), ('flores.La', 0.4931686818599701), ('gardenia', 0.4834303855895996), ('plantita', 0.4797089993953705), ('florcita', 0.47890302538871765), ('gerbera', 0.4722459316253662), ('peonía', 0.4695531129837036)]\n",
      "===\n",
      "[('cumpleaños', 0.7326678037643433), ('cumpleaño', 0.6536815762519836), ('cumpleños', 0.6065086126327515), ('aniversario', 0.5872988104820251), ('cumpleaños.El', 0.5673967003822327), ('cumpeaños', 0.5645080208778381), ('Cumpleaños', 0.5528781414031982), ('cumpleanos', 0.5322667956352234), ('cumpleñaos', 0.5267534255981445), ('cumpleaños.', 0.5253393650054932)]\n",
      "===\n",
      "[('saudades', 0.5174434185028076), ('morriñas', 0.4936010241508484), ('ganas', 0.4889754354953766), ('añoranzas', 0.4799804389476776), ('nostálgia', 0.47339314222335815), ('añoranza', 0.47094112634658813), ('nostalgias', 0.4639553427696228), ('nostalgia', 0.45602428913116455), ('nostágico', 0.4537942111492157), ('nostálgicas', 0.44510430097579956)]\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "for pt_word in pt_word_list:\n",
    "    print(models['es'].most_similar(translations['pt']['es'] @ models['pt'][pt_word]))\n",
    "    print(\"===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e534a",
   "metadata": {},
   "source": [
    "## 4-Evaluate *future work\n",
    "Two ways to evaluate a path between two languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1c08d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoes\n",
      "[('zapatos', 0.6464644074440002), ('zapatillas', 0.6166307926177979), ('sandalias', 0.5769971013069153), ('botas', 0.5539029240608215), ('calzado', 0.551113486289978), ('zapato', 0.5218526721000671), ('chanclas', 0.5212720036506653), ('calzarán', 0.5174567103385925), ('chancletas', 0.5101444721221924), ('calcetines', 0.5067110657691956)]\n",
      "===\n",
      "flower\n",
      "[('flor', 0.5974904894828796), ('peonía', 0.5804789066314697), ('flores', 0.5449814796447754), ('peonías', 0.5210880637168884), ('floral', 0.49466392397880554), ('anturio', 0.4922579824924469), ('crisantemo', 0.4872678816318512), ('camelia', 0.47671687602996826), ('flores.La', 0.47307777404785156), ('gerbera', 0.4728681743144989)]\n",
      "===\n",
      "birthday\n",
      "[('cumpleaños', 0.7605622410774231), ('cumpleaño', 0.6504004597663879), ('cumpleños', 0.5819917321205139), ('cumpleaños.El', 0.5789167284965515), ('Cumpleaños', 0.5748640894889832), ('cumpeaños', 0.572516918182373), ('cumpleañero', 0.5690513849258423), ('cumpleaños.Y', 0.5607236623764038), ('cumpleaños.En', 0.5477907657623291), ('cumpleñaos', 0.5442656874656677)]\n",
      "===\n",
      "memories.So\n",
      "[('recuerdos', 0.5069612264633179), ('recuerdos.Y', 0.45639243721961975), ('recuerdos.En', 0.44077301025390625), ('añoranzas', 0.4395352303981781), ('Gratos', 0.4357491135597229), ('recuerdos.La', 0.4351595938205719), ('recuerdos.Un', 0.4291515052318573), ('memoria.Y', 0.4289899170398712), ('recuerdos.El', 0.4282625615596771), ('nostalgias', 0.4201315939426422)]\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "# Getting the most similar word in each language it pass\n",
    "# Most expensive (uses most_similar multiple times) and try to aproximate a word each time\n",
    "for pt_word in pt_word_list:\n",
    "    english_word = models['en'].most_similar(translations['pt']['en'] @models['pt'][pt_word])[0][0]\n",
    "    print(english_word)\n",
    "    print(models['es'].most_similar(translations['en']['es'] @ models['en'][english_word]))\n",
    "    print(\"===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db82fc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('zapato', 0.5569401383399963), ('zapatos', 0.5283559560775757), ('tacones', 0.49460408091545105), ('vestido', 0.4847036302089691), ('sapato', 0.4791000187397003), ('sapatos', 0.46534422039985657), ('pantalón', 0.46260935068130493), ('collarcito', 0.4543265402317047), ('tacón', 0.4519156813621521), ('pantalones', 0.45182451605796814)]\n",
      "===\n",
      "[('flor', 0.5727273225784302), ('peonia', 0.498028963804245), ('peonía', 0.4919746220111847), ('florecita', 0.48463183641433716), ('rosa', 0.4773949682712555), ('florecilla', 0.4752405881881714), ('flor.Y', 0.4716757535934448), ('rosaY', 0.4682154655456543), ('rosaa', 0.46463143825531006), ('azalea', 0.4611826539039612)]\n",
      "===\n",
      "[('cumpleaños', 0.6476301550865173), ('cumpleaño', 0.6001196503639221), ('cumpleños', 0.5466558933258057), ('cumpleaños.El', 0.5311540961265564), ('cumpleaños.En', 0.5147355198860168), ('cumpeaños', 0.4955201745033264), ('aniversario', 0.4934757947921753), ('cumpleanos', 0.48804065585136414), ('cumpleañero', 0.4873219132423401), ('cumpleñaos', 0.4855706989765167)]\n",
      "===\n",
      "[('morriñas', 0.47367650270462036), ('añorar', 0.4645899534225464), ('añoro', 0.4526515007019043), ('extrañamos', 0.4451638460159302), ('añoranza', 0.44479629397392273), ('nostálgia', 0.4394629895687103), ('fatiguitas', 0.4392240345478058), ('nostalgia', 0.43839192390441895), ('añoranzas', 0.4283502995967865), ('añoraré', 0.4271792471408844)]\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "# Using the vector transformed to each subspace\n",
    "# Uses most_similar and try to approximate the word just one time \n",
    "for pt_word in pt_word_list:\n",
    "    english_vector = translations['pt']['en'] @models['pt'][pt_word]\n",
    "    print(models['es'].most_similar(translations['en']['es'] @ english_vector))\n",
    "    print(\"===\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
